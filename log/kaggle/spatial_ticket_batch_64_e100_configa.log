
5.6s	0	Cloning into 'TickNets'...
6.2s	1	remote: Enumerating objects: 283, done.[K
6.2s	2	remote: Counting objects:   2% (1/37)[K
remote: Counting objects:   5% (2/37)[K
remote: Counting objects:   8% (3/37)[K
remote: Counting objects:  10% (4/37)[K
remote: Counting objects:  13% (5/37)[K
remote: Counting objects:  16% (6/37)[K
remote: Counting objects:  18% (7/37)[K
remote: Counting objects:  21% (8/37)[K
remote: Counting objects:  24% (9/37)[K
remote: Counting objects:  27% (10/37)[K
remote: Counting objects:  29% (11/37)[K
remote: Counting objects:  32% (12/37)[K
remote: Counting objects:  35% (13/37)[K
remote: Counting objects:  37% (14/37)[K
remote: Counting objects:  40% (15/37)[K
remote: Counting objects:  43% (16/37)[K
remote: Counting objects:  45% (17/37)[K
remote: Counting objects:  48% (18/37)[K
remote: Counting objects:  51% (19/37)[K
remote: Counting objects:  54% (20/37)[K
remote: Counting objects:  56% (21/37)[K
remote: Counting objects:  59% (22/37)[K
remote: Counting objects:  62% (23/37)[K
remote: Counting objects:  64% (24/37)[K
remote: Counting objects:  67% (25/37)[K
remote: Counting objects:  70% (26/37)[K
remote: Counting objects:  72% (27/37)[K
remote: Counting objects:  75% (28/37)[K
remote: Counting objects:  78% (29/37)[K
remote: Counting objects:  81% (30/37)[K
remote: Counting objects:  83% (31/37)[K
remote: Counting objects:  86% (32/37)[K
remote: Counting objects:  89% (33/37)[K
remote: Counting objects:  91% (34/37)[K
remote: Counting objects:  94% (35/37)[K
remote: Counting objects:  97% (36/37)[K
remote: Counting objects: 100% (37/37)[K
remote: Counting objects: 100% (37/37), done.[K
6.2s	3	remote: Compressing objects:   4% (1/24)[K
remote: Compressing objects:   8% (2/24)[K
remote: Compressing objects:  12% (3/24)[K
remote: Compressing objects:  16% (4/24)[K
remote: Compressing objects:  20% (5/24)[K
remote: Compressing objects:  25% (6/24)[K
remote: Compressing objects:  29% (7/24)[K
remote: Compressing objects:  33% (8/24)[K
remote: Compressing objects:  37% (9/24)[K
remote: Compressing objects:  41% (10/24)[K
remote: Compressing objects:  45% (11/24)[K
remote: Compressing objects:  50% (12/24)[K
remote: Compressing objects:  54% (13/24)[K
remote: Compressing objects:  58% (14/24)[K
remote: Compressing objects:  62% (15/24)[K
remote: Compressing objects:  66% (16/24)[K
remote: Compressing objects:  70% (17/24)[K
remote: Compressing objects:  75% (18/24)[K
remote: Compressing objects:  79% (19/24)[K
remote: Compressing objects:  83% (20/24)[K
remote: Compressing objects:  87% (21/24)[K
remote: Compressing objects:  91% (22/24)[K
remote: Compressing objects:  95% (23/24)[K
remote: Compressing objects: 100% (24/24)[K
remote: Compressing objects: 100% (24/24), done.[K
6.8s	4	Receiving objects:   0% (1/283)
Receiving objects:   1% (3/283)
Receiving objects:   2% (6/283)
Receiving objects:   3% (9/283)
Receiving objects:   4% (12/283)
Receiving objects:   5% (15/283)
Receiving objects:   6% (17/283)
Receiving objects:   7% (20/283)
Receiving objects:   8% (23/283)
Receiving objects:   9% (26/283)
Receiving objects:  10% (29/283)
Receiving objects:  11% (32/283)
Receiving objects:  12% (34/283)
Receiving objects:  13% (37/283)
Receiving objects:  14% (40/283)
Receiving objects:  15% (43/283)
Receiving objects:  16% (46/283)
Receiving objects:  17% (49/283)
Receiving objects:  18% (51/283)
Receiving objects:  19% (54/283)
Receiving objects:  20% (57/283)
Receiving objects:  21% (60/283)
Receiving objects:  22% (63/283)
Receiving objects:  23% (66/283)
Receiving objects:  24% (68/283)
Receiving objects:  25% (71/283)
Receiving objects:  26% (74/283)
Receiving objects:  27% (77/283)
Receiving objects:  28% (80/283)
Receiving objects:  29% (83/283)
Receiving objects:  30% (85/283)
Receiving objects:  31% (88/283)
Receiving objects:  32% (91/283)
Receiving objects:  33% (94/283)
Receiving objects:  34% (97/283)
Receiving objects:  35% (100/283)
Receiving objects:  36% (102/283)
Receiving objects:  37% (105/283)
Receiving objects:  38% (108/283)
Receiving objects:  39% (111/283)
Receiving objects:  40% (114/283)
Receiving objects:  41% (117/283)
Receiving objects:  42% (119/283)
Receiving objects:  43% (122/283)
Receiving objects:  44% (125/283)
Receiving objects:  45% (128/283)
Receiving objects:  46% (131/283)
Receiving objects:  47% (134/283)
Receiving objects:  48% (136/283)
Receiving objects:  49% (139/283)
Receiving objects:  50% (142/283)
Receiving objects:  51% (145/283)
Receiving objects:  52% (148/283)
Receiving objects:  53% (150/283)
Receiving objects:  54% (153/283)
Receiving objects:  55% (156/283)
Receiving objects:  56% (159/283)
Receiving objects:  57% (162/283)
Receiving objects:  58% (165/283)
Receiving objects:  59% (167/283)
Receiving objects:  60% (170/283)
Receiving objects:  61% (173/283)
Receiving objects:  62% (176/283)
Receiving objects:  63% (179/283)
Receiving objects:  64% (182/283)
Receiving objects:  65% (184/283)
Receiving objects:  66% (187/283)
Receiving objects:  67% (190/283)
Receiving objects:  68% (193/283)
Receiving objects:  69% (196/283)
Receiving objects:  70% (199/283)
Receiving objects:  71% (201/283)
Receiving objects:  72% (204/283)
Receiving objects:  73% (207/283)
Receiving objects:  74% (210/283)
Receiving objects:  75% (213/283)
Receiving objects:  76% (216/283)
Receiving objects:  77% (218/283)
Receiving objects:  78% (221/283)
remote: Total 283 (delta 25), reused 23 (delta 13), pack-reused 246 (from 2)[K
6.8s	5	Receiving objects:  79% (224/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  80% (227/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  81% (230/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  82% (233/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  83% (235/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  84% (238/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  85% (241/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  86% (244/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  87% (247/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  88% (250/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  89% (252/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  90% (255/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  91% (258/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  92% (261/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  93% (264/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  94% (267/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  95% (269/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  96% (272/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  97% (275/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  98% (278/283), 18.35 MiB | 36.75 MiB/s
Receiving objects:  99% (281/283), 18.35 MiB | 36.75 MiB/s
Receiving objects: 100% (283/283), 18.35 MiB | 36.75 MiB/s
Receiving objects: 100% (283/283), 18.40 MiB | 36.44 MiB/s, done.
6.8s	6	Resolving deltas:   0% (0/124)
Resolving deltas:   1% (2/124)
Resolving deltas:   2% (3/124)
Resolving deltas:   3% (4/124)
Resolving deltas:   4% (5/124)
Resolving deltas:   5% (7/124)
Resolving deltas:   6% (8/124)
Resolving deltas:   7% (9/124)
Resolving deltas:   8% (10/124)
Resolving deltas:   9% (12/124)
Resolving deltas:  10% (13/124)
Resolving deltas:  11% (14/124)
Resolving deltas:  12% (15/124)
Resolving deltas:  13% (17/124)
Resolving deltas:  14% (18/124)
Resolving deltas:  15% (19/124)
Resolving deltas:  16% (20/124)
Resolving deltas:  17% (22/124)
Resolving deltas:  18% (23/124)
Resolving deltas:  19% (24/124)
Resolving deltas:  20% (25/124)
Resolving deltas:  21% (27/124)
Resolving deltas:  22% (28/124)
Resolving deltas:  23% (29/124)
Resolving deltas:  24% (30/124)
Resolving deltas:  25% (31/124)
Resolving deltas:  26% (33/124)
Resolving deltas:  27% (34/124)
Resolving deltas:  28% (35/124)
Resolving deltas:  29% (36/124)
Resolving deltas:  30% (38/124)
Resolving deltas:  31% (39/124)
Resolving deltas:  32% (40/124)
Resolving deltas:  33% (41/124)
Resolving deltas:  34% (43/124)
Resolving deltas:  35% (44/124)
Resolving deltas:  36% (45/124)
Resolving deltas:  37% (46/124)
Resolving deltas:  38% (48/124)
Resolving deltas:  39% (49/124)
Resolving deltas:  40% (50/124)
Resolving deltas:  41% (51/124)
Resolving deltas:  42% (53/124)
Resolving deltas:  43% (54/124)
Resolving deltas:  44% (55/124)
Resolving deltas:  45% (56/124)
Resolving deltas:  46% (58/124)
Resolving deltas:  47% (59/124)
Resolving deltas:  48% (60/124)
Resolving deltas:  49% (61/124)
Resolving deltas:  50% (62/124)
Resolving deltas:  51% (64/124)
Resolving deltas:  52% (65/124)
Resolving deltas:  53% (66/124)
Resolving deltas:  54% (67/124)
Resolving deltas:  55% (69/124)
Resolving deltas:  56% (70/124)
Resolving deltas:  57% (71/124)
Resolving deltas:  58% (72/124)
Resolving deltas:  59% (74/124)
Resolving deltas:  60% (75/124)
Resolving deltas:  61% (76/124)
Resolving deltas:  62% (77/124)
Resolving deltas:  63% (79/124)
Resolving deltas:  64% (80/124)
Resolving deltas:  65% (81/124)
Resolving deltas:  66% (82/124)
Resolving deltas:  67% (84/124)
Resolving deltas:  68% (85/124)
Resolving deltas:  69% (86/124)
Resolving deltas:  70% (87/124)
Resolving deltas:  71% (89/124)
Resolving deltas:  72% (90/124)
Resolving deltas:  73% (91/124)
Resolving deltas:  74% (92/124)
Resolving deltas:  75% (93/124)
Resolving deltas:  76% (95/124)
Resolving deltas:  77% (96/124)
Resolving deltas:  78% (97/124)
Resolving deltas:  79% (98/124)
Resolving deltas:  80% (100/124)
Resolving deltas:  81% (101/124)
Resolving deltas:  82% (102/124)
Resolving deltas:  83% (103/124)
Resolving deltas:  84% (105/124)
Resolving deltas:  85% (106/124)
Resolving deltas:  86% (107/124)
Resolving deltas:  87% (108/124)
Resolving deltas:  88% (110/124)
Resolving deltas:  89% (111/124)
Resolving deltas:  90% (112/124)
Resolving deltas:  91% (113/124)
Resolving deltas:  92% (115/124)
Resolving deltas:  93% (116/124)
Resolving deltas:  94% (117/124)
Resolving deltas:  95% (118/124)
Resolving deltas:  96% (120/124)
Resolving deltas:  97% (121/124)
Resolving deltas:  98% (122/124)
Resolving deltas:  99% (123/124)
Resolving deltas: 100% (124/124)
Resolving deltas: 100% (124/124), done.
12.2s	7	Command: ./TickNets/TickNet_Dogs.py --download --base-dir=./ --data-root=./datasets/StanfordDogs --network-type=spatialTickNet --config=a -g 0 -b 64 -e 100
12.3s	8	Using device cuda:0
12.3s	9	THE ACTUAL CHANNEL: basic
12.3s	10	THE ACTUAL CHANNEL CONFIG: a
12.3s	11	add_stages: stage(1), node(1)
12.3s	12	add_stages: stage(1), node(2)
12.3s	13	add_stages: stage(2), node(1)
12.3s	14	add_stages: stage(3), node(1)
12.3s	15	add_stages: stage(4), node(1)
12.3s	16	add_stages: stage(5), node(1)
12.5s	17	SpatialTickNet(
12.5s	18	  (backbone): Sequential(
12.5s	19	    (data_bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	20	    (init_conv): ConvBlock(
12.5s	21	      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
12.5s	22	      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	23	      (activation): ReLU(inplace=True)
12.5s	24	    )
12.5s	25	    (stage1): Sequential(
12.5s	26	      (unit1): FR_PDP_block(
12.5s	27	        (Pw1): ConvBlock(
12.5s	28	          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
12.5s	29	        )
12.5s	30	        (Dw): ConvBlock(
12.5s	31	          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
12.5s	32	          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	33	          (activation): ReLU(inplace=True)
12.5s	34	        )
12.5s	35	        (Pw2): ConvBlock(
12.5s	36	          (conv): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
12.5s	37	          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	38	          (activation): ReLU(inplace=True)
12.5s	39	        )
12.5s	40	        (PwR): ConvBlock(
12.5s	41	          (conv): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
12.5s	42	          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	43	          (activation): ReLU(inplace=True)
12.5s	44	        )
12.5s	45	        (SE): SE(
12.5s	46	          (ChannelGate): ChannelGate(
12.5s	47	            (mlp): Sequential(
12.5s	48	              (0): Flatten()
12.5s	49	              (1): Linear(in_features=256, out_features=16, bias=True)
12.5s	50	              (2): ReLU()
12.5s	51	              (3): Linear(in_features=16, out_features=256, bias=True)
12.5s	52	            )
12.5s	53	          )
12.5s	54	        )
12.5s	55	      )
12.5s	56	      (unit2): FR_PDP_block(
12.5s	57	        (Pw1): ConvBlock(
12.5s	58	          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
12.5s	59	        )
12.5s	60	        (Dw): ConvBlock(
12.5s	61	          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
12.5s	62	          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	63	          (activation): ReLU(inplace=True)
12.5s	64	        )
12.5s	65	        (Pw2): ConvBlock(
12.5s	66	          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
12.5s	67	          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	68	          (activation): ReLU(inplace=True)
12.5s	69	        )
12.5s	70	        (PwR): ConvBlock(
12.5s	71	          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
12.5s	72	          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	73	          (activation): ReLU(inplace=True)
12.5s	74	        )
12.5s	75	        (SE): SE(
12.5s	76	          (ChannelGate): ChannelGate(
12.5s	77	            (mlp): Sequential(
12.5s	78	              (0): Flatten()
12.5s	79	              (1): Linear(in_features=128, out_features=8, bias=True)
12.5s	80	              (2): ReLU()
12.5s	81	              (3): Linear(in_features=8, out_features=128, bias=True)
12.5s	82	            )
12.5s	83	          )
12.5s	84	        )
12.5s	85	      )
12.5s	86	    )
12.5s	87	    (stage2): Sequential(
12.5s	88	      (unit1): FR_PDP_block(
12.5s	89	        (Pw1): ConvBlock(
12.5s	90	          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
12.5s	91	        )
12.5s	92	        (Dw): ConvBlock(
12.5s	93	          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
12.5s	94	          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	95	          (activation): ReLU(inplace=True)
12.5s	96	        )
12.5s	97	        (Pw2): ConvBlock(
12.5s	98	          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
12.5s	99	          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	100	          (activation): ReLU(inplace=True)
12.5s	101	        )
12.5s	102	        (PwR): ConvBlock(
12.5s	103	          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
12.5s	104	          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	105	          (activation): ReLU(inplace=True)
12.5s	106	        )
12.5s	107	        (SE): SE(
12.5s	108	          (ChannelGate): ChannelGate(
12.5s	109	            (mlp): Sequential(
12.5s	110	              (0): Flatten()
12.5s	111	              (1): Linear(in_features=64, out_features=4, bias=True)
12.5s	112	              (2): ReLU()
12.5s	113	              (3): Linear(in_features=4, out_features=64, bias=True)
12.5s	114	            )
12.5s	115	          )
12.5s	116	        )
12.5s	117	      )
12.5s	118	    )
12.5s	119	    (stage3): Sequential(
12.5s	120	      (unit1): FR_PDP_block(
12.5s	121	        (Pw1): ConvBlock(
12.5s	122	          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
12.5s	123	        )
12.5s	124	        (Dw): ConvBlock(
12.5s	125	          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
12.5s	126	          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	127	          (activation): ReLU(inplace=True)
12.5s	128	        )
12.5s	129	        (Pw2): ConvBlock(
12.5s	130	          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
12.5s	131	          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	132	          (activation): ReLU(inplace=True)
12.5s	133	        )
12.5s	134	        (PwR): ConvBlock(
12.5s	135	          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
12.5s	136	          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	137	          (activation): ReLU(inplace=True)
12.5s	138	        )
12.5s	139	        (SE): SE(
12.5s	140	          (ChannelGate): ChannelGate(
12.5s	141	            (mlp): Sequential(
12.5s	142	              (0): Flatten()
12.5s	143	              (1): Linear(in_features=128, out_features=8, bias=True)
12.5s	144	              (2): ReLU()
12.5s	145	              (3): Linear(in_features=8, out_features=128, bias=True)
12.5s	146	            )
12.5s	147	          )
12.5s	148	        )
12.5s	149	      )
12.5s	150	    )
12.5s	151	    (stage4): Sequential(
12.5s	152	      (unit1): FR_PDP_block(
12.5s	153	        (Pw1): ConvBlock(
12.5s	154	          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
12.5s	155	        )
12.5s	156	        (Dw): ConvBlock(
12.5s	157	          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
12.5s	158	          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	159	          (activation): ReLU(inplace=True)
12.5s	160	        )
12.5s	161	        (Pw2): ConvBlock(
12.5s	162	          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
12.5s	163	          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	164	          (activation): ReLU(inplace=True)
12.5s	165	        )
12.5s	166	        (PwR): ConvBlock(
12.5s	167	          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
12.5s	168	          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	169	          (activation): ReLU(inplace=True)
12.5s	170	        )
12.5s	171	        (SE): SE(
12.5s	172	          (ChannelGate): ChannelGate(
12.5s	173	            (mlp): Sequential(
12.5s	174	              (0): Flatten()
12.5s	175	              (1): Linear(in_features=256, out_features=16, bias=True)
12.5s	176	              (2): ReLU()
12.5s	177	              (3): Linear(in_features=16, out_features=256, bias=True)
12.5s	178	            )
12.5s	179	          )
12.5s	180	        )
12.5s	181	      )
12.5s	182	    )
12.5s	183	    (stage5): Sequential(
12.5s	184	      (unit1): FR_PDP_block(
12.5s	185	        (Pw1): ConvBlock(
12.5s	186	          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
12.5s	187	        )
12.5s	188	        (Dw): ConvBlock(
12.5s	189	          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
12.5s	190	          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	191	          (activation): ReLU(inplace=True)
12.5s	192	        )
12.5s	193	        (Pw2): ConvBlock(
12.5s	194	          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
12.5s	195	          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	196	          (activation): ReLU(inplace=True)
12.5s	197	        )
12.5s	198	        (PwR): ConvBlock(
12.5s	199	          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
12.5s	200	          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	201	          (activation): ReLU(inplace=True)
12.5s	202	        )
12.5s	203	        (SE): SE(
12.5s	204	          (ChannelGate): ChannelGate(
12.5s	205	            (mlp): Sequential(
12.5s	206	              (0): Flatten()
12.5s	207	              (1): Linear(in_features=512, out_features=32, bias=True)
12.5s	208	              (2): ReLU()
12.5s	209	              (3): Linear(in_features=32, out_features=512, bias=True)
12.5s	210	            )
12.5s	211	          )
12.5s	212	        )
12.5s	213	      )
12.5s	214	    )
12.5s	215	    (final_conv): ConvBlock(
12.5s	216	      (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
12.5s	217	      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
12.5s	218	      (activation): ReLU(inplace=True)
12.5s	219	    )
12.5s	220	    (global_pool): AdaptiveAvgPool2d(output_size=1)
12.5s	221	  )
12.5s	222	  (classifier): Classifier(
12.5s	223	    (conv): Conv2d(1024, 120, kernel_size=(1, 1), stride=(1, 1))
12.5s	224	  )
12.5s	225	)
12.5s	226	Number of model parameters: 1331666
12.6s	227	Downloading http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar to ./datasets/StanfordDogs/images.tar
95.9s	228	
  0%|                                             | 0/793579520 [00:00<?, ?it/s]
  0%|                           | 131072/793579520 [00:00<10:31, 1256923.73it/s]
  0%|                           | 262144/793579520 [00:00<12:21, 1069236.63it/s]
  0%|                           | 393216/793579520 [00:00<12:00, 1100948.21it/s]
  0%|                           | 589824/793579520 [00:00<10:04, 1311333.93it/s]
  0%|                           | 983040/793579520 [00:00<07:34, 1744037.20it/s]
  0%|                          | 1310720/793579520 [00:00<06:25, 2054497.04it/s]
  0%|                          | 1572864/793579520 [00:00<06:03, 2178359.28it/s]
  0%|                          | 1900544/793579520 [00:00<05:22, 2455131.35it/s]
  0%|                          | 2228224/793579520 [00:01<05:00, 2633776.60it/s]
  0%|                          | 2523136/793579520 [00:01<04:52, 2700497.64it/s]
  0%|                          | 2818048/793579520 [00:01<04:48, 2739130.08it/s]
  0%|                          | 3211264/793579520 [00:01<04:20, 3034192.91it/s]
  1%|â–                         | 4292608/793579520 [00:01<02:32, 5168629.22it/s]
  1%|â–                         | 5210112/793579520 [00:01<02:22, 5515379.13it/s]
  1%|â–                         | 5767168/793579520 [00:01<02:30, 5222768.64it/s]
  1%|â–Ž                         | 7897088/793579520 [00:01<01:23, 9436582.89it/s]
  1%|â–Ž                       | 10747904/793579520 [00:01<00:55, 14166097.34it/s]
  2%|â–Ž                       | 12222464/793579520 [00:02<01:14, 10504906.14it/s]
  2%|â–                       | 14942208/793579520 [00:02<00:54, 14166515.42it/s]
  2%|â–Œ                       | 17629184/793579520 [00:02<00:45, 17204656.28it/s]
  3%|â–Œ                       | 19922944/793579520 [00:02<00:41, 18647710.66it/s]
  3%|â–‹                       | 22085632/793579520 [00:02<00:39, 19394454.09it/s]
  3%|â–‹                       | 24379392/793579520 [00:02<00:37, 20324137.84it/s]
  3%|â–Š                       | 27131904/793579520 [00:02<00:34, 22340016.99it/s]
  4%|â–‰                       | 29622272/793579520 [00:02<00:33, 23064995.43it/s]
  4%|â–‰                       | 32014336/793579520 [00:03<00:35, 21304803.03it/s]
  4%|â–ˆ                       | 34242560/793579520 [00:03<01:11, 10694702.72it/s]
  5%|â–ˆâ–                       | 35946496/793579520 [00:04<01:48, 6986030.30it/s]
  5%|â–ˆâ–                       | 37224448/793579520 [00:04<02:26, 5163617.44it/s]
  5%|â–ˆâ–                       | 38207488/793579520 [00:04<02:37, 4803661.59it/s]
  5%|â–ˆâ–                       | 39026688/793579520 [00:04<02:28, 5072819.17it/s]
  5%|â–ˆâ–Ž                       | 40042496/793579520 [00:05<02:11, 5748549.16it/s]
  5%|â–ˆâ–Ž                       | 40894464/793579520 [00:05<02:34, 4858625.66it/s]
  5%|â–ˆâ–Ž                       | 41582592/793579520 [00:05<02:44, 4571629.71it/s]
  5%|â–ˆâ–Ž                       | 42172416/793579520 [00:05<02:38, 4740836.21it/s]
  6%|â–ˆâ–                       | 44040192/793579520 [00:05<01:42, 7302712.57it/s]
  6%|â–ˆâ–                       | 45940736/793579520 [00:05<01:16, 9717959.32it/s]
  6%|â–ˆâ–                      | 47710208/793579520 [00:05<01:04, 11543352.79it/s]
  6%|â–ˆâ–Œ                      | 49610752/793579520 [00:06<00:55, 13387239.74it/s]
  6%|â–ˆâ–Œ                      | 51478528/793579520 [00:06<00:50, 14763351.12it/s]
  7%|â–ˆâ–Œ                      | 53346304/793579520 [00:06<00:46, 15821508.38it/s]
  7%|â–ˆâ–‹                       | 55083008/793579520 [00:06<01:17, 9535422.33it/s]
  7%|â–ˆâ–Š                       | 56426496/793579520 [00:07<02:07, 5778749.59it/s]
  7%|â–ˆâ–Š                       | 58327040/793579520 [00:07<01:37, 7522026.29it/s]
  8%|â–ˆâ–‰                       | 60293120/793579520 [00:07<01:17, 9443360.57it/s]
  8%|â–ˆâ–‰                      | 62193664/793579520 [00:07<01:05, 11170458.83it/s]
  8%|â–ˆâ–‰                      | 63963136/793579520 [00:07<00:58, 12455169.03it/s]
  8%|â–ˆâ–‰                      | 65601536/793579520 [00:07<00:57, 12638852.37it/s]
  8%|â–ˆâ–ˆ                      | 67141632/793579520 [00:07<00:56, 12873918.76it/s]
  9%|â–ˆâ–ˆ                      | 68648960/793579520 [00:07<00:54, 13182612.17it/s]
  9%|â–ˆâ–ˆ                      | 70123520/793579520 [00:07<00:54, 13351171.30it/s]
  9%|â–ˆâ–ˆâ–                     | 71565312/793579520 [00:08<01:03, 11404720.44it/s]
  9%|â–ˆâ–ˆâ–Ž                      | 72843264/793579520 [00:08<01:35, 7586617.01it/s]
  9%|â–ˆâ–ˆâ–Ž                      | 74285056/793579520 [00:08<01:21, 8806897.86it/s]
 10%|â–ˆâ–ˆâ–                      | 75431936/793579520 [00:08<01:33, 7714531.24it/s]
 10%|â–ˆâ–ˆâ–                      | 76939264/793579520 [00:08<01:18, 9089768.38it/s]
 10%|â–ˆâ–ˆâ–Ž                     | 78479360/793579520 [00:08<01:08, 10418836.07it/s]
 10%|â–ˆâ–ˆâ–                     | 79921152/793579520 [00:09<01:02, 11348346.27it/s]
 10%|â–ˆâ–ˆâ–                     | 81395712/793579520 [00:09<00:58, 12083889.96it/s]
 10%|â–ˆâ–ˆâ–Œ                     | 82935808/793579520 [00:09<00:54, 12922116.29it/s]
 11%|â–ˆâ–ˆâ–Œ                     | 84443136/793579520 [00:09<00:52, 13468895.90it/s]
 11%|â–ˆâ–ˆâ–Œ                     | 85884928/793579520 [00:09<00:51, 13693692.76it/s]
 11%|â–ˆâ–ˆâ–‹                     | 87490560/793579520 [00:09<00:49, 14263632.29it/s]
 11%|â–ˆâ–ˆâ–Š                      | 88965120/793579520 [00:10<01:47, 6560976.26it/s]
 11%|â–ˆâ–ˆâ–Š                      | 90079232/793579520 [00:10<02:09, 5413937.65it/s]
 12%|â–ˆâ–ˆâ–‰                      | 91619328/793579520 [00:10<01:42, 6829732.68it/s]
 12%|â–ˆâ–ˆâ–‰                      | 93224960/793579520 [00:10<01:23, 8362608.19it/s]
 12%|â–ˆâ–ˆâ–‰                      | 94470144/793579520 [00:10<01:32, 7574700.82it/s]
 12%|â–ˆâ–ˆâ–ˆ                      | 96010240/793579520 [00:10<01:17, 9009377.61it/s]
 12%|â–ˆâ–ˆâ–‰                     | 97550336/793579520 [00:10<01:07, 10344634.40it/s]
 12%|â–ˆâ–ˆâ–‰                     | 99123200/793579520 [00:11<01:00, 11571524.77it/s]
 13%|â–ˆâ–ˆâ–‰                    | 100597760/793579520 [00:11<01:03, 10879175.90it/s]
 13%|â–ˆâ–ˆâ–ˆ                     | 101842944/793579520 [00:11<01:13, 9376400.79it/s]
 13%|â–ˆâ–ˆâ–‰                    | 103415808/793579520 [00:11<01:04, 10738377.36it/s]
 13%|â–ˆâ–ˆâ–ˆ                    | 105054208/793579520 [00:11<00:57, 12057316.50it/s]
 13%|â–ˆâ–ˆâ–ˆ                    | 106594304/793579520 [00:11<00:53, 12901232.43it/s]
 14%|â–ˆâ–ˆâ–ˆâ–                   | 108199936/793579520 [00:11<00:50, 13668498.72it/s]
 14%|â–ˆâ–ˆâ–ˆâ–Ž                    | 109674496/793579520 [00:12<01:10, 9699612.91it/s]
 14%|â–ˆâ–ˆâ–ˆâ–                   | 111280128/793579520 [00:12<01:02, 10880344.95it/s]
 14%|â–ˆâ–ˆâ–ˆâ–Ž                   | 112885760/793579520 [00:12<00:56, 12073721.28it/s]
 14%|â–ˆâ–ˆâ–ˆâ–Ž                   | 114360320/793579520 [00:12<00:53, 12704601.27it/s]
 15%|â–ˆâ–ˆâ–ˆâ–Ž                   | 115965952/793579520 [00:12<00:50, 13423402.31it/s]
 15%|â–ˆâ–ˆâ–ˆâ–                   | 117538816/793579520 [00:12<00:48, 14005300.25it/s]
 15%|â–ˆâ–ˆâ–ˆâ–                   | 119046144/793579520 [00:12<00:47, 14287299.66it/s]
 15%|â–ˆâ–ˆâ–ˆâ–                   | 120619008/793579520 [00:12<00:45, 14639699.75it/s]
 15%|â–ˆâ–ˆâ–ˆâ–Œ                   | 122126336/793579520 [00:12<00:45, 14752835.75it/s]
 16%|â–ˆâ–ˆâ–ˆâ–Œ                   | 123666432/793579520 [00:13<00:44, 14928264.15it/s]
 16%|â–ˆâ–ˆâ–ˆâ–‹                   | 125272064/793579520 [00:13<00:43, 15197513.32it/s]
 16%|â–ˆâ–ˆâ–ˆâ–‰                     | 126812160/793579520 [00:28<32:58, 336984.83it/s]
 16%|â–ˆâ–ˆâ–ˆâ–ˆ                     | 128090112/793579520 [00:28<24:34, 451289.33it/s]
 16%|â–ˆâ–ˆâ–ˆâ–ˆ                     | 129761280/793579520 [00:28<16:43, 661662.02it/s]
 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–                    | 131465216/793579520 [00:28<11:30, 958863.63it/s]
 17%|â–ˆâ–ˆâ–ˆâ–ˆ                    | 133169152/793579520 [00:28<08:04, 1364251.83it/s]
 17%|â–ˆâ–ˆâ–ˆâ–ˆ                    | 134840320/793579520 [00:28<05:46, 1899097.34it/s]
 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–                   | 136445952/793579520 [00:28<04:16, 2566496.00it/s]
 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–                   | 138051584/793579520 [00:28<03:12, 3410378.54it/s]
 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–                   | 139755520/793579520 [00:29<02:24, 4526305.73it/s]
 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 141459456/793579520 [00:29<01:52, 5816300.18it/s]
 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 143065088/793579520 [00:29<01:32, 7008023.94it/s]
 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 144605184/793579520 [00:29<01:23, 7805701.92it/s]
 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–                   | 146014208/793579520 [00:29<01:15, 8563735.15it/s]
 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–                   | 147357696/793579520 [00:29<01:09, 9317887.99it/s]
 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–                   | 148668416/793579520 [00:29<01:04, 9973427.42it/s]
 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 149946368/793579520 [00:29<01:00, 10556621.91it/s]
 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–                  | 151289856/793579520 [00:29<00:57, 11195565.92it/s]
 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–                  | 152633344/793579520 [00:30<00:54, 11773269.39it/s]
 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–                  | 153944064/793579520 [00:30<00:53, 11969642.65it/s]
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 155287552/793579520 [00:30<00:51, 12354590.14it/s]
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 156663808/793579520 [00:30<00:50, 12727642.34it/s]
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 158007296/793579520 [00:30<00:49, 12875931.42it/s]
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 159449088/793579520 [00:30<00:47, 13273248.80it/s]
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 160890880/793579520 [00:30<00:46, 13500784.99it/s]
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 162267136/793579520 [00:30<00:46, 13565452.15it/s]
 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 163708928/793579520 [00:30<00:46, 13659575.09it/s]
 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 165183488/793579520 [00:31<00:45, 13933496.71it/s]
 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 166625280/793579520 [00:31<00:44, 14042013.98it/s]
 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 168099840/793579520 [00:31<00:44, 14198448.30it/s]
 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                  | 169607168/793579520 [00:31<00:43, 14291182.38it/s]
 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                  | 171048960/793579520 [00:31<00:43, 14288806.33it/s]
 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 172556288/793579520 [00:31<00:42, 14476216.47it/s]
 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 174063616/793579520 [00:31<00:42, 14478972.75it/s]
 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 175538176/793579520 [00:31<00:44, 14009018.28it/s]
 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 176947200/793579520 [00:31<00:47, 12851662.62it/s]
 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 178257920/793579520 [00:31<00:50, 12080740.90it/s]
 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 179503104/793579520 [00:32<00:53, 11577895.41it/s]
 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 180682752/793579520 [00:32<00:54, 11332464.19it/s]
 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 181829632/793579520 [00:32<00:54, 11162697.00it/s]
 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 183009280/793579520 [00:32<00:53, 11314334.41it/s]
 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 184156160/793579520 [00:32<00:53, 11300906.04it/s]
 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 185303040/793579520 [00:32<00:54, 11153811.86it/s]
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 186515456/793579520 [00:32<00:54, 11165446.81it/s]
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 187727872/793579520 [00:32<00:53, 11413046.60it/s]
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 188940288/793579520 [00:32<00:52, 11518885.24it/s]
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 190119936/793579520 [00:33<00:52, 11503942.09it/s]
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 191332352/793579520 [00:33<00:52, 11558602.88it/s]
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 192544768/793579520 [00:33<00:51, 11624414.06it/s]
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 193757184/793579520 [00:33<00:51, 11755124.12it/s]
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                 | 194936832/793579520 [00:33<00:51, 11522047.53it/s]
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                 | 196182016/793579520 [00:33<00:51, 11710922.27it/s]
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                 | 197427200/793579520 [00:33<00:50, 11906403.85it/s]
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 198639616/793579520 [00:33<00:50, 11858244.75it/s]
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 199852032/793579520 [00:33<00:50, 11677167.70it/s]
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 201031680/793579520 [00:33<00:54, 10948232.99it/s]
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 202145792/793579520 [00:34<00:57, 10211824.15it/s]
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 203194368/793579520 [00:34<00:59, 9911429.45it/s]
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 204210176/793579520 [00:34<01:01, 9621342.09it/s]
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 205193216/793579520 [00:34<01:01, 9513312.18it/s]
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 206176256/793579520 [00:34<01:01, 9474510.55it/s]
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 207126528/793579520 [00:34<01:02, 9389552.34it/s]
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 208076800/793579520 [00:34<01:03, 9290724.55it/s]
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 209092608/793579520 [00:34<01:01, 9475302.83it/s]
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 210141184/793579520 [00:34<01:00, 9599741.19it/s]
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 211124224/793579520 [00:35<01:00, 9651727.52it/s]
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 212107264/793579520 [00:35<01:00, 9550634.93it/s]
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 213123072/793579520 [00:35<01:00, 9585536.09it/s]
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 214138880/793579520 [00:35<00:59, 9734097.33it/s]
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 215154688/793579520 [00:35<00:58, 9804598.79it/s]
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 216170496/793579520 [00:35<00:58, 9839318.92it/s]
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 217251840/793579520 [00:35<00:57, 10019234.10it/s]
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 218300416/793579520 [00:35<00:56, 10129457.96it/s]
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                 | 219316224/793579520 [00:35<00:57, 9960881.09it/s]
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 220364800/793579520 [00:36<00:56, 10077681.06it/s]
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 221446144/793579520 [00:36<00:56, 10159146.91it/s]
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 222494720/793579520 [00:36<00:56, 10186627.02it/s]
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 223543296/793579520 [00:36<00:56, 10091650.90it/s]
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 224591872/793579520 [00:36<00:56, 10056548.72it/s]
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 225673216/793579520 [00:36<00:56, 10125171.06it/s]
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 226689024/793579520 [00:36<01:30, 6246825.04it/s]
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 227704832/793579520 [00:36<01:20, 6999078.68it/s]
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 228786176/793579520 [00:37<01:12, 7770200.05it/s]
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 229867520/793579520 [00:37<01:06, 8432460.12it/s]
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 230850560/793579520 [00:37<01:04, 8783833.17it/s]
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 231899136/793579520 [00:37<01:01, 9160383.16it/s]
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 232980480/793579520 [00:37<00:59, 9500892.39it/s]
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 234029056/793579520 [00:37<00:57, 9756537.19it/s]
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                 | 235044864/793579520 [00:37<00:57, 9738256.79it/s]
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 236060672/793579520 [00:37<01:03, 8746619.09it/s]
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 236978176/793579520 [00:38<01:31, 6111517.13it/s]
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 238026752/793579520 [00:38<01:19, 7002394.96it/s]
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 239009792/793579520 [00:38<01:12, 7642102.87it/s]
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 239894528/793579520 [00:38<01:19, 7005715.81it/s]
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 240910336/793579520 [00:38<01:12, 7659559.74it/s]
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 241991680/793579520 [00:38<01:05, 8367533.90it/s]
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 242909184/793579520 [00:38<01:17, 7131040.41it/s]
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 243695616/793579520 [00:39<01:31, 6039233.38it/s]
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 244711424/793579520 [00:39<01:19, 6870973.53it/s]
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 245792768/793579520 [00:39<01:11, 7700976.01it/s]
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 246874112/793579520 [00:39<01:04, 8463874.02it/s]
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 247889920/793579520 [00:39<01:01, 8908545.16it/s]
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 248905728/793579520 [00:39<00:59, 9101028.80it/s]
 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 249987072/793579520 [00:39<00:57, 9528480.08it/s]
 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 251035648/793579520 [00:39<00:55, 9773188.55it/s]
 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 252051456/793579520 [00:39<00:55, 9764011.92it/s]
 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                | 253100032/793579520 [00:39<00:54, 9897298.05it/s]
 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 254181376/793579520 [00:40<00:53, 10037308.48it/s]
 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 255229952/793579520 [00:40<00:52, 10163616.54it/s]
 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 256278528/793579520 [00:40<00:52, 10219980.06it/s]
 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 257359872/793579520 [00:40<00:51, 10361435.83it/s]
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 258408448/793579520 [00:40<00:52, 10246460.19it/s]
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ               | 259555328/793579520 [00:40<00:50, 10522398.90it/s]
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ               | 260669440/793579520 [00:40<00:50, 10569926.70it/s]
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 261750784/793579520 [00:40<01:08, 7812476.03it/s]
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 262799360/793579520 [00:40<01:03, 8355812.82it/s]
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 263946240/793579520 [00:41<00:58, 9118954.27it/s]
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 265060352/793579520 [00:41<00:55, 9603601.18it/s]
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 266108928/793579520 [00:41<00:54, 9728203.68it/s]
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 267190272/793579520 [00:41<00:52, 10026084.27it/s]
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 268271616/793579520 [00:41<00:51, 10187490.37it/s]
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 269418496/793579520 [00:41<00:49, 10499388.36it/s]
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 270565376/793579520 [00:41<00:48, 10703958.59it/s]
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 271712256/793579520 [00:41<00:48, 10777088.16it/s]
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 272891904/793579520 [00:41<00:47, 11046260.41it/s]
 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 274006016/793579520 [00:42<00:47, 10918538.60it/s]
 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 275120128/793579520 [00:42<00:52, 9818358.05it/s]
 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 276135936/793579520 [00:42<01:41, 5120306.19it/s]
 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 277217280/793579520 [00:42<01:26, 5998230.86it/s]
 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 278495232/793579520 [00:42<01:11, 7196825.79it/s]
 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 279805952/793579520 [00:42<01:01, 8324227.45it/s]
 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ               | 281116672/793579520 [00:43<00:54, 9337651.85it/s]
 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 282427392/793579520 [00:43<00:50, 10175976.42it/s]
 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 283672576/793579520 [00:43<00:47, 10734803.87it/s]
 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 284950528/793579520 [00:43<00:45, 11247027.10it/s]
 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 286294016/793579520 [00:43<00:42, 11821437.79it/s]
 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 287637504/793579520 [00:43<00:41, 12240729.90it/s]
 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 288915456/793579520 [00:43<00:40, 12374358.96it/s]
 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 290324480/793579520 [00:43<00:39, 12786783.26it/s]
 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 291635200/793579520 [00:43<00:53, 9305094.03it/s]
 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 293011456/793579520 [00:44<00:48, 10312645.18it/s]
 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 294420480/793579520 [00:44<00:44, 11233695.42it/s]
 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 295895040/793579520 [00:44<00:41, 12127113.42it/s]
 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 297336832/793579520 [00:44<00:38, 12747850.08it/s]
 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹              | 298876928/793579520 [00:44<00:37, 13292352.60it/s]
 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 300285952/793579520 [00:44<01:11, 6881636.25it/s]
 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 301367296/793579520 [00:45<01:06, 7433954.21it/s]
 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 302809088/793579520 [00:45<00:56, 8700389.98it/s]
 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 304513024/793579520 [00:45<00:47, 10392413.09it/s]
 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 306216960/793579520 [00:45<00:41, 11850480.68it/s]
 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰              | 307953664/793579520 [00:45<00:36, 13216742.92it/s]
 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 309460992/793579520 [00:46<02:01, 4000819.11it/s]
 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 310575104/793579520 [00:46<01:49, 4427168.54it/s]
 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 311590912/793579520 [00:46<01:34, 5080060.67it/s]
 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 312573952/793579520 [00:46<01:40, 4775771.94it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 313950208/793579520 [00:47<01:19, 6057337.34it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 315686912/793579520 [00:47<01:00, 7922979.69it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 317784064/793579520 [00:47<00:45, 10419443.26it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 319848448/793579520 [00:47<00:37, 12610489.15it/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 321880064/793579520 [00:47<00:32, 14382400.07it/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 324108288/793579520 [00:47<00:28, 16327851.85it/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 326303744/793579520 [00:47<00:26, 17757533.95it/s]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 328466432/793579520 [00:47<00:24, 18798546.09it/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 330858496/793579520 [00:47<00:22, 20205067.36it/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹             | 333185024/793579520 [00:47<00:21, 21020543.32it/s]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹             | 335544320/793579520 [00:48<00:21, 21625263.38it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 338100224/793579520 [00:48<00:20, 22682854.55it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 340426752/793579520 [00:48<00:21, 20779788.36it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 342589440/793579520 [00:48<00:22, 19758067.61it/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 344621056/793579520 [00:48<00:23, 19150996.74it/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 346587136/793579520 [00:48<00:23, 18932581.67it/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 348520448/793579520 [00:48<00:23, 18696111.83it/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 350486528/793579520 [00:48<00:23, 18806013.75it/s]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 352485376/793579520 [00:48<00:23, 19129696.81it/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 354418688/793579520 [00:49<00:23, 19091073.55it/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 356352000/793579520 [00:49<00:22, 19137532.68it/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 358449152/793579520 [00:49<00:22, 19652351.58it/s]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 360448000/793579520 [00:49<00:22, 19648109.98it/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 362446848/793579520 [00:49<00:26, 16464425.34it/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 364544000/793579520 [00:49<00:24, 17610914.65it/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 366575616/793579520 [00:49<00:23, 18285582.90it/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 368705536/793579520 [00:49<00:22, 19097821.42it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 370900992/793579520 [00:49<00:21, 19802082.74it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 373096448/793579520 [00:50<00:20, 20354802.19it/s]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 375324672/793579520 [00:50<00:20, 20789023.16it/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 377520128/793579520 [00:50<00:19, 21116954.46it/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 379650048/793579520 [00:50<00:23, 17784170.66it/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 381911040/793579520 [00:50<00:21, 18914646.92it/s]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 384139264/793579520 [00:50<00:20, 19762310.50it/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 386367488/793579520 [00:50<00:20, 20341978.29it/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 388628480/793579520 [00:50<00:19, 20920804.08it/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 390922240/793579520 [00:50<00:18, 21491383.53it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 393216000/793579520 [00:51<00:18, 21857695.35it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 395575296/793579520 [00:51<00:17, 22295164.76it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 397967360/793579520 [00:51<00:17, 22661932.90it/s]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 400293888/793579520 [00:51<00:17, 22803291.00it/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 402587648/793579520 [00:51<00:27, 14187456.49it/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 404946944/793579520 [00:51<00:24, 16133436.73it/s]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 407109632/793579520 [00:51<00:22, 17291594.12it/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 409141248/793579520 [00:52<00:30, 12430535.86it/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 411467776/793579520 [00:52<00:26, 14530902.47it/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 413827072/793579520 [00:52<00:23, 16498095.36it/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 416153600/793579520 [00:52<00:20, 18101280.96it/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 418250752/793579520 [00:52<00:30, 12470301.18it/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 419987456/793579520 [00:52<00:28, 13298369.09it/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 421822464/793579520 [00:52<00:25, 14322282.32it/s]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 423559168/793579520 [00:53<00:24, 15030137.98it/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 425328640/793579520 [00:53<00:23, 15552946.47it/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 427196416/793579520 [00:53<00:22, 16190297.32it/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 428965888/793579520 [00:53<00:27, 13338199.72it/s]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 430833664/793579520 [00:53<00:24, 14534876.48it/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 432701440/793579520 [00:53<00:23, 15538612.10it/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 434569216/793579520 [00:53<00:21, 16364860.90it/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 436469760/793579520 [00:53<00:20, 17026142.05it/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 438304768/793579520 [00:53<00:20, 17373527.64it/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 440270848/793579520 [00:54<00:19, 17902348.40it/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 442204160/793579520 [00:54<00:19, 18313917.94it/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 444071936/793579520 [00:54<00:19, 18354193.86it/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰          | 446038016/793579520 [00:54<00:18, 18638537.29it/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰          | 447971328/793579520 [00:54<00:18, 18818033.16it/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 449871872/793579520 [00:54<00:23, 14766307.46it/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 451706880/793579520 [00:54<00:21, 15632239.25it/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 453672960/793579520 [00:54<00:20, 16615150.97it/s]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 455606272/793579520 [00:54<00:19, 17331917.51it/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 457572352/793579520 [00:55<00:18, 17950181.36it/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 459669504/793579520 [00:55<00:17, 18668457.81it/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 461701120/793579520 [00:55<00:17, 19021324.08it/s]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 463699968/793579520 [00:55<00:17, 19269598.06it/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 465764352/793579520 [00:55<00:16, 19520272.96it/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 467795968/793579520 [00:55<00:16, 19707469.98it/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 469794816/793579520 [00:55<00:21, 14965245.54it/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 471498752/793579520 [00:55<00:23, 13578719.81it/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 473530368/793579520 [00:56<00:21, 15079032.19it/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 475594752/793579520 [00:56<00:19, 16428760.44it/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 477691904/793579520 [00:56<00:17, 17580021.66it/s]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 479690752/793579520 [00:56<00:17, 18165725.70it/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 481787904/793579520 [00:56<00:16, 18836087.84it/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 483852288/793579520 [00:56<00:16, 19341147.30it/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 485883904/793579520 [00:56<00:15, 19514479.31it/s]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 487981056/793579520 [00:56<00:15, 19926032.25it/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 490012672/793579520 [00:56<00:15, 19952580.77it/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 492077056/793579520 [00:56<00:15, 20084024.73it/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 494174208/793579520 [00:57<00:14, 20305161.82it/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 496238592/793579520 [00:57<00:14, 20266964.05it/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 498302976/793579520 [00:57<00:14, 20229162.96it/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 500367360/793579520 [00:57<00:14, 20348078.61it/s]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 502431744/793579520 [00:57<00:14, 20301162.53it/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 504496128/793579520 [00:57<00:14, 20308963.89it/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 506593280/793579520 [00:57<00:14, 20243334.20it/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 508690432/793579520 [00:57<00:13, 20364944.98it/s]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 510754816/793579520 [00:57<00:13, 20363008.39it/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 512819200/793579520 [00:57<00:13, 20301179.62it/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 514916352/793579520 [00:58<00:13, 20404691.85it/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 516980736/793579520 [00:58<00:13, 20409431.55it/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 519045120/793579520 [00:58<00:13, 20237380.75it/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 521142272/793579520 [00:58<00:13, 20388016.28it/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 523206656/793579520 [00:58<00:13, 20440582.37it/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 525271040/793579520 [00:58<00:16, 16496953.73it/s]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 527073280/793579520 [00:58<00:22, 11896489.32it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 529170432/793579520 [00:59<00:19, 13630139.23it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 531267584/793579520 [00:59<00:20, 13026400.49it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 533397504/793579520 [00:59<00:17, 14710886.42it/s]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 535429120/793579520 [00:59<00:16, 15988305.06it/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 537460736/793579520 [00:59<00:15, 16907671.48it/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 539295744/793579520 [00:59<00:17, 14885130.23it/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 541360128/793579520 [00:59<00:15, 16231893.76it/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 543457280/793579520 [00:59<00:14, 17350816.82it/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 545521664/793579520 [00:59<00:13, 18174225.20it/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 547553280/793579520 [01:00<00:13, 18753424.81it/s]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 549650432/793579520 [01:00<00:12, 19316544.63it/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 551682048/793579520 [01:00<00:12, 19597333.01it/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 553746432/793579520 [01:00<00:12, 19780678.51it/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 555810816/793579520 [01:00<00:11, 20029928.18it/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 557842432/793579520 [01:00<00:12, 18645880.31it/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 559742976/793579520 [01:00<00:13, 17089877.36it/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 561512448/793579520 [01:00<00:14, 16367603.18it/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 563183616/793579520 [01:00<00:15, 14425378.67it/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 564690944/793579520 [01:01<00:15, 14429032.25it/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 566263808/793579520 [01:01<00:15, 14673400.12it/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 567836672/793579520 [01:01<00:15, 14914794.02it/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 569376768/793579520 [01:01<00:15, 14921627.90it/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 570982400/793579520 [01:01<00:14, 15129043.65it/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 572588032/793579520 [01:01<00:14, 15340568.65it/s]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 574160896/793579520 [01:01<00:14, 15392685.06it/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 575733760/793579520 [01:01<00:14, 15343869.45it/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 577404928/793579520 [01:01<00:13, 15622013.22it/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 578977792/793579520 [01:02<00:15, 14126782.89it/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 580648960/793579520 [01:02<00:14, 14745189.24it/s]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 582221824/793579520 [01:02<00:14, 14995699.87it/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 583860224/793579520 [01:02<00:13, 15350950.33it/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 585531392/793579520 [01:02<00:13, 15739713.16it/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 587137024/793579520 [01:02<00:15, 13231518.47it/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 588808192/793579520 [01:02<00:14, 14110372.42it/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 590381056/793579520 [01:02<00:14, 14462880.00it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 592084992/793579520 [01:02<00:13, 15079477.28it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 593854464/793579520 [01:03<00:12, 15673507.50it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 595525632/793579520 [01:03<00:12, 15909200.50it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 597164032/793579520 [01:03<00:18, 10593458.58it/s]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 598933504/793579520 [01:03<00:16, 11939124.86it/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 600735744/793579520 [01:03<00:14, 13263469.28it/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 602472448/793579520 [01:03<00:13, 14197881.40it/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 604045312/793579520 [01:03<00:13, 14177869.37it/s]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 605683712/793579520 [01:03<00:12, 14759170.23it/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 607420416/793579520 [01:04<00:12, 15436955.52it/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 609124352/793579520 [01:04<00:11, 15840525.46it/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 610795520/793579520 [01:04<00:11, 16077239.22it/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 612499456/793579520 [01:04<00:11, 16273065.82it/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 614203392/793579520 [01:04<00:10, 16322755.82it/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 615972864/793579520 [01:04<00:10, 16695244.65it/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 617676800/793579520 [01:04<00:10, 16787240.47it/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 619380736/793579520 [01:04<00:10, 16716220.18it/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 621084672/793579520 [01:04<00:11, 14790814.64it/s]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 622788608/793579520 [01:04<00:11, 15368509.49it/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 624558080/793579520 [01:05<00:10, 15967765.28it/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 626229248/793579520 [01:05<00:10, 16087583.57it/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 627965952/793579520 [01:05<00:10, 16333191.13it/s]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 629735424/793579520 [01:05<00:09, 16694985.07it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 631439360/793579520 [01:05<00:09, 16695148.99it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 633143296/793579520 [01:05<00:09, 16670159.78it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 634912768/793579520 [01:05<00:09, 16886328.08it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 636616704/793579520 [01:05<00:09, 16926409.91it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 638320640/793579520 [01:05<00:11, 13530842.88it/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 639795200/793579520 [01:06<00:15, 9629352.00it/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 641302528/793579520 [01:06<00:19, 7971894.92it/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 643104768/793579520 [01:06<00:15, 9726119.46it/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 644743168/793579520 [01:06<00:13, 11054456.75it/s]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 646479872/793579520 [01:06<00:11, 12411111.98it/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 648216576/793579520 [01:06<00:10, 13579722.48it/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 649756672/793579520 [01:07<00:19, 7534610.11it/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 651395072/793579520 [01:07<00:15, 8954255.14it/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 653197312/793579520 [01:07<00:13, 10561659.55it/s]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 654639104/793579520 [01:07<00:15, 8738989.76it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 656310272/793579520 [01:07<00:13, 10230957.41it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 658079744/793579520 [01:08<00:11, 11673879.49it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 659849216/793579520 [01:08<00:10, 13055788.35it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 661389312/793579520 [01:08<00:15, 8687413.96it/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 662601728/793579520 [01:08<00:16, 7785993.28it/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 664109056/793579520 [01:08<00:14, 8682473.21it/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 665911296/793579520 [01:08<00:12, 10512204.49it/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 667582464/793579520 [01:09<00:10, 11859470.49it/s]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 669351936/793579520 [01:09<00:09, 13151999.38it/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 671186944/793579520 [01:09<00:08, 14369550.88it/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 672858112/793579520 [01:09<00:08, 14341158.46it/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 674398208/793579520 [01:09<00:09, 12652907.45it/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 675774464/793579520 [01:09<00:10, 11399472.09it/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 677019648/793579520 [01:09<00:13, 8591210.68it/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 678035456/793579520 [01:09<00:13, 8773633.95it/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 679051264/793579520 [01:10<00:12, 8900501.12it/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 680034304/793579520 [01:10<00:12, 8977688.20it/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 681017344/793579520 [01:10<00:12, 9081076.09it/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 682033152/793579520 [01:10<00:11, 9351344.03it/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 683048960/793579520 [01:10<00:11, 9503102.49it/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 684032000/793579520 [01:10<00:11, 9523572.00it/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 685015040/793579520 [01:10<00:11, 9539192.42it/s]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 686030848/793579520 [01:10<00:11, 9668397.57it/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 687046656/793579520 [01:10<00:10, 9764353.62it/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 688062464/793579520 [01:11<00:10, 9783736.59it/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 689078272/793579520 [01:11<00:10, 9876626.81it/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 690159616/793579520 [01:11<00:10, 10044702.97it/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 691208192/793579520 [01:11<00:10, 10170149.19it/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 692256768/793579520 [01:11<00:10, 10061806.27it/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 693305344/793579520 [01:11<00:09, 10082747.48it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 694386688/793579520 [01:11<00:09, 10153743.02it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 695468032/793579520 [01:11<00:09, 10222627.28it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 696516608/793579520 [01:11<00:09, 10294179.78it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 697565184/793579520 [01:12<00:15, 6391011.64it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 698417152/793579520 [01:12<00:25, 3660343.19it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 699236352/793579520 [01:12<00:22, 4254573.23it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 700284928/793579520 [01:12<00:18, 5141340.62it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 701038592/793579520 [01:13<00:19, 4736559.20it/s]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 702152704/793579520 [01:13<00:15, 5874841.05it/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 703234048/793579520 [01:13<00:13, 6838883.12it/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 704217088/793579520 [01:13<00:11, 7507496.54it/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 705265664/793579520 [01:13<00:10, 8152778.36it/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 706347008/793579520 [01:13<00:09, 8769044.97it/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 707395584/793579520 [01:13<00:09, 9220817.98it/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 708411392/793579520 [01:13<00:09, 9366717.55it/s]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 709492736/793579520 [01:13<00:08, 9613899.02it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 710574080/793579520 [01:14<00:08, 9937317.65it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 711622656/793579520 [01:14<00:08, 9173650.64it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 712736768/793579520 [01:14<00:08, 9474900.47it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 713719808/793579520 [01:14<00:08, 9538793.75it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 714702848/793579520 [01:14<00:11, 6761402.66it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 715784192/793579520 [01:14<00:10, 7549313.94it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 716865536/793579520 [01:14<00:09, 8177095.01it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 717946880/793579520 [01:14<00:08, 8815040.64it/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 718929920/793579520 [01:15<00:08, 8959482.91it/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 720011264/793579520 [01:15<00:07, 9315531.20it/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 721092608/793579520 [01:15<00:07, 9633254.32it/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 722108416/793579520 [01:15<00:07, 9756082.71it/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 723124224/793579520 [01:15<00:07, 9748071.84it/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 724140032/793579520 [01:15<00:07, 9765093.34it/s]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 725155840/793579520 [01:15<00:07, 9448271.44it/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 726171648/793579520 [01:15<00:07, 9593889.10it/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 727252992/793579520 [01:15<00:06, 9885416.22it/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 728301568/793579520 [01:15<00:06, 10045260.39it/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 729350144/793579520 [01:16<00:06, 10146505.63it/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 730398720/793579520 [01:16<00:06, 10219184.04it/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 731447296/793579520 [01:16<00:06, 10238084.51it/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 732495872/793579520 [01:16<00:05, 10308704.58it/s]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 733544448/793579520 [01:16<00:06, 9871889.89it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 734560256/793579520 [01:16<00:06, 9660973.57it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 735641600/793579520 [01:16<00:05, 9860684.10it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 736821248/793579520 [01:16<00:05, 10195731.52it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 737968128/793579520 [01:16<00:05, 10531592.11it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 739082240/793579520 [01:17<00:05, 10640300.88it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 740163584/793579520 [01:17<00:05, 10630124.03it/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 741244928/793579520 [01:17<00:05, 9847598.60it/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 742260736/793579520 [01:17<00:05, 9243765.24it/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 743211008/793579520 [01:17<00:06, 7485543.47it/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 744030208/793579520 [01:17<00:08, 5926299.62it/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 744849408/793579520 [01:17<00:07, 6332532.40it/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 745799680/793579520 [01:18<00:06, 6934448.66it/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 746749952/793579520 [01:18<00:06, 7435473.94it/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 747732992/793579520 [01:18<00:05, 7944065.04it/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 748584960/793579520 [01:18<00:05, 7631957.18it/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 749404160/793579520 [01:18<00:06, 6980048.14it/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 750354432/793579520 [01:18<00:05, 7571989.03it/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 751370240/793579520 [01:18<00:05, 8236864.13it/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 752320512/793579520 [01:18<00:04, 8557038.25it/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 753303552/793579520 [01:18<00:04, 8912124.66it/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 754253824/793579520 [01:19<00:04, 8963496.32it/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 755302400/793579520 [01:19<00:04, 9346975.62it/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 756285440/793579520 [01:19<00:03, 9433685.49it/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 757366784/793579520 [01:19<00:03, 9834381.43it/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 758382592/793579520 [01:19<00:03, 9925971.29it/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 759398400/793579520 [01:19<00:03, 9933700.72it/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 760479744/793579520 [01:19<00:03, 10139767.67it/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 761528320/793579520 [01:19<00:03, 10215101.73it/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 762576896/793579520 [01:19<00:03, 9571214.26it/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 763691008/793579520 [01:19<00:03, 9807067.79it/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 764706816/793579520 [01:20<00:04, 6270002.48it/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 765788160/793579520 [01:20<00:03, 7143250.83it/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 766935040/793579520 [01:20<00:03, 7979512.50it/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 768114688/793579520 [01:20<00:02, 8720057.37it/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 769097728/793579520 [01:20<00:04, 5554044.27it/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 769884160/793579520 [01:21<00:04, 5864114.45it/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 770834432/793579520 [01:21<00:03, 6577602.04it/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 771981312/793579520 [01:21<00:02, 7549596.20it/s]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 773128192/793579520 [01:21<00:02, 8360829.06it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 774275072/793579520 [01:21<00:02, 9048265.57it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 775421952/793579520 [01:21<00:01, 9582054.31it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 776503296/793579520 [01:21<00:01, 9907079.85it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 777584640/793579520 [01:21<00:01, 10101797.38it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 778731520/793579520 [01:21<00:01, 10367243.74it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 779878400/793579520 [01:21<00:01, 10496967.11it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 780959744/793579520 [01:22<00:01, 10584302.43it/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 782073856/793579520 [01:22<00:01, 10649263.89it/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 783155200/793579520 [01:22<00:00, 10458615.14it/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 784236544/793579520 [01:22<00:00, 10438532.30it/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 785350656/793579520 [01:22<00:00, 10493595.72it/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 786497536/793579520 [01:22<00:00, 10642744.42it/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 787644416/793579520 [01:22<00:00, 10722000.51it/s]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 788725760/793579520 [01:22<00:00, 9196334.96it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 789741568/793579520 [01:22<00:00, 9388812.61it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 790888448/793579520 [01:23<00:00, 9835038.69it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 792068096/793579520 [01:23<00:00, 10103527.63it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 793247744/793579520 [01:23<00:00, 10340972.48it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 793579520/793579520 [01:23<00:00, 9527359.20it/s]
97.3s	229	Extracting 'images.tar' to './datasets/StanfordDogs'
101.8s	230	Downloading http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar to ./datasets/StanfordDogs/lists.tar
102.1s	231	
  0%|                                                | 0/481280 [00:00<?, ?it/s]
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 163840/481280 [00:00<00:00, 1545675.06it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 481280/481280 [00:00<00:00, 2352424.90it/s]
102.1s	232	Extracting 'lists.tar' to './datasets/StanfordDogs'
104.6s	233	Using downloaded and verified file: ./datasets/StanfordDogs/images.tar
104.6s	234	File 'images.tar' was already extracted, skipped extraction
104.6s	235	Using downloaded and verified file: ./datasets/StanfordDogs/lists.tar
104.6s	236	File 'lists.tar' was already extracted, skipped extraction
105.2s	237	Starting epoch 1/100, learning_rate=0.1
107.7s	238	[train]  epoch 1/100,  batch 1/188,  loss_train=4.92595,  acc_train=1.56%
113.4s	239	[train]  epoch 1/100,  batch 11/188,  loss_train=5.14912,  acc_train=1.56%
119.1s	240	[train]  epoch 1/100,  batch 21/188,  loss_train=5.09129,  acc_train=1.56%
124.7s	241	[train]  epoch 1/100,  batch 31/188,  loss_train=5.04242,  acc_train=3.12%
130.3s	242	[train]  epoch 1/100,  batch 41/188,  loss_train=4.89294,  acc_train=3.12%
136.0s	243	[train]  epoch 1/100,  batch 51/188,  loss_train=5.02200,  acc_train=1.56%
141.6s	244	[train]  epoch 1/100,  batch 61/188,  loss_train=4.96286,  acc_train=0.00%
147.2s	245	[train]  epoch 1/100,  batch 71/188,  loss_train=4.92827,  acc_train=3.12%
152.8s	246	[train]  epoch 1/100,  batch 81/188,  loss_train=4.89486,  acc_train=6.25%
158.4s	247	[train]  epoch 1/100,  batch 91/188,  loss_train=4.70240,  acc_train=3.12%
164.0s	248	[train]  epoch 1/100,  batch 101/188,  loss_train=4.63486,  acc_train=1.56%
169.7s	249	[train]  epoch 1/100,  batch 111/188,  loss_train=4.84533,  acc_train=4.69%
175.3s	250	[train]  epoch 1/100,  batch 121/188,  loss_train=4.59696,  acc_train=1.56%
180.9s	251	[train]  epoch 1/100,  batch 131/188,  loss_train=4.80395,  acc_train=1.56%
186.5s	252	[train]  epoch 1/100,  batch 141/188,  loss_train=4.73038,  acc_train=0.00%
192.1s	253	[train]  epoch 1/100,  batch 151/188,  loss_train=4.75467,  acc_train=1.56%
197.7s	254	[train]  epoch 1/100,  batch 161/188,  loss_train=4.69476,  acc_train=1.56%
203.4s	255	[train]  epoch 1/100,  batch 171/188,  loss_train=4.65238,  acc_train=1.56%
209.0s	256	[train]  epoch 1/100,  batch 181/188,  loss_train=4.46575,  acc_train=4.69%
213.6s	257	[ val ]  epoch 1/100,  batch 1/135,  loss_val=5.03720,  acc_val=0.00%
215.4s	258	[ val ]  epoch 1/100,  batch 11/135,  loss_val=4.80268,  acc_val=0.00%
217.1s	259	[ val ]  epoch 1/100,  batch 21/135,  loss_val=4.63281,  acc_val=1.56%
218.9s	260	[ val ]  epoch 1/100,  batch 31/135,  loss_val=4.72608,  acc_val=0.00%
220.7s	261	[ val ]  epoch 1/100,  batch 41/135,  loss_val=5.04479,  acc_val=0.00%
222.5s	262	[ val ]  epoch 1/100,  batch 51/135,  loss_val=4.27655,  acc_val=1.56%
224.3s	263	[ val ]  epoch 1/100,  batch 61/135,  loss_val=5.01482,  acc_val=0.00%
226.0s	264	[ val ]  epoch 1/100,  batch 71/135,  loss_val=5.01460,  acc_val=0.00%
227.8s	265	[ val ]  epoch 1/100,  batch 81/135,  loss_val=4.74831,  acc_val=0.00%
229.6s	266	[ val ]  epoch 1/100,  batch 91/135,  loss_val=4.49743,  acc_val=0.00%
231.5s	267	[ val ]  epoch 1/100,  batch 101/135,  loss_val=5.01788,  acc_val=0.00%
233.3s	268	[ val ]  epoch 1/100,  batch 111/135,  loss_val=4.79618,  acc_val=0.00%
235.1s	269	[ val ]  epoch 1/100,  batch 121/135,  loss_val=3.76534,  acc_val=31.25%
236.8s	270	[ val ]  epoch 1/100,  batch 131/135,  loss_val=4.87079,  acc_val=0.00%
237.4s	271	==============================================================================================================
237.4s	272	Epoch 1/100 summary: loss_train=4.86103, acc_train=1.54%, loss_val=4.63, acc_val=2.69% (best: 2.69% @ epoch 1)
237.4s	273	==============================================================================================================
237.4s	274	Starting epoch 2/100, learning_rate=0.1
238.7s	275	[train]  epoch 2/100,  batch 1/188,  loss_train=4.60395,  acc_train=1.56%
244.3s	276	[train]  epoch 2/100,  batch 11/188,  loss_train=4.66448,  acc_train=3.12%
249.9s	277	[train]  epoch 2/100,  batch 21/188,  loss_train=4.51699,  acc_train=4.69%
255.5s	278	[train]  epoch 2/100,  batch 31/188,  loss_train=4.57321,  acc_train=3.12%
261.1s	279	[train]  epoch 2/100,  batch 41/188,  loss_train=4.71722,  acc_train=1.56%
266.8s	280	[train]  epoch 2/100,  batch 51/188,  loss_train=4.59492,  acc_train=1.56%
272.4s	281	[train]  epoch 2/100,  batch 61/188,  loss_train=4.68294,  acc_train=1.56%
278.0s	282	[train]  epoch 2/100,  batch 71/188,  loss_train=4.57784,  acc_train=3.12%
283.6s	283	[train]  epoch 2/100,  batch 81/188,  loss_train=4.51099,  acc_train=1.56%
289.2s	284	[train]  epoch 2/100,  batch 91/188,  loss_train=4.47552,  acc_train=6.25%
294.9s	285	[train]  epoch 2/100,  batch 101/188,  loss_train=4.48468,  acc_train=0.00%
300.6s	286	[train]  epoch 2/100,  batch 111/188,  loss_train=4.64155,  acc_train=1.56%
306.2s	287	[train]  epoch 2/100,  batch 121/188,  loss_train=4.58110,  acc_train=3.12%
311.8s	288	[train]  epoch 2/100,  batch 131/188,  loss_train=4.53662,  acc_train=0.00%
317.4s	289	[train]  epoch 2/100,  batch 141/188,  loss_train=4.48514,  acc_train=4.69%
323.0s	290	[train]  epoch 2/100,  batch 151/188,  loss_train=4.62793,  acc_train=3.12%
328.6s	291	[train]  epoch 2/100,  batch 161/188,  loss_train=4.50193,  acc_train=6.25%
334.3s	292	[train]  epoch 2/100,  batch 171/188,  loss_train=4.63698,  acc_train=0.00%
339.8s	293	[train]  epoch 2/100,  batch 181/188,  loss_train=4.37055,  acc_train=0.00%
344.4s	294	[ val ]  epoch 2/100,  batch 1/135,  loss_val=5.24256,  acc_val=0.00%
346.2s	295	[ val ]  epoch 2/100,  batch 11/135,  loss_val=4.45589,  acc_val=0.00%
348.0s	296	[ val ]  epoch 2/100,  batch 21/135,  loss_val=4.62405,  acc_val=0.00%
349.8s	297	[ val ]  epoch 2/100,  batch 31/135,  loss_val=4.43321,  acc_val=0.00%
351.5s	298	[ val ]  epoch 2/100,  batch 41/135,  loss_val=4.06189,  acc_val=6.25%
353.3s	299	[ val ]  epoch 2/100,  batch 51/135,  loss_val=4.13782,  acc_val=15.62%
355.1s	300	[ val ]  epoch 2/100,  batch 61/135,  loss_val=4.75234,  acc_val=0.00%
356.9s	301	[ val ]  epoch 2/100,  batch 71/135,  loss_val=4.72097,  acc_val=0.00%
358.7s	302	[ val ]  epoch 2/100,  batch 81/135,  loss_val=4.36624,  acc_val=4.69%
360.5s	303	[ val ]  epoch 2/100,  batch 91/135,  loss_val=4.87064,  acc_val=0.00%
362.3s	304	[ val ]  epoch 2/100,  batch 101/135,  loss_val=4.45597,  acc_val=0.00%
364.1s	305	[ val ]  epoch 2/100,  batch 111/135,  loss_val=4.95306,  acc_val=0.00%
365.9s	306	[ val ]  epoch 2/100,  batch 121/135,  loss_val=3.24250,  acc_val=32.81%
367.6s	307	[ val ]  epoch 2/100,  batch 131/135,  loss_val=5.18433,  acc_val=0.00%
368.2s	308	==============================================================================================================
368.2s	309	Epoch 2/100 summary: loss_train=4.58499, acc_train=2.48%, loss_val=4.50, acc_val=3.34% (best: 3.34% @ epoch 2)
368.2s	310	==============================================================================================================
368.2s	311	Starting epoch 3/100, learning_rate=0.1
369.5s	312	[train]  epoch 3/100,  batch 1/188,  loss_train=4.70286,  acc_train=0.00%
375.1s	313	[train]  epoch 3/100,  batch 11/188,  loss_train=4.45857,  acc_train=1.56%
380.7s	314	[train]  epoch 3/100,  batch 21/188,  loss_train=4.61607,  acc_train=1.56%
386.3s	315	[train]  epoch 3/100,  batch 31/188,  loss_train=4.43504,  acc_train=1.56%
392.0s	316	[train]  epoch 3/100,  batch 41/188,  loss_train=4.55345,  acc_train=3.12%
397.7s	317	[train]  epoch 3/100,  batch 51/188,  loss_train=4.59708,  acc_train=3.12%
403.3s	318	[train]  epoch 3/100,  batch 61/188,  loss_train=4.46762,  acc_train=1.56%
408.9s	319	[train]  epoch 3/100,  batch 71/188,  loss_train=4.58993,  acc_train=4.69%
414.5s	320	[train]  epoch 3/100,  batch 81/188,  loss_train=4.31007,  acc_train=12.50%
420.1s	321	[train]  epoch 3/100,  batch 91/188,  loss_train=4.51008,  acc_train=4.69%
425.7s	322	[train]  epoch 3/100,  batch 101/188,  loss_train=4.43948,  acc_train=3.12%
431.5s	323	[train]  epoch 3/100,  batch 111/188,  loss_train=4.44563,  acc_train=4.69%
437.0s	324	[train]  epoch 3/100,  batch 121/188,  loss_train=4.29613,  acc_train=4.69%
442.6s	325	[train]  epoch 3/100,  batch 131/188,  loss_train=4.35162,  acc_train=0.00%
448.3s	326	[train]  epoch 3/100,  batch 141/188,  loss_train=4.61520,  acc_train=3.12%
453.9s	327	[train]  epoch 3/100,  batch 151/188,  loss_train=4.51847,  acc_train=4.69%
459.5s	328	[train]  epoch 3/100,  batch 161/188,  loss_train=4.56482,  acc_train=4.69%
465.2s	329	[train]  epoch 3/100,  batch 171/188,  loss_train=4.35076,  acc_train=6.25%
470.8s	330	[train]  epoch 3/100,  batch 181/188,  loss_train=4.24499,  acc_train=4.69%
475.4s	331	[ val ]  epoch 3/100,  batch 1/135,  loss_val=4.30620,  acc_val=0.00%
477.2s	332	[ val ]  epoch 3/100,  batch 11/135,  loss_val=4.44276,  acc_val=0.00%
479.0s	333	[ val ]  epoch 3/100,  batch 21/135,  loss_val=4.65610,  acc_val=0.00%
480.8s	334	[ val ]  epoch 3/100,  batch 31/135,  loss_val=4.85385,  acc_val=0.00%
482.6s	335	[ val ]  epoch 3/100,  batch 41/135,  loss_val=4.33133,  acc_val=0.00%
484.3s	336	[ val ]  epoch 3/100,  batch 51/135,  loss_val=3.56715,  acc_val=25.00%
486.2s	337	[ val ]  epoch 3/100,  batch 61/135,  loss_val=4.85531,  acc_val=0.00%
488.0s	338	[ val ]  epoch 3/100,  batch 71/135,  loss_val=5.21156,  acc_val=0.00%
489.8s	339	[ val ]  epoch 3/100,  batch 81/135,  loss_val=4.30476,  acc_val=4.69%
491.6s	340	[ val ]  epoch 3/100,  batch 91/135,  loss_val=4.19090,  acc_val=10.94%
493.4s	341	[ val ]  epoch 3/100,  batch 101/135,  loss_val=4.37243,  acc_val=3.12%
495.2s	342	[ val ]  epoch 3/100,  batch 111/135,  loss_val=4.19399,  acc_val=0.00%
496.9s	343	[ val ]  epoch 3/100,  batch 121/135,  loss_val=3.47534,  acc_val=23.44%
498.7s	344	[ val ]  epoch 3/100,  batch 131/135,  loss_val=4.41419,  acc_val=3.12%
499.3s	345	==============================================================================================================
499.3s	346	Epoch 3/100 summary: loss_train=4.45662, acc_train=3.64%, loss_val=4.38, acc_val=4.93% (best: 4.93% @ epoch 3)
499.3s	347	==============================================================================================================
499.3s	348	Starting epoch 4/100, learning_rate=0.1
500.6s	349	[train]  epoch 4/100,  batch 1/188,  loss_train=4.38748,  acc_train=3.12%
506.2s	350	[train]  epoch 4/100,  batch 11/188,  loss_train=4.52484,  acc_train=1.56%
511.9s	351	[train]  epoch 4/100,  batch 21/188,  loss_train=4.34324,  acc_train=1.56%
517.5s	352	[train]  epoch 4/100,  batch 31/188,  loss_train=4.40323,  acc_train=1.56%
523.1s	353	[train]  epoch 4/100,  batch 41/188,  loss_train=4.55019,  acc_train=4.69%
528.8s	354	[train]  epoch 4/100,  batch 51/188,  loss_train=4.40183,  acc_train=3.12%
534.4s	355	[train]  epoch 4/100,  batch 61/188,  loss_train=4.37533,  acc_train=1.56%
540.0s	356	[train]  epoch 4/100,  batch 71/188,  loss_train=4.48642,  acc_train=1.56%
545.6s	357	[train]  epoch 4/100,  batch 81/188,  loss_train=4.22412,  acc_train=7.81%
551.3s	358	[train]  epoch 4/100,  batch 91/188,  loss_train=4.29812,  acc_train=7.81%
556.9s	359	[train]  epoch 4/100,  batch 101/188,  loss_train=4.28516,  acc_train=6.25%
562.5s	360	[train]  epoch 4/100,  batch 111/188,  loss_train=4.04021,  acc_train=6.25%
568.1s	361	[train]  epoch 4/100,  batch 121/188,  loss_train=4.34757,  acc_train=4.69%
573.7s	362	[train]  epoch 4/100,  batch 131/188,  loss_train=4.19815,  acc_train=9.38%
579.3s	363	[train]  epoch 4/100,  batch 141/188,  loss_train=4.25382,  acc_train=6.25%
585.0s	364	[train]  epoch 4/100,  batch 151/188,  loss_train=4.32624,  acc_train=3.12%
590.6s	365	[train]  epoch 4/100,  batch 161/188,  loss_train=4.10773,  acc_train=7.81%
596.3s	366	[train]  epoch 4/100,  batch 171/188,  loss_train=4.15572,  acc_train=6.25%
601.8s	367	[train]  epoch 4/100,  batch 181/188,  loss_train=3.87356,  acc_train=15.62%
606.4s	368	[ val ]  epoch 4/100,  batch 1/135,  loss_val=5.09698,  acc_val=0.00%
608.2s	369	[ val ]  epoch 4/100,  batch 11/135,  loss_val=4.93276,  acc_val=0.00%
609.9s	370	[ val ]  epoch 4/100,  batch 21/135,  loss_val=3.48784,  acc_val=17.19%
611.7s	371	[ val ]  epoch 4/100,  batch 31/135,  loss_val=5.98507,  acc_val=0.00%
613.6s	372	[ val ]  epoch 4/100,  batch 41/135,  loss_val=4.83520,  acc_val=0.00%
615.4s	373	[ val ]  epoch 4/100,  batch 51/135,  loss_val=4.08902,  acc_val=18.75%
617.2s	374	[ val ]  epoch 4/100,  batch 61/135,  loss_val=5.27017,  acc_val=0.00%
618.9s	375	[ val ]  epoch 4/100,  batch 71/135,  loss_val=5.03780,  acc_val=0.00%
620.7s	376	[ val ]  epoch 4/100,  batch 81/135,  loss_val=4.85611,  acc_val=0.00%
622.5s	377	[ val ]  epoch 4/100,  batch 91/135,  loss_val=4.36150,  acc_val=1.56%
624.3s	378	[ val ]  epoch 4/100,  batch 101/135,  loss_val=2.86127,  acc_val=20.31%
626.1s	379	[ val ]  epoch 4/100,  batch 111/135,  loss_val=4.14141,  acc_val=0.00%
627.9s	380	[ val ]  epoch 4/100,  batch 121/135,  loss_val=4.20073,  acc_val=12.50%
629.6s	381	[ val ]  epoch 4/100,  batch 131/135,  loss_val=5.09692,  acc_val=0.00%
630.2s	382	==============================================================================================================
630.2s	383	Epoch 4/100 summary: loss_train=4.29518, acc_train=5.16%, loss_val=4.41, acc_val=5.12% (best: 5.12% @ epoch 4)
630.2s	384	==============================================================================================================
630.2s	385	Starting epoch 5/100, learning_rate=0.1
631.5s	386	[train]  epoch 5/100,  batch 1/188,  loss_train=4.17754,  acc_train=7.81%
637.1s	387	[train]  epoch 5/100,  batch 11/188,  loss_train=4.06709,  acc_train=4.69%
642.8s	388	[train]  epoch 5/100,  batch 21/188,  loss_train=4.27232,  acc_train=7.81%
648.4s	389	[train]  epoch 5/100,  batch 31/188,  loss_train=4.13791,  acc_train=3.12%
654.0s	390	[train]  epoch 5/100,  batch 41/188,  loss_train=4.12089,  acc_train=6.25%
659.7s	391	[train]  epoch 5/100,  batch 51/188,  loss_train=4.09201,  acc_train=3.12%
665.3s	392	[train]  epoch 5/100,  batch 61/188,  loss_train=4.13197,  acc_train=10.94%
670.9s	393	[train]  epoch 5/100,  batch 71/188,  loss_train=3.96708,  acc_train=12.50%
676.5s	394	[train]  epoch 5/100,  batch 81/188,  loss_train=4.13392,  acc_train=6.25%
682.2s	395	[train]  epoch 5/100,  batch 91/188,  loss_train=4.01647,  acc_train=9.38%
687.8s	396	[train]  epoch 5/100,  batch 101/188,  loss_train=4.19251,  acc_train=9.38%
693.5s	397	[train]  epoch 5/100,  batch 111/188,  loss_train=3.84015,  acc_train=9.38%
699.0s	398	[train]  epoch 5/100,  batch 121/188,  loss_train=4.08970,  acc_train=3.12%
704.7s	399	[train]  epoch 5/100,  batch 131/188,  loss_train=4.04206,  acc_train=6.25%
710.3s	400	[train]  epoch 5/100,  batch 141/188,  loss_train=4.01420,  acc_train=6.25%
715.9s	401	[train]  epoch 5/100,  batch 151/188,  loss_train=4.31452,  acc_train=6.25%
721.5s	402	[train]  epoch 5/100,  batch 161/188,  loss_train=4.05609,  acc_train=6.25%
727.2s	403	[train]  epoch 5/100,  batch 171/188,  loss_train=4.28957,  acc_train=6.25%
732.8s	404	[train]  epoch 5/100,  batch 181/188,  loss_train=3.90754,  acc_train=10.94%
737.4s	405	[ val ]  epoch 5/100,  batch 1/135,  loss_val=4.36350,  acc_val=3.12%
739.2s	406	[ val ]  epoch 5/100,  batch 11/135,  loss_val=4.49415,  acc_val=0.00%
741.2s	407	[ val ]  epoch 5/100,  batch 21/135,  loss_val=3.95571,  acc_val=7.81%
743.1s	408	[ val ]  epoch 5/100,  batch 31/135,  loss_val=4.50398,  acc_val=0.00%
744.9s	409	[ val ]  epoch 5/100,  batch 41/135,  loss_val=3.56272,  acc_val=7.81%
746.7s	410	[ val ]  epoch 5/100,  batch 51/135,  loss_val=3.67312,  acc_val=10.94%
748.5s	411	[ val ]  epoch 5/100,  batch 61/135,  loss_val=5.58266,  acc_val=0.00%
750.3s	412	[ val ]  epoch 5/100,  batch 71/135,  loss_val=4.40463,  acc_val=0.00%
752.1s	413	[ val ]  epoch 5/100,  batch 81/135,  loss_val=4.15844,  acc_val=14.06%
753.9s	414	[ val ]  epoch 5/100,  batch 91/135,  loss_val=4.34186,  acc_val=7.81%
755.6s	415	[ val ]  epoch 5/100,  batch 101/135,  loss_val=3.44370,  acc_val=23.44%
757.5s	416	[ val ]  epoch 5/100,  batch 111/135,  loss_val=4.54268,  acc_val=7.81%
759.2s	417	[ val ]  epoch 5/100,  batch 121/135,  loss_val=3.67665,  acc_val=0.00%
760.9s	418	[ val ]  epoch 5/100,  batch 131/135,  loss_val=4.60480,  acc_val=4.69%
761.6s	419	==============================================================================================================
761.6s	420	Epoch 5/100 summary: loss_train=4.10335, acc_train=7.06%, loss_val=4.10, acc_val=6.70% (best: 6.70% @ epoch 5)
761.6s	421	==============================================================================================================
761.6s	422	Starting epoch 6/100, learning_rate=0.1
762.8s	423	[train]  epoch 6/100,  batch 1/188,  loss_train=3.74476,  acc_train=18.75%
768.4s	424	[train]  epoch 6/100,  batch 11/188,  loss_train=4.15622,  acc_train=7.81%
774.0s	425	[train]  epoch 6/100,  batch 21/188,  loss_train=3.99598,  acc_train=6.25%
779.7s	426	[train]  epoch 6/100,  batch 31/188,  loss_train=3.99694,  acc_train=4.69%
785.3s	427	[train]  epoch 6/100,  batch 41/188,  loss_train=4.04282,  acc_train=10.94%
791.0s	428	[train]  epoch 6/100,  batch 51/188,  loss_train=3.69994,  acc_train=17.19%
796.6s	429	[train]  epoch 6/100,  batch 61/188,  loss_train=3.92251,  acc_train=7.81%
802.2s	430	[train]  epoch 6/100,  batch 71/188,  loss_train=4.12627,  acc_train=10.94%
807.9s	431	[train]  epoch 6/100,  batch 81/188,  loss_train=3.92713,  acc_train=6.25%
813.5s	432	[train]  epoch 6/100,  batch 91/188,  loss_train=4.01018,  acc_train=12.50%
819.1s	433	[train]  epoch 6/100,  batch 101/188,  loss_train=3.82096,  acc_train=9.38%
824.8s	434	[train]  epoch 6/100,  batch 111/188,  loss_train=3.72833,  acc_train=7.81%
830.3s	435	[train]  epoch 6/100,  batch 121/188,  loss_train=3.47268,  acc_train=14.06%
835.9s	436	[train]  epoch 6/100,  batch 131/188,  loss_train=4.03524,  acc_train=9.38%
841.6s	437	[train]  epoch 6/100,  batch 141/188,  loss_train=3.87883,  acc_train=9.38%
847.3s	438	[train]  epoch 6/100,  batch 151/188,  loss_train=3.97401,  acc_train=7.81%
852.9s	439	[train]  epoch 6/100,  batch 161/188,  loss_train=3.75430,  acc_train=7.81%
858.5s	440	[train]  epoch 6/100,  batch 171/188,  loss_train=3.69286,  acc_train=12.50%
864.1s	441	[train]  epoch 6/100,  batch 181/188,  loss_train=3.87359,  acc_train=12.50%
868.9s	442	[ val ]  epoch 6/100,  batch 1/135,  loss_val=3.99845,  acc_val=7.81%
870.8s	443	[ val ]  epoch 6/100,  batch 11/135,  loss_val=4.34178,  acc_val=3.12%
872.6s	444	[ val ]  epoch 6/100,  batch 21/135,  loss_val=4.27753,  acc_val=0.00%
874.4s	445	[ val ]  epoch 6/100,  batch 31/135,  loss_val=3.96208,  acc_val=12.50%
876.1s	446	[ val ]  epoch 6/100,  batch 41/135,  loss_val=3.82027,  acc_val=1.56%
877.9s	447	[ val ]  epoch 6/100,  batch 51/135,  loss_val=3.83459,  acc_val=7.81%
879.7s	448	[ val ]  epoch 6/100,  batch 61/135,  loss_val=3.77165,  acc_val=20.31%
881.4s	449	[ val ]  epoch 6/100,  batch 71/135,  loss_val=4.34018,  acc_val=0.00%
883.2s	450	[ val ]  epoch 6/100,  batch 81/135,  loss_val=3.39108,  acc_val=21.88%
885.0s	451	[ val ]  epoch 6/100,  batch 91/135,  loss_val=4.80816,  acc_val=3.12%
886.8s	452	[ val ]  epoch 6/100,  batch 101/135,  loss_val=3.40401,  acc_val=25.00%
888.7s	453	[ val ]  epoch 6/100,  batch 111/135,  loss_val=3.63365,  acc_val=6.25%
890.4s	454	[ val ]  epoch 6/100,  batch 121/135,  loss_val=3.49750,  acc_val=9.38%
892.2s	455	[ val ]  epoch 6/100,  batch 131/135,  loss_val=3.87217,  acc_val=23.44%
892.8s	456	==============================================================================================================
892.8s	457	Epoch 6/100 summary: loss_train=3.93318, acc_train=9.08%, loss_val=3.99, acc_val=8.09% (best: 8.09% @ epoch 6)
892.8s	458	==============================================================================================================
892.8s	459	Starting epoch 7/100, learning_rate=0.1
894.1s	460	[train]  epoch 7/100,  batch 1/188,  loss_train=3.80834,  acc_train=4.69%
899.7s	461	[train]  epoch 7/100,  batch 11/188,  loss_train=3.68364,  acc_train=10.94%
905.3s	462	[train]  epoch 7/100,  batch 21/188,  loss_train=3.66337,  acc_train=12.50%
910.9s	463	[train]  epoch 7/100,  batch 31/188,  loss_train=3.69684,  acc_train=17.19%
916.5s	464	[train]  epoch 7/100,  batch 41/188,  loss_train=3.67912,  acc_train=14.06%
922.2s	465	[train]  epoch 7/100,  batch 51/188,  loss_train=3.80605,  acc_train=10.94%
927.8s	466	[train]  epoch 7/100,  batch 61/188,  loss_train=3.90035,  acc_train=14.06%
933.4s	467	[train]  epoch 7/100,  batch 71/188,  loss_train=3.85132,  acc_train=7.81%
939.0s	468	[train]  epoch 7/100,  batch 81/188,  loss_train=3.92782,  acc_train=10.94%
944.6s	469	[train]  epoch 7/100,  batch 91/188,  loss_train=3.88226,  acc_train=4.69%
950.3s	470	[train]  epoch 7/100,  batch 101/188,  loss_train=3.73828,  acc_train=9.38%
956.0s	471	[train]  epoch 7/100,  batch 111/188,  loss_train=3.82610,  acc_train=17.19%
961.5s	472	[train]  epoch 7/100,  batch 121/188,  loss_train=3.78576,  acc_train=14.06%
967.1s	473	[train]  epoch 7/100,  batch 131/188,  loss_train=3.85263,  acc_train=12.50%
972.8s	474	[train]  epoch 7/100,  batch 141/188,  loss_train=3.55739,  acc_train=12.50%
978.4s	475	[train]  epoch 7/100,  batch 151/188,  loss_train=3.92064,  acc_train=9.38%
984.0s	476	[train]  epoch 7/100,  batch 161/188,  loss_train=3.47007,  acc_train=4.69%
989.7s	477	[train]  epoch 7/100,  batch 171/188,  loss_train=3.61993,  acc_train=14.06%
995.3s	478	[train]  epoch 7/100,  batch 181/188,  loss_train=3.56219,  acc_train=15.62%
999.9s	479	[ val ]  epoch 7/100,  batch 1/135,  loss_val=5.31324,  acc_val=0.00%
1001.7s	480	[ val ]  epoch 7/100,  batch 11/135,  loss_val=5.80954,  acc_val=0.00%
1003.5s	481	[ val ]  epoch 7/100,  batch 21/135,  loss_val=4.73991,  acc_val=0.00%
1005.3s	482	[ val ]  epoch 7/100,  batch 31/135,  loss_val=4.13704,  acc_val=4.69%
1007.1s	483	[ val ]  epoch 7/100,  batch 41/135,  loss_val=3.34577,  acc_val=20.31%
1008.8s	484	[ val ]  epoch 7/100,  batch 51/135,  loss_val=4.03022,  acc_val=3.12%
1010.6s	485	[ val ]  epoch 7/100,  batch 61/135,  loss_val=4.42955,  acc_val=1.56%
1012.4s	486	[ val ]  epoch 7/100,  batch 71/135,  loss_val=4.90643,  acc_val=0.00%
1014.1s	487	[ val ]  epoch 7/100,  batch 81/135,  loss_val=3.46048,  acc_val=25.00%
1015.9s	488	[ val ]  epoch 7/100,  batch 91/135,  loss_val=5.57912,  acc_val=1.56%
1017.7s	489	[ val ]  epoch 7/100,  batch 101/135,  loss_val=5.40605,  acc_val=1.56%
1019.5s	490	[ val ]  epoch 7/100,  batch 111/135,  loss_val=4.18209,  acc_val=4.69%
1021.3s	491	[ val ]  epoch 7/100,  batch 121/135,  loss_val=2.87554,  acc_val=29.69%
1023.1s	492	[ val ]  epoch 7/100,  batch 131/135,  loss_val=4.32408,  acc_val=9.38%
1023.7s	493	===============================================================================================================
1023.7s	494	Epoch 7/100 summary: loss_train=3.75282, acc_train=11.56%, loss_val=4.17, acc_val=6.89% (best: 8.09% @ epoch 6)
1023.7s	495	===============================================================================================================
1023.7s	496	Starting epoch 8/100, learning_rate=0.1
1025.0s	497	[train]  epoch 8/100,  batch 1/188,  loss_train=3.65242,  acc_train=9.38%
1030.6s	498	[train]  epoch 8/100,  batch 11/188,  loss_train=3.73627,  acc_train=15.62%
1036.2s	499	[train]  epoch 8/100,  batch 21/188,  loss_train=3.58435,  acc_train=21.88%
1041.9s	500	[train]  epoch 8/100,  batch 31/188,  loss_train=3.53361,  acc_train=14.06%
1047.5s	501	[train]  epoch 8/100,  batch 41/188,  loss_train=3.07546,  acc_train=25.00%
1053.2s	502	[train]  epoch 8/100,  batch 51/188,  loss_train=3.86153,  acc_train=6.25%
1058.8s	503	[train]  epoch 8/100,  batch 61/188,  loss_train=3.53613,  acc_train=9.38%
1064.4s	504	[train]  epoch 8/100,  batch 71/188,  loss_train=3.40385,  acc_train=17.19%
1070.1s	505	[train]  epoch 8/100,  batch 81/188,  loss_train=3.72666,  acc_train=17.19%
1075.7s	506	[train]  epoch 8/100,  batch 91/188,  loss_train=3.38266,  acc_train=20.31%
1081.3s	507	[train]  epoch 8/100,  batch 101/188,  loss_train=3.76469,  acc_train=9.38%
1087.1s	508	[train]  epoch 8/100,  batch 111/188,  loss_train=3.48725,  acc_train=14.06%
1092.7s	509	[train]  epoch 8/100,  batch 121/188,  loss_train=3.82933,  acc_train=10.94%
1098.3s	510	[train]  epoch 8/100,  batch 131/188,  loss_train=3.29830,  acc_train=17.19%
1103.9s	511	[train]  epoch 8/100,  batch 141/188,  loss_train=3.85207,  acc_train=6.25%
1109.5s	512	[train]  epoch 8/100,  batch 151/188,  loss_train=3.49290,  acc_train=23.44%
1115.1s	513	[train]  epoch 8/100,  batch 161/188,  loss_train=3.64921,  acc_train=17.19%
1120.8s	514	[train]  epoch 8/100,  batch 171/188,  loss_train=3.78772,  acc_train=15.62%
1126.4s	515	[train]  epoch 8/100,  batch 181/188,  loss_train=3.61985,  acc_train=14.06%
1131.0s	516	[ val ]  epoch 8/100,  batch 1/135,  loss_val=4.11589,  acc_val=1.56%
1132.8s	517	[ val ]  epoch 8/100,  batch 11/135,  loss_val=3.85626,  acc_val=6.25%
1134.6s	518	[ val ]  epoch 8/100,  batch 21/135,  loss_val=2.94811,  acc_val=21.88%
1136.4s	519	[ val ]  epoch 8/100,  batch 31/135,  loss_val=4.23106,  acc_val=7.81%
1138.1s	520	[ val ]  epoch 8/100,  batch 41/135,  loss_val=3.95936,  acc_val=7.81%
1139.9s	521	[ val ]  epoch 8/100,  batch 51/135,  loss_val=3.83415,  acc_val=9.38%
1141.7s	522	[ val ]  epoch 8/100,  batch 61/135,  loss_val=3.77801,  acc_val=4.69%
1143.5s	523	[ val ]  epoch 8/100,  batch 71/135,  loss_val=4.01832,  acc_val=7.81%
1145.3s	524	[ val ]  epoch 8/100,  batch 81/135,  loss_val=2.87603,  acc_val=39.06%
1147.1s	525	[ val ]  epoch 8/100,  batch 91/135,  loss_val=3.33415,  acc_val=31.25%
1148.9s	526	[ val ]  epoch 8/100,  batch 101/135,  loss_val=2.01746,  acc_val=46.88%
1150.7s	527	[ val ]  epoch 8/100,  batch 111/135,  loss_val=3.27488,  acc_val=9.38%
1152.5s	528	[ val ]  epoch 8/100,  batch 121/135,  loss_val=3.63531,  acc_val=6.25%
1154.3s	529	[ val ]  epoch 8/100,  batch 131/135,  loss_val=3.38620,  acc_val=31.25%
1154.9s	530	=================================================================================================================
1154.9s	531	Epoch 8/100 summary: loss_train=3.60408, acc_train=13.69%, loss_val=3.72, acc_val=11.56% (best: 11.56% @ epoch 8)
1154.9s	532	=================================================================================================================
1154.9s	533	Starting epoch 9/100, learning_rate=0.1
1156.2s	534	[train]  epoch 9/100,  batch 1/188,  loss_train=3.15073,  acc_train=15.62%
1161.9s	535	[train]  epoch 9/100,  batch 11/188,  loss_train=3.75300,  acc_train=14.06%
1167.5s	536	[train]  epoch 9/100,  batch 21/188,  loss_train=3.22977,  acc_train=20.31%
1173.1s	537	[train]  epoch 9/100,  batch 31/188,  loss_train=3.25875,  acc_train=12.50%
1178.8s	538	[train]  epoch 9/100,  batch 41/188,  loss_train=3.60889,  acc_train=3.12%
1184.4s	539	[train]  epoch 9/100,  batch 51/188,  loss_train=3.26281,  acc_train=21.88%
1190.0s	540	[train]  epoch 9/100,  batch 61/188,  loss_train=3.36149,  acc_train=20.31%
1195.6s	541	[train]  epoch 9/100,  batch 71/188,  loss_train=3.65060,  acc_train=12.50%
1201.3s	542	[train]  epoch 9/100,  batch 81/188,  loss_train=3.31946,  acc_train=15.62%
1206.9s	543	[train]  epoch 9/100,  batch 91/188,  loss_train=3.15346,  acc_train=17.19%
1212.5s	544	[train]  epoch 9/100,  batch 101/188,  loss_train=3.60477,  acc_train=10.94%
1218.2s	545	[train]  epoch 9/100,  batch 111/188,  loss_train=3.15360,  acc_train=18.75%
1223.8s	546	[train]  epoch 9/100,  batch 121/188,  loss_train=3.67647,  acc_train=15.62%
1229.5s	547	[train]  epoch 9/100,  batch 131/188,  loss_train=3.33450,  acc_train=23.44%
1235.1s	548	[train]  epoch 9/100,  batch 141/188,  loss_train=3.29371,  acc_train=21.88%
1240.7s	549	[train]  epoch 9/100,  batch 151/188,  loss_train=3.23393,  acc_train=18.75%
1246.3s	550	[train]  epoch 9/100,  batch 161/188,  loss_train=3.07862,  acc_train=26.56%
1252.1s	551	[train]  epoch 9/100,  batch 171/188,  loss_train=3.61567,  acc_train=15.62%
1257.6s	552	[train]  epoch 9/100,  batch 181/188,  loss_train=3.44389,  acc_train=17.19%
1262.2s	553	[ val ]  epoch 9/100,  batch 1/135,  loss_val=4.12458,  acc_val=3.12%
1264.0s	554	[ val ]  epoch 9/100,  batch 11/135,  loss_val=4.27534,  acc_val=6.25%
1265.8s	555	[ val ]  epoch 9/100,  batch 21/135,  loss_val=3.61147,  acc_val=14.06%
1267.6s	556	[ val ]  epoch 9/100,  batch 31/135,  loss_val=3.72374,  acc_val=9.38%
1269.4s	557	[ val ]  epoch 9/100,  batch 41/135,  loss_val=3.50134,  acc_val=12.50%
1271.2s	558	[ val ]  epoch 9/100,  batch 51/135,  loss_val=3.94391,  acc_val=1.56%
1273.0s	559	[ val ]  epoch 9/100,  batch 61/135,  loss_val=4.23845,  acc_val=3.12%
1274.8s	560	[ val ]  epoch 9/100,  batch 71/135,  loss_val=3.72947,  acc_val=9.38%
1276.6s	561	[ val ]  epoch 9/100,  batch 81/135,  loss_val=3.84943,  acc_val=12.50%
1278.4s	562	[ val ]  epoch 9/100,  batch 91/135,  loss_val=4.81122,  acc_val=12.50%
1280.2s	563	[ val ]  epoch 9/100,  batch 101/135,  loss_val=2.62993,  acc_val=31.25%
1282.3s	564	[ val ]  epoch 9/100,  batch 111/135,  loss_val=4.02928,  acc_val=4.69%
1283.9s	565	[ val ]  epoch 9/100,  batch 121/135,  loss_val=3.44009,  acc_val=4.69%
1285.7s	566	[ val ]  epoch 9/100,  batch 131/135,  loss_val=3.06859,  acc_val=39.06%
1286.3s	567	=================================================================================================================
1286.3s	568	Epoch 9/100 summary: loss_train=3.46587, acc_train=15.84%, loss_val=3.68, acc_val=12.93% (best: 12.93% @ epoch 9)
1286.3s	569	=================================================================================================================
1286.3s	570	Starting epoch 10/100, learning_rate=0.1
1287.6s	571	[train]  epoch 10/100,  batch 1/188,  loss_train=3.37644,  acc_train=15.62%
1293.3s	572	[train]  epoch 10/100,  batch 11/188,  loss_train=3.05380,  acc_train=20.31%
1298.9s	573	[train]  epoch 10/100,  batch 21/188,  loss_train=3.43422,  acc_train=14.06%
1304.6s	574	[train]  epoch 10/100,  batch 31/188,  loss_train=3.23493,  acc_train=25.00%
1310.2s	575	[train]  epoch 10/100,  batch 41/188,  loss_train=3.35949,  acc_train=21.88%
1316.0s	576	[train]  epoch 10/100,  batch 51/188,  loss_train=3.18809,  acc_train=21.88%
1321.5s	577	[train]  epoch 10/100,  batch 61/188,  loss_train=3.08590,  acc_train=28.12%
1327.2s	578	[train]  epoch 10/100,  batch 71/188,  loss_train=3.45374,  acc_train=17.19%
1332.8s	579	[train]  epoch 10/100,  batch 81/188,  loss_train=3.18275,  acc_train=20.31%
1338.4s	580	[train]  epoch 10/100,  batch 91/188,  loss_train=3.62135,  acc_train=12.50%
1344.1s	581	[train]  epoch 10/100,  batch 101/188,  loss_train=3.01529,  acc_train=18.75%
1349.8s	582	[train]  epoch 10/100,  batch 111/188,  loss_train=3.39306,  acc_train=20.31%
1355.5s	583	[train]  epoch 10/100,  batch 121/188,  loss_train=3.15069,  acc_train=17.19%
1361.1s	584	[train]  epoch 10/100,  batch 131/188,  loss_train=3.23971,  acc_train=20.31%
1366.7s	585	[train]  epoch 10/100,  batch 141/188,  loss_train=3.17127,  acc_train=25.00%
1372.4s	586	[train]  epoch 10/100,  batch 151/188,  loss_train=3.21772,  acc_train=15.62%
1378.0s	587	[train]  epoch 10/100,  batch 161/188,  loss_train=3.25430,  acc_train=20.31%
1383.7s	588	[train]  epoch 10/100,  batch 171/188,  loss_train=3.16440,  acc_train=14.06%
1389.3s	589	[train]  epoch 10/100,  batch 181/188,  loss_train=3.78761,  acc_train=10.94%
1393.9s	590	[ val ]  epoch 10/100,  batch 1/135,  loss_val=5.17507,  acc_val=0.00%
1395.7s	591	[ val ]  epoch 10/100,  batch 11/135,  loss_val=4.89231,  acc_val=1.56%
1397.5s	592	[ val ]  epoch 10/100,  batch 21/135,  loss_val=3.55576,  acc_val=1.56%
1399.3s	593	[ val ]  epoch 10/100,  batch 31/135,  loss_val=5.53611,  acc_val=0.00%
1401.1s	594	[ val ]  epoch 10/100,  batch 41/135,  loss_val=4.06417,  acc_val=1.56%
1402.8s	595	[ val ]  epoch 10/100,  batch 51/135,  loss_val=3.44638,  acc_val=14.06%
1404.6s	596	[ val ]  epoch 10/100,  batch 61/135,  loss_val=4.71683,  acc_val=0.00%
1406.4s	597	[ val ]  epoch 10/100,  batch 71/135,  loss_val=4.26805,  acc_val=9.38%
1408.2s	598	[ val ]  epoch 10/100,  batch 81/135,  loss_val=3.73329,  acc_val=9.38%
1410.0s	599	[ val ]  epoch 10/100,  batch 91/135,  loss_val=5.12549,  acc_val=3.12%
1411.9s	600	[ val ]  epoch 10/100,  batch 101/135,  loss_val=2.50565,  acc_val=25.00%
1413.7s	601	[ val ]  epoch 10/100,  batch 111/135,  loss_val=3.45299,  acc_val=6.25%
1415.5s	602	[ val ]  epoch 10/100,  batch 121/135,  loss_val=2.47774,  acc_val=40.62%
1417.2s	603	[ val ]  epoch 10/100,  batch 131/135,  loss_val=2.94215,  acc_val=34.38%
1417.8s	604	==================================================================================================================
1417.8s	605	Epoch 10/100 summary: loss_train=3.32901, acc_train=18.18%, loss_val=3.77, acc_val=11.60% (best: 12.93% @ epoch 9)
1417.8s	606	==================================================================================================================
1417.8s	607	Starting epoch 11/100, learning_rate=0.1
1419.0s	608	[train]  epoch 11/100,  batch 1/188,  loss_train=3.16462,  acc_train=23.44%
1424.6s	609	[train]  epoch 11/100,  batch 11/188,  loss_train=3.04381,  acc_train=25.00%
1430.3s	610	[train]  epoch 11/100,  batch 21/188,  loss_train=3.14511,  acc_train=20.31%
1435.9s	611	[train]  epoch 11/100,  batch 31/188,  loss_train=3.15835,  acc_train=32.81%
1441.6s	612	[train]  epoch 11/100,  batch 41/188,  loss_train=3.17196,  acc_train=12.50%
1447.2s	613	[train]  epoch 11/100,  batch 51/188,  loss_train=3.17616,  acc_train=18.75%
1452.8s	614	[train]  epoch 11/100,  batch 61/188,  loss_train=3.33642,  acc_train=18.75%
1458.4s	615	[train]  epoch 11/100,  batch 71/188,  loss_train=2.70289,  acc_train=31.25%
1464.0s	616	[train]  epoch 11/100,  batch 81/188,  loss_train=3.08452,  acc_train=21.88%
1469.7s	617	[train]  epoch 11/100,  batch 91/188,  loss_train=3.15106,  acc_train=15.62%
1475.3s	618	[train]  epoch 11/100,  batch 101/188,  loss_train=3.32743,  acc_train=14.06%
1480.9s	619	[train]  epoch 11/100,  batch 111/188,  loss_train=3.18498,  acc_train=26.56%
1486.5s	620	[train]  epoch 11/100,  batch 121/188,  loss_train=3.09852,  acc_train=21.88%
1492.1s	621	[train]  epoch 11/100,  batch 131/188,  loss_train=2.89346,  acc_train=28.12%
1497.7s	622	[train]  epoch 11/100,  batch 141/188,  loss_train=2.91200,  acc_train=23.44%
1503.3s	623	[train]  epoch 11/100,  batch 151/188,  loss_train=3.30223,  acc_train=17.19%
1509.0s	624	[train]  epoch 11/100,  batch 161/188,  loss_train=3.01633,  acc_train=20.31%
1514.6s	625	[train]  epoch 11/100,  batch 171/188,  loss_train=3.40103,  acc_train=18.75%
1520.2s	626	[train]  epoch 11/100,  batch 181/188,  loss_train=2.96861,  acc_train=20.31%
1524.9s	627	[ val ]  epoch 11/100,  batch 1/135,  loss_val=4.53603,  acc_val=4.69%
1526.7s	628	[ val ]  epoch 11/100,  batch 11/135,  loss_val=4.37922,  acc_val=6.25%
1528.4s	629	[ val ]  epoch 11/100,  batch 21/135,  loss_val=4.04030,  acc_val=6.25%
1530.2s	630	[ val ]  epoch 11/100,  batch 31/135,  loss_val=4.47547,  acc_val=0.00%
1532.0s	631	[ val ]  epoch 11/100,  batch 41/135,  loss_val=2.69954,  acc_val=17.19%
1533.8s	632	[ val ]  epoch 11/100,  batch 51/135,  loss_val=2.86247,  acc_val=21.88%
1535.6s	633	[ val ]  epoch 11/100,  batch 61/135,  loss_val=4.69634,  acc_val=0.00%
1537.4s	634	[ val ]  epoch 11/100,  batch 71/135,  loss_val=5.74749,  acc_val=0.00%
1539.4s	635	[ val ]  epoch 11/100,  batch 81/135,  loss_val=4.72420,  acc_val=0.00%
1541.2s	636	[ val ]  epoch 11/100,  batch 91/135,  loss_val=3.31384,  acc_val=6.25%
1543.0s	637	[ val ]  epoch 11/100,  batch 101/135,  loss_val=3.56177,  acc_val=4.69%
1544.8s	638	[ val ]  epoch 11/100,  batch 111/135,  loss_val=4.13117,  acc_val=4.69%
1546.5s	639	[ val ]  epoch 11/100,  batch 121/135,  loss_val=3.42701,  acc_val=18.75%
1548.2s	640	[ val ]  epoch 11/100,  batch 131/135,  loss_val=4.68689,  acc_val=3.12%
1548.9s	641	==================================================================================================================
1548.9s	642	Epoch 11/100 summary: loss_train=3.22832, acc_train=19.38%, loss_val=3.99, acc_val=11.53% (best: 12.93% @ epoch 9)
1548.9s	643	==================================================================================================================
1548.9s	644	Starting epoch 12/100, learning_rate=0.1
1550.2s	645	[train]  epoch 12/100,  batch 1/188,  loss_train=2.99111,  acc_train=26.56%
1555.8s	646	[train]  epoch 12/100,  batch 11/188,  loss_train=3.13729,  acc_train=21.88%
1561.4s	647	[train]  epoch 12/100,  batch 21/188,  loss_train=3.44510,  acc_train=15.62%
1567.0s	648	[train]  epoch 12/100,  batch 31/188,  loss_train=3.16996,  acc_train=25.00%
1572.7s	649	[train]  epoch 12/100,  batch 41/188,  loss_train=2.94566,  acc_train=23.44%
1578.4s	650	[train]  epoch 12/100,  batch 51/188,  loss_train=2.95060,  acc_train=21.88%
1583.9s	651	[train]  epoch 12/100,  batch 61/188,  loss_train=3.02623,  acc_train=17.19%
1589.6s	652	[train]  epoch 12/100,  batch 71/188,  loss_train=3.37203,  acc_train=18.75%
1595.2s	653	[train]  epoch 12/100,  batch 81/188,  loss_train=3.09331,  acc_train=10.94%
1600.8s	654	[train]  epoch 12/100,  batch 91/188,  loss_train=3.24209,  acc_train=21.88%
1606.4s	655	[train]  epoch 12/100,  batch 101/188,  loss_train=3.18515,  acc_train=17.19%
1612.1s	656	[train]  epoch 12/100,  batch 111/188,  loss_train=3.11915,  acc_train=28.12%
1617.7s	657	[train]  epoch 12/100,  batch 121/188,  loss_train=3.26730,  acc_train=18.75%
1623.3s	658	[train]  epoch 12/100,  batch 131/188,  loss_train=3.33219,  acc_train=25.00%
1628.9s	659	[train]  epoch 12/100,  batch 141/188,  loss_train=3.28333,  acc_train=25.00%
1634.6s	660	[train]  epoch 12/100,  batch 151/188,  loss_train=2.97098,  acc_train=20.31%
1640.2s	661	[train]  epoch 12/100,  batch 161/188,  loss_train=3.04641,  acc_train=25.00%
1645.9s	662	[train]  epoch 12/100,  batch 171/188,  loss_train=3.03388,  acc_train=26.56%
1651.4s	663	[train]  epoch 12/100,  batch 181/188,  loss_train=3.05087,  acc_train=23.44%
1656.1s	664	[ val ]  epoch 12/100,  batch 1/135,  loss_val=3.74829,  acc_val=14.06%
1657.9s	665	[ val ]  epoch 12/100,  batch 11/135,  loss_val=2.24822,  acc_val=56.25%
1659.7s	666	[ val ]  epoch 12/100,  batch 21/135,  loss_val=3.59721,  acc_val=3.12%
1661.4s	667	[ val ]  epoch 12/100,  batch 31/135,  loss_val=2.83274,  acc_val=39.06%
1663.2s	668	[ val ]  epoch 12/100,  batch 41/135,  loss_val=2.77045,  acc_val=20.31%
1665.1s	669	[ val ]  epoch 12/100,  batch 51/135,  loss_val=2.96548,  acc_val=15.62%
1667.0s	670	[ val ]  epoch 12/100,  batch 61/135,  loss_val=4.22253,  acc_val=6.25%
1668.7s	671	[ val ]  epoch 12/100,  batch 71/135,  loss_val=3.53346,  acc_val=14.06%
1670.5s	672	[ val ]  epoch 12/100,  batch 81/135,  loss_val=4.41838,  acc_val=9.38%
1672.3s	673	[ val ]  epoch 12/100,  batch 91/135,  loss_val=4.01326,  acc_val=14.06%
1674.1s	674	[ val ]  epoch 12/100,  batch 101/135,  loss_val=1.99940,  acc_val=42.19%
1675.9s	675	[ val ]  epoch 12/100,  batch 111/135,  loss_val=3.39900,  acc_val=15.62%
1677.8s	676	[ val ]  epoch 12/100,  batch 121/135,  loss_val=2.11291,  acc_val=40.62%
1679.5s	677	[ val ]  epoch 12/100,  batch 131/135,  loss_val=3.22168,  acc_val=34.38%
1680.1s	678	===================================================================================================================
1680.1s	679	Epoch 12/100 summary: loss_train=3.10039, acc_train=21.82%, loss_val=3.31, acc_val=18.72% (best: 18.72% @ epoch 12)
1680.1s	680	===================================================================================================================
1680.1s	681	Starting epoch 13/100, learning_rate=0.1
1681.4s	682	[train]  epoch 13/100,  batch 1/188,  loss_train=3.26522,  acc_train=17.19%
1687.0s	683	[train]  epoch 13/100,  batch 11/188,  loss_train=2.99656,  acc_train=26.56%
1692.7s	684	[train]  epoch 13/100,  batch 21/188,  loss_train=3.07740,  acc_train=18.75%
1698.3s	685	[train]  epoch 13/100,  batch 31/188,  loss_train=2.93356,  acc_train=21.88%
1703.9s	686	[train]  epoch 13/100,  batch 41/188,  loss_train=2.86794,  acc_train=26.56%
1709.6s	687	[train]  epoch 13/100,  batch 51/188,  loss_train=3.03900,  acc_train=29.69%
1715.2s	688	[train]  epoch 13/100,  batch 61/188,  loss_train=2.89995,  acc_train=35.94%
1720.8s	689	[train]  epoch 13/100,  batch 71/188,  loss_train=3.06635,  acc_train=21.88%
1726.4s	690	[train]  epoch 13/100,  batch 81/188,  loss_train=3.10049,  acc_train=26.56%
1732.1s	691	[train]  epoch 13/100,  batch 91/188,  loss_train=3.04310,  acc_train=14.06%
1737.7s	692	[train]  epoch 13/100,  batch 101/188,  loss_train=2.87409,  acc_train=28.12%
1743.3s	693	[train]  epoch 13/100,  batch 111/188,  loss_train=3.09058,  acc_train=26.56%
1748.9s	694	[train]  epoch 13/100,  batch 121/188,  loss_train=2.96234,  acc_train=21.88%
1754.5s	695	[train]  epoch 13/100,  batch 131/188,  loss_train=3.10688,  acc_train=15.62%
1760.1s	696	[train]  epoch 13/100,  batch 141/188,  loss_train=3.02361,  acc_train=28.12%
1765.7s	697	[train]  epoch 13/100,  batch 151/188,  loss_train=3.10589,  acc_train=23.44%
1771.4s	698	[train]  epoch 13/100,  batch 161/188,  loss_train=2.73531,  acc_train=25.00%
1777.1s	699	[train]  epoch 13/100,  batch 171/188,  loss_train=3.10052,  acc_train=17.19%
1782.6s	700	[train]  epoch 13/100,  batch 181/188,  loss_train=2.91956,  acc_train=21.88%
1787.2s	701	[ val ]  epoch 13/100,  batch 1/135,  loss_val=4.34911,  acc_val=0.00%
1789.0s	702	[ val ]  epoch 13/100,  batch 11/135,  loss_val=2.49690,  acc_val=35.94%
1790.8s	703	[ val ]  epoch 13/100,  batch 21/135,  loss_val=1.48083,  acc_val=56.25%
1792.5s	704	[ val ]  epoch 13/100,  batch 31/135,  loss_val=2.77131,  acc_val=20.31%
1794.4s	705	[ val ]  epoch 13/100,  batch 41/135,  loss_val=2.92056,  acc_val=28.12%
1796.2s	706	[ val ]  epoch 13/100,  batch 51/135,  loss_val=3.75816,  acc_val=9.38%
1798.0s	707	[ val ]  epoch 13/100,  batch 61/135,  loss_val=3.75793,  acc_val=23.44%
1799.8s	708	[ val ]  epoch 13/100,  batch 71/135,  loss_val=3.39886,  acc_val=4.69%
1801.5s	709	[ val ]  epoch 13/100,  batch 81/135,  loss_val=4.10281,  acc_val=21.88%
1803.3s	710	[ val ]  epoch 13/100,  batch 91/135,  loss_val=3.22265,  acc_val=25.00%
1805.1s	711	[ val ]  epoch 13/100,  batch 101/135,  loss_val=1.10545,  acc_val=60.94%
1806.9s	712	[ val ]  epoch 13/100,  batch 111/135,  loss_val=3.24357,  acc_val=20.31%
1808.7s	713	[ val ]  epoch 13/100,  batch 121/135,  loss_val=1.80132,  acc_val=64.06%
1810.4s	714	[ val ]  epoch 13/100,  batch 131/135,  loss_val=2.59018,  acc_val=50.00%
1811.0s	715	===================================================================================================================
1811.0s	716	Epoch 13/100 summary: loss_train=2.98164, acc_train=23.84%, loss_val=3.27, acc_val=19.71% (best: 19.71% @ epoch 13)
1811.0s	717	===================================================================================================================
1811.0s	718	Starting epoch 14/100, learning_rate=0.1
1812.3s	719	[train]  epoch 14/100,  batch 1/188,  loss_train=2.80936,  acc_train=28.12%
1817.9s	720	[train]  epoch 14/100,  batch 11/188,  loss_train=3.35985,  acc_train=18.75%
1823.5s	721	[train]  epoch 14/100,  batch 21/188,  loss_train=2.91266,  acc_train=20.31%
1829.2s	722	[train]  epoch 14/100,  batch 31/188,  loss_train=2.55145,  acc_train=32.81%
1834.8s	723	[train]  epoch 14/100,  batch 41/188,  loss_train=3.07950,  acc_train=25.00%
1840.5s	724	[train]  epoch 14/100,  batch 51/188,  loss_train=2.78326,  acc_train=25.00%
1846.0s	725	[train]  epoch 14/100,  batch 61/188,  loss_train=2.61799,  acc_train=35.94%
1851.6s	726	[train]  epoch 14/100,  batch 71/188,  loss_train=2.58395,  acc_train=29.69%
1857.2s	727	[train]  epoch 14/100,  batch 81/188,  loss_train=2.92022,  acc_train=20.31%
1862.9s	728	[train]  epoch 14/100,  batch 91/188,  loss_train=3.43619,  acc_train=18.75%
1868.5s	729	[train]  epoch 14/100,  batch 101/188,  loss_train=2.77656,  acc_train=26.56%
1874.2s	730	[train]  epoch 14/100,  batch 111/188,  loss_train=3.08105,  acc_train=25.00%
1879.7s	731	[train]  epoch 14/100,  batch 121/188,  loss_train=2.94986,  acc_train=29.69%
1885.4s	732	[train]  epoch 14/100,  batch 131/188,  loss_train=2.82493,  acc_train=21.88%
1891.0s	733	[train]  epoch 14/100,  batch 141/188,  loss_train=2.97575,  acc_train=31.25%
1896.7s	734	[train]  epoch 14/100,  batch 151/188,  loss_train=2.54500,  acc_train=31.25%
1902.3s	735	[train]  epoch 14/100,  batch 161/188,  loss_train=2.95657,  acc_train=32.81%
1908.0s	736	[train]  epoch 14/100,  batch 171/188,  loss_train=2.73530,  acc_train=28.12%
1913.6s	737	[train]  epoch 14/100,  batch 181/188,  loss_train=3.11398,  acc_train=29.69%
1918.2s	738	[ val ]  epoch 14/100,  batch 1/135,  loss_val=3.88733,  acc_val=6.25%
1920.0s	739	[ val ]  epoch 14/100,  batch 11/135,  loss_val=3.31089,  acc_val=26.56%
1922.0s	740	[ val ]  epoch 14/100,  batch 21/135,  loss_val=2.77771,  acc_val=26.56%
1923.8s	741	[ val ]  epoch 14/100,  batch 31/135,  loss_val=2.97142,  acc_val=28.12%
1925.6s	742	[ val ]  epoch 14/100,  batch 41/135,  loss_val=2.41362,  acc_val=34.38%
1927.3s	743	[ val ]  epoch 14/100,  batch 51/135,  loss_val=3.16661,  acc_val=15.62%
1929.1s	744	[ val ]  epoch 14/100,  batch 61/135,  loss_val=4.71798,  acc_val=1.56%
1930.9s	745	[ val ]  epoch 14/100,  batch 71/135,  loss_val=2.90110,  acc_val=18.75%
1932.7s	746	[ val ]  epoch 14/100,  batch 81/135,  loss_val=3.44337,  acc_val=15.62%
1934.5s	747	[ val ]  epoch 14/100,  batch 91/135,  loss_val=3.65657,  acc_val=10.94%
1936.3s	748	[ val ]  epoch 14/100,  batch 101/135,  loss_val=1.71779,  acc_val=57.81%
1938.2s	749	[ val ]  epoch 14/100,  batch 111/135,  loss_val=3.56552,  acc_val=7.81%
1939.8s	750	[ val ]  epoch 14/100,  batch 121/135,  loss_val=3.11501,  acc_val=10.94%
1941.6s	751	[ val ]  epoch 14/100,  batch 131/135,  loss_val=3.05122,  acc_val=26.56%
1942.3s	752	===================================================================================================================
1942.3s	753	Epoch 14/100 summary: loss_train=2.86173, acc_train=25.99%, loss_val=3.16, acc_val=20.14% (best: 20.14% @ epoch 14)
1942.3s	754	===================================================================================================================
1942.3s	755	Starting epoch 15/100, learning_rate=0.1
1943.4s	756	[train]  epoch 15/100,  batch 1/188,  loss_train=2.73464,  acc_train=25.00%
1949.1s	757	[train]  epoch 15/100,  batch 11/188,  loss_train=2.57613,  acc_train=28.12%
1954.7s	758	[train]  epoch 15/100,  batch 21/188,  loss_train=2.85336,  acc_train=29.69%
1960.4s	759	[train]  epoch 15/100,  batch 31/188,  loss_train=2.52521,  acc_train=37.50%
1966.0s	760	[train]  epoch 15/100,  batch 41/188,  loss_train=2.84101,  acc_train=26.56%
1971.6s	761	[train]  epoch 15/100,  batch 51/188,  loss_train=2.72532,  acc_train=26.56%
1977.2s	762	[train]  epoch 15/100,  batch 61/188,  loss_train=2.98791,  acc_train=28.12%
1982.8s	763	[train]  epoch 15/100,  batch 71/188,  loss_train=2.69481,  acc_train=29.69%
1988.5s	764	[train]  epoch 15/100,  batch 81/188,  loss_train=3.09969,  acc_train=20.31%
1994.1s	765	[train]  epoch 15/100,  batch 91/188,  loss_train=2.84589,  acc_train=31.25%
1999.7s	766	[train]  epoch 15/100,  batch 101/188,  loss_train=3.01008,  acc_train=18.75%
2005.4s	767	[train]  epoch 15/100,  batch 111/188,  loss_train=2.68124,  acc_train=26.56%
2011.0s	768	[train]  epoch 15/100,  batch 121/188,  loss_train=2.58089,  acc_train=35.94%
2016.7s	769	[train]  epoch 15/100,  batch 131/188,  loss_train=2.76924,  acc_train=23.44%
2022.3s	770	[train]  epoch 15/100,  batch 141/188,  loss_train=2.47613,  acc_train=34.38%
2027.9s	771	[train]  epoch 15/100,  batch 151/188,  loss_train=2.93595,  acc_train=31.25%
2033.5s	772	[train]  epoch 15/100,  batch 161/188,  loss_train=2.63453,  acc_train=23.44%
2039.2s	773	[train]  epoch 15/100,  batch 171/188,  loss_train=2.70210,  acc_train=28.12%
2044.8s	774	[train]  epoch 15/100,  batch 181/188,  loss_train=2.70805,  acc_train=28.12%
2049.6s	775	[ val ]  epoch 15/100,  batch 1/135,  loss_val=3.89884,  acc_val=17.19%
2051.3s	776	[ val ]  epoch 15/100,  batch 11/135,  loss_val=3.39796,  acc_val=18.75%
2053.1s	777	[ val ]  epoch 15/100,  batch 21/135,  loss_val=3.01070,  acc_val=15.62%
2054.9s	778	[ val ]  epoch 15/100,  batch 31/135,  loss_val=3.74173,  acc_val=10.94%
2056.6s	779	[ val ]  epoch 15/100,  batch 41/135,  loss_val=2.27227,  acc_val=37.50%
2058.4s	780	[ val ]  epoch 15/100,  batch 51/135,  loss_val=2.87802,  acc_val=23.44%
2060.2s	781	[ val ]  epoch 15/100,  batch 61/135,  loss_val=4.10593,  acc_val=4.69%
2061.9s	782	[ val ]  epoch 15/100,  batch 71/135,  loss_val=3.82852,  acc_val=12.50%
2063.7s	783	[ val ]  epoch 15/100,  batch 81/135,  loss_val=3.18074,  acc_val=40.62%
2065.5s	784	[ val ]  epoch 15/100,  batch 91/135,  loss_val=4.73494,  acc_val=7.81%
2067.3s	785	[ val ]  epoch 15/100,  batch 101/135,  loss_val=3.41809,  acc_val=1.56%
2069.1s	786	[ val ]  epoch 15/100,  batch 111/135,  loss_val=2.49952,  acc_val=26.56%
2070.9s	787	[ val ]  epoch 15/100,  batch 121/135,  loss_val=3.17187,  acc_val=17.19%
2072.6s	788	[ val ]  epoch 15/100,  batch 131/135,  loss_val=3.20879,  acc_val=23.44%
2073.2s	789	===================================================================================================================
2073.2s	790	Epoch 15/100 summary: loss_train=2.78039, acc_train=28.37%, loss_val=3.31, acc_val=19.50% (best: 20.14% @ epoch 14)
2073.2s	791	===================================================================================================================
2073.2s	792	Starting epoch 16/100, learning_rate=0.1
2074.5s	793	[train]  epoch 16/100,  batch 1/188,  loss_train=2.33723,  acc_train=39.06%
2080.1s	794	[train]  epoch 16/100,  batch 11/188,  loss_train=2.60910,  acc_train=32.81%
2085.8s	795	[train]  epoch 16/100,  batch 21/188,  loss_train=2.39446,  acc_train=39.06%
2091.4s	796	[train]  epoch 16/100,  batch 31/188,  loss_train=2.62736,  acc_train=25.00%
2097.0s	797	[train]  epoch 16/100,  batch 41/188,  loss_train=2.62787,  acc_train=37.50%
2102.7s	798	[train]  epoch 16/100,  batch 51/188,  loss_train=2.51988,  acc_train=32.81%
2108.3s	799	[train]  epoch 16/100,  batch 61/188,  loss_train=2.52018,  acc_train=39.06%
2114.0s	800	[train]  epoch 16/100,  batch 71/188,  loss_train=2.50876,  acc_train=31.25%
2119.6s	801	[train]  epoch 16/100,  batch 81/188,  loss_train=2.35665,  acc_train=35.94%
2125.2s	802	[train]  epoch 16/100,  batch 91/188,  loss_train=2.67460,  acc_train=25.00%
2130.9s	803	[train]  epoch 16/100,  batch 101/188,  loss_train=2.31442,  acc_train=45.31%
2136.5s	804	[train]  epoch 16/100,  batch 111/188,  loss_train=2.48981,  acc_train=34.38%
2142.1s	805	[train]  epoch 16/100,  batch 121/188,  loss_train=2.36836,  acc_train=34.38%
2147.8s	806	[train]  epoch 16/100,  batch 131/188,  loss_train=2.88401,  acc_train=20.31%
2153.4s	807	[train]  epoch 16/100,  batch 141/188,  loss_train=2.68368,  acc_train=26.56%
2159.0s	808	[train]  epoch 16/100,  batch 151/188,  loss_train=2.45062,  acc_train=39.06%
2164.6s	809	[train]  epoch 16/100,  batch 161/188,  loss_train=2.50815,  acc_train=42.19%
2170.3s	810	[train]  epoch 16/100,  batch 171/188,  loss_train=2.88889,  acc_train=21.88%
2175.8s	811	[train]  epoch 16/100,  batch 181/188,  loss_train=2.32266,  acc_train=31.25%
2180.4s	812	[ val ]  epoch 16/100,  batch 1/135,  loss_val=4.31750,  acc_val=6.25%
2182.2s	813	[ val ]  epoch 16/100,  batch 11/135,  loss_val=2.72002,  acc_val=21.88%
2184.0s	814	[ val ]  epoch 16/100,  batch 21/135,  loss_val=1.30746,  acc_val=62.50%
2185.8s	815	[ val ]  epoch 16/100,  batch 31/135,  loss_val=2.10395,  acc_val=48.44%
2187.6s	816	[ val ]  epoch 16/100,  batch 41/135,  loss_val=2.18494,  acc_val=45.31%
2189.3s	817	[ val ]  epoch 16/100,  batch 51/135,  loss_val=3.10174,  acc_val=28.12%
2191.1s	818	[ val ]  epoch 16/100,  batch 61/135,  loss_val=3.35575,  acc_val=23.44%
2192.8s	819	[ val ]  epoch 16/100,  batch 71/135,  loss_val=3.23830,  acc_val=10.94%
2194.6s	820	[ val ]  epoch 16/100,  batch 81/135,  loss_val=3.42645,  acc_val=37.50%
2196.4s	821	[ val ]  epoch 16/100,  batch 91/135,  loss_val=2.88658,  acc_val=28.12%
2198.2s	822	[ val ]  epoch 16/100,  batch 101/135,  loss_val=0.36998,  acc_val=92.19%
2199.9s	823	[ val ]  epoch 16/100,  batch 111/135,  loss_val=3.36545,  acc_val=18.75%
2201.8s	824	[ val ]  epoch 16/100,  batch 121/135,  loss_val=2.85489,  acc_val=32.81%
2203.5s	825	[ val ]  epoch 16/100,  batch 131/135,  loss_val=3.06989,  acc_val=45.31%
2204.1s	826	===================================================================================================================
2204.1s	827	Epoch 16/100 summary: loss_train=2.67130, acc_train=29.85%, loss_val=2.89, acc_val=25.97% (best: 25.97% @ epoch 16)
2204.1s	828	===================================================================================================================
2204.1s	829	Starting epoch 17/100, learning_rate=0.1
2205.3s	830	[train]  epoch 17/100,  batch 1/188,  loss_train=2.35599,  acc_train=29.69%
2210.9s	831	[train]  epoch 17/100,  batch 11/188,  loss_train=2.41503,  acc_train=34.38%
2216.5s	832	[train]  epoch 17/100,  batch 21/188,  loss_train=2.66062,  acc_train=32.81%
2222.1s	833	[train]  epoch 17/100,  batch 31/188,  loss_train=2.53256,  acc_train=32.81%
2227.7s	834	[train]  epoch 17/100,  batch 41/188,  loss_train=2.56383,  acc_train=28.12%
2233.5s	835	[train]  epoch 17/100,  batch 51/188,  loss_train=2.58144,  acc_train=31.25%
2239.0s	836	[train]  epoch 17/100,  batch 61/188,  loss_train=2.61388,  acc_train=29.69%
2244.6s	837	[train]  epoch 17/100,  batch 71/188,  loss_train=2.21442,  acc_train=45.31%
2250.2s	838	[train]  epoch 17/100,  batch 81/188,  loss_train=2.55382,  acc_train=32.81%
2255.9s	839	[train]  epoch 17/100,  batch 91/188,  loss_train=2.44607,  acc_train=40.62%
2261.5s	840	[train]  epoch 17/100,  batch 101/188,  loss_train=2.56095,  acc_train=35.94%
2267.2s	841	[train]  epoch 17/100,  batch 111/188,  loss_train=2.24119,  acc_train=42.19%
2272.8s	842	[train]  epoch 17/100,  batch 121/188,  loss_train=2.65743,  acc_train=32.81%
2278.4s	843	[train]  epoch 17/100,  batch 131/188,  loss_train=2.50286,  acc_train=34.38%
2284.0s	844	[train]  epoch 17/100,  batch 141/188,  loss_train=2.54172,  acc_train=39.06%
2289.7s	845	[train]  epoch 17/100,  batch 151/188,  loss_train=2.38651,  acc_train=34.38%
2295.3s	846	[train]  epoch 17/100,  batch 161/188,  loss_train=2.61375,  acc_train=32.81%
2301.1s	847	[train]  epoch 17/100,  batch 171/188,  loss_train=2.51631,  acc_train=31.25%
2306.6s	848	[train]  epoch 17/100,  batch 181/188,  loss_train=2.22451,  acc_train=48.44%
2311.3s	849	[ val ]  epoch 17/100,  batch 1/135,  loss_val=3.48426,  acc_val=10.94%
2313.1s	850	[ val ]  epoch 17/100,  batch 11/135,  loss_val=2.74909,  acc_val=28.12%
2314.9s	851	[ val ]  epoch 17/100,  batch 21/135,  loss_val=1.95111,  acc_val=53.12%
2316.6s	852	[ val ]  epoch 17/100,  batch 31/135,  loss_val=2.18506,  acc_val=46.88%
2318.4s	853	[ val ]  epoch 17/100,  batch 41/135,  loss_val=3.48774,  acc_val=15.62%
2320.2s	854	[ val ]  epoch 17/100,  batch 51/135,  loss_val=2.66714,  acc_val=37.50%
2322.0s	855	[ val ]  epoch 17/100,  batch 61/135,  loss_val=3.69772,  acc_val=10.94%
2323.7s	856	[ val ]  epoch 17/100,  batch 71/135,  loss_val=2.72088,  acc_val=29.69%
2325.5s	857	[ val ]  epoch 17/100,  batch 81/135,  loss_val=2.90521,  acc_val=40.62%
2327.3s	858	[ val ]  epoch 17/100,  batch 91/135,  loss_val=3.03807,  acc_val=28.12%
2329.1s	859	[ val ]  epoch 17/100,  batch 101/135,  loss_val=1.19198,  acc_val=64.06%
2330.9s	860	[ val ]  epoch 17/100,  batch 111/135,  loss_val=3.39638,  acc_val=14.06%
2332.8s	861	[ val ]  epoch 17/100,  batch 121/135,  loss_val=2.65617,  acc_val=25.00%
2334.4s	862	[ val ]  epoch 17/100,  batch 131/135,  loss_val=3.28841,  acc_val=25.00%
2335.0s	863	===================================================================================================================
2335.0s	864	Epoch 17/100 summary: loss_train=2.53115, acc_train=32.93%, loss_val=2.97, acc_val=25.24% (best: 25.97% @ epoch 16)
2335.0s	865	===================================================================================================================
2335.0s	866	Starting epoch 18/100, learning_rate=0.1
2336.3s	867	[train]  epoch 18/100,  batch 1/188,  loss_train=2.65321,  acc_train=34.38%
2341.9s	868	[train]  epoch 18/100,  batch 11/188,  loss_train=2.55865,  acc_train=37.50%
2347.5s	869	[train]  epoch 18/100,  batch 21/188,  loss_train=2.33736,  acc_train=37.50%
2353.1s	870	[train]  epoch 18/100,  batch 31/188,  loss_train=2.57410,  acc_train=29.69%
2358.8s	871	[train]  epoch 18/100,  batch 41/188,  loss_train=2.35317,  acc_train=34.38%
2364.5s	872	[train]  epoch 18/100,  batch 51/188,  loss_train=2.43092,  acc_train=39.06%
2370.0s	873	[train]  epoch 18/100,  batch 61/188,  loss_train=2.33058,  acc_train=34.38%
2375.7s	874	[train]  epoch 18/100,  batch 71/188,  loss_train=2.40085,  acc_train=37.50%
2381.3s	875	[train]  epoch 18/100,  batch 81/188,  loss_train=2.28653,  acc_train=40.62%
2386.9s	876	[train]  epoch 18/100,  batch 91/188,  loss_train=2.42340,  acc_train=37.50%
2392.5s	877	[train]  epoch 18/100,  batch 101/188,  loss_train=2.35255,  acc_train=40.62%
2398.3s	878	[train]  epoch 18/100,  batch 111/188,  loss_train=2.38052,  acc_train=35.94%
2403.8s	879	[train]  epoch 18/100,  batch 121/188,  loss_train=2.47006,  acc_train=39.06%
2409.4s	880	[train]  epoch 18/100,  batch 131/188,  loss_train=2.31874,  acc_train=39.06%
2415.0s	881	[train]  epoch 18/100,  batch 141/188,  loss_train=2.45816,  acc_train=34.38%
2420.6s	882	[train]  epoch 18/100,  batch 151/188,  loss_train=2.56262,  acc_train=32.81%
2426.3s	883	[train]  epoch 18/100,  batch 161/188,  loss_train=2.62735,  acc_train=31.25%
2432.0s	884	[train]  epoch 18/100,  batch 171/188,  loss_train=2.59850,  acc_train=39.06%
2437.5s	885	[train]  epoch 18/100,  batch 181/188,  loss_train=2.39503,  acc_train=32.81%
2442.1s	886	[ val ]  epoch 18/100,  batch 1/135,  loss_val=4.54848,  acc_val=6.25%
2443.9s	887	[ val ]  epoch 18/100,  batch 11/135,  loss_val=4.11249,  acc_val=7.81%
2445.7s	888	[ val ]  epoch 18/100,  batch 21/135,  loss_val=2.94389,  acc_val=25.00%
2447.5s	889	[ val ]  epoch 18/100,  batch 31/135,  loss_val=5.31714,  acc_val=1.56%
2449.2s	890	[ val ]  epoch 18/100,  batch 41/135,  loss_val=3.73802,  acc_val=18.75%
2451.0s	891	[ val ]  epoch 18/100,  batch 51/135,  loss_val=3.96932,  acc_val=7.81%
2452.8s	892	[ val ]  epoch 18/100,  batch 61/135,  loss_val=3.93618,  acc_val=15.62%
2454.5s	893	[ val ]  epoch 18/100,  batch 71/135,  loss_val=5.06179,  acc_val=1.56%
2456.3s	894	[ val ]  epoch 18/100,  batch 81/135,  loss_val=2.32964,  acc_val=45.31%
2458.1s	895	[ val ]  epoch 18/100,  batch 91/135,  loss_val=5.11554,  acc_val=4.69%
2459.9s	896	[ val ]  epoch 18/100,  batch 101/135,  loss_val=3.77173,  acc_val=12.50%
2461.8s	897	[ val ]  epoch 18/100,  batch 111/135,  loss_val=3.62040,  acc_val=23.44%
2463.7s	898	[ val ]  epoch 18/100,  batch 121/135,  loss_val=3.71913,  acc_val=20.31%
2465.3s	899	[ val ]  epoch 18/100,  batch 131/135,  loss_val=4.85219,  acc_val=12.50%
2466.0s	900	===================================================================================================================
2466.0s	901	Epoch 18/100 summary: loss_train=2.42330, acc_train=35.21%, loss_val=3.74, acc_val=16.99% (best: 25.97% @ epoch 16)
2466.0s	902	===================================================================================================================
2466.0s	903	Starting epoch 19/100, learning_rate=0.1
2467.2s	904	[train]  epoch 19/100,  batch 1/188,  loss_train=2.43685,  acc_train=35.94%
2472.8s	905	[train]  epoch 19/100,  batch 11/188,  loss_train=2.28814,  acc_train=39.06%
2478.5s	906	[train]  epoch 19/100,  batch 21/188,  loss_train=2.51491,  acc_train=25.00%
2484.1s	907	[train]  epoch 19/100,  batch 31/188,  loss_train=2.62108,  acc_train=34.38%
2489.7s	908	[train]  epoch 19/100,  batch 41/188,  loss_train=2.32722,  acc_train=34.38%
2495.5s	909	[train]  epoch 19/100,  batch 51/188,  loss_train=2.40108,  acc_train=31.25%
2501.0s	910	[train]  epoch 19/100,  batch 61/188,  loss_train=2.15302,  acc_train=42.19%
2506.6s	911	[train]  epoch 19/100,  batch 71/188,  loss_train=2.25230,  acc_train=37.50%
2512.2s	912	[train]  epoch 19/100,  batch 81/188,  loss_train=1.86985,  acc_train=46.88%
2517.9s	913	[train]  epoch 19/100,  batch 91/188,  loss_train=2.53621,  acc_train=31.25%
2523.5s	914	[train]  epoch 19/100,  batch 101/188,  loss_train=2.68893,  acc_train=32.81%
2529.2s	915	[train]  epoch 19/100,  batch 111/188,  loss_train=2.61928,  acc_train=28.12%
2534.8s	916	[train]  epoch 19/100,  batch 121/188,  loss_train=2.39244,  acc_train=31.25%
2540.4s	917	[train]  epoch 19/100,  batch 131/188,  loss_train=2.25306,  acc_train=34.38%
2546.0s	918	[train]  epoch 19/100,  batch 141/188,  loss_train=2.61778,  acc_train=35.94%
2551.7s	919	[train]  epoch 19/100,  batch 151/188,  loss_train=2.57083,  acc_train=37.50%
2557.3s	920	[train]  epoch 19/100,  batch 161/188,  loss_train=2.45160,  acc_train=31.25%
2563.0s	921	[train]  epoch 19/100,  batch 171/188,  loss_train=2.22748,  acc_train=28.12%
2568.6s	922	[train]  epoch 19/100,  batch 181/188,  loss_train=2.16516,  acc_train=46.88%
2573.2s	923	[ val ]  epoch 19/100,  batch 1/135,  loss_val=4.06087,  acc_val=6.25%
2575.0s	924	[ val ]  epoch 19/100,  batch 11/135,  loss_val=2.87149,  acc_val=34.38%
2576.8s	925	[ val ]  epoch 19/100,  batch 21/135,  loss_val=1.73693,  acc_val=43.75%
2578.6s	926	[ val ]  epoch 19/100,  batch 31/135,  loss_val=2.65891,  acc_val=29.69%
2580.3s	927	[ val ]  epoch 19/100,  batch 41/135,  loss_val=2.37968,  acc_val=32.81%
2582.1s	928	[ val ]  epoch 19/100,  batch 51/135,  loss_val=1.95525,  acc_val=42.19%
2583.9s	929	[ val ]  epoch 19/100,  batch 61/135,  loss_val=3.22302,  acc_val=20.31%
2585.7s	930	[ val ]  epoch 19/100,  batch 71/135,  loss_val=3.03367,  acc_val=20.31%
2587.5s	931	[ val ]  epoch 19/100,  batch 81/135,  loss_val=3.68823,  acc_val=12.50%
2589.3s	932	[ val ]  epoch 19/100,  batch 91/135,  loss_val=4.12538,  acc_val=1.56%
2591.2s	933	[ val ]  epoch 19/100,  batch 101/135,  loss_val=1.40707,  acc_val=54.69%
2593.0s	934	[ val ]  epoch 19/100,  batch 111/135,  loss_val=3.07223,  acc_val=7.81%
2594.8s	935	[ val ]  epoch 19/100,  batch 121/135,  loss_val=1.58030,  acc_val=64.06%
2596.5s	936	[ val ]  epoch 19/100,  batch 131/135,  loss_val=2.90942,  acc_val=28.12%
2597.1s	937	===================================================================================================================
2597.1s	938	Epoch 19/100 summary: loss_train=2.33216, acc_train=36.79%, loss_val=2.65, acc_val=30.03% (best: 30.03% @ epoch 19)
2597.1s	939	===================================================================================================================
2597.1s	940	Starting epoch 20/100, learning_rate=0.1
2598.4s	941	[train]  epoch 20/100,  batch 1/188,  loss_train=2.07374,  acc_train=43.75%
2604.0s	942	[train]  epoch 20/100,  batch 11/188,  loss_train=2.33193,  acc_train=42.19%
2609.6s	943	[train]  epoch 20/100,  batch 21/188,  loss_train=2.07719,  acc_train=45.31%
2615.2s	944	[train]  epoch 20/100,  batch 31/188,  loss_train=2.17790,  acc_train=50.00%
2620.9s	945	[train]  epoch 20/100,  batch 41/188,  loss_train=2.57669,  acc_train=39.06%
2626.6s	946	[train]  epoch 20/100,  batch 51/188,  loss_train=2.25536,  acc_train=42.19%
2632.1s	947	[train]  epoch 20/100,  batch 61/188,  loss_train=2.14930,  acc_train=42.19%
2637.8s	948	[train]  epoch 20/100,  batch 71/188,  loss_train=2.35060,  acc_train=32.81%
2643.4s	949	[train]  epoch 20/100,  batch 81/188,  loss_train=2.09960,  acc_train=42.19%
2649.0s	950	[train]  epoch 20/100,  batch 91/188,  loss_train=1.95923,  acc_train=39.06%
2654.7s	951	[train]  epoch 20/100,  batch 101/188,  loss_train=2.36156,  acc_train=35.94%
2660.4s	952	[train]  epoch 20/100,  batch 111/188,  loss_train=2.16030,  acc_train=39.06%
2665.9s	953	[train]  epoch 20/100,  batch 121/188,  loss_train=2.32097,  acc_train=42.19%
2671.5s	954	[train]  epoch 20/100,  batch 131/188,  loss_train=2.23946,  acc_train=34.38%
2677.1s	955	[train]  epoch 20/100,  batch 141/188,  loss_train=2.07252,  acc_train=40.62%
2682.7s	956	[train]  epoch 20/100,  batch 151/188,  loss_train=2.22728,  acc_train=40.62%
2688.3s	957	[train]  epoch 20/100,  batch 161/188,  loss_train=1.94722,  acc_train=42.19%
2694.1s	958	[train]  epoch 20/100,  batch 171/188,  loss_train=1.99859,  acc_train=46.88%
2699.6s	959	[train]  epoch 20/100,  batch 181/188,  loss_train=2.00206,  acc_train=54.69%
2704.2s	960	[ val ]  epoch 20/100,  batch 1/135,  loss_val=3.89586,  acc_val=7.81%
2706.0s	961	[ val ]  epoch 20/100,  batch 11/135,  loss_val=3.68748,  acc_val=17.19%
2707.8s	962	[ val ]  epoch 20/100,  batch 21/135,  loss_val=1.65444,  acc_val=56.25%
2709.6s	963	[ val ]  epoch 20/100,  batch 31/135,  loss_val=1.99778,  acc_val=48.44%
2711.4s	964	[ val ]  epoch 20/100,  batch 41/135,  loss_val=1.37304,  acc_val=65.62%
2713.2s	965	[ val ]  epoch 20/100,  batch 51/135,  loss_val=2.38905,  acc_val=34.38%
2715.0s	966	[ val ]  epoch 20/100,  batch 61/135,  loss_val=3.38206,  acc_val=20.31%
2716.7s	967	[ val ]  epoch 20/100,  batch 71/135,  loss_val=2.87867,  acc_val=28.12%
2718.6s	968	[ val ]  epoch 20/100,  batch 81/135,  loss_val=3.95625,  acc_val=21.88%
2720.4s	969	[ val ]  epoch 20/100,  batch 91/135,  loss_val=3.39739,  acc_val=21.88%
2722.2s	970	[ val ]  epoch 20/100,  batch 101/135,  loss_val=2.75891,  acc_val=7.81%
2723.9s	971	[ val ]  epoch 20/100,  batch 111/135,  loss_val=3.30970,  acc_val=18.75%
2725.8s	972	[ val ]  epoch 20/100,  batch 121/135,  loss_val=3.21395,  acc_val=18.75%
2727.4s	973	[ val ]  epoch 20/100,  batch 131/135,  loss_val=3.02719,  acc_val=40.62%
2728.0s	974	===================================================================================================================
2728.0s	975	Epoch 20/100 summary: loss_train=2.25695, acc_train=38.69%, loss_val=2.75, acc_val=29.20% (best: 30.03% @ epoch 19)
2728.0s	976	===================================================================================================================
2728.0s	977	Starting epoch 21/100, learning_rate=0.1
2729.2s	978	[train]  epoch 21/100,  batch 1/188,  loss_train=2.04077,  acc_train=48.44%
2734.9s	979	[train]  epoch 21/100,  batch 11/188,  loss_train=2.25502,  acc_train=43.75%
2740.5s	980	[train]  epoch 21/100,  batch 21/188,  loss_train=2.32875,  acc_train=35.94%
2746.1s	981	[train]  epoch 21/100,  batch 31/188,  loss_train=2.10788,  acc_train=45.31%
2751.7s	982	[train]  epoch 21/100,  batch 41/188,  loss_train=2.13462,  acc_train=42.19%
2757.5s	983	[train]  epoch 21/100,  batch 51/188,  loss_train=2.27027,  acc_train=35.94%
2763.0s	984	[train]  epoch 21/100,  batch 61/188,  loss_train=2.23387,  acc_train=35.94%
2768.6s	985	[train]  epoch 21/100,  batch 71/188,  loss_train=1.95448,  acc_train=37.50%
2774.2s	986	[train]  epoch 21/100,  batch 81/188,  loss_train=1.79193,  acc_train=53.12%
2779.8s	987	[train]  epoch 21/100,  batch 91/188,  loss_train=2.25317,  acc_train=37.50%
2785.5s	988	[train]  epoch 21/100,  batch 101/188,  loss_train=2.14835,  acc_train=34.38%
2791.2s	989	[train]  epoch 21/100,  batch 111/188,  loss_train=2.48987,  acc_train=28.12%
2796.7s	990	[train]  epoch 21/100,  batch 121/188,  loss_train=1.88612,  acc_train=48.44%
2802.4s	991	[train]  epoch 21/100,  batch 131/188,  loss_train=2.17920,  acc_train=42.19%
2808.0s	992	[train]  epoch 21/100,  batch 141/188,  loss_train=1.91924,  acc_train=43.75%
2813.6s	993	[train]  epoch 21/100,  batch 151/188,  loss_train=2.46410,  acc_train=28.12%
2819.2s	994	[train]  epoch 21/100,  batch 161/188,  loss_train=2.46715,  acc_train=35.94%
2825.0s	995	[train]  epoch 21/100,  batch 171/188,  loss_train=2.31471,  acc_train=39.06%
2830.5s	996	[train]  epoch 21/100,  batch 181/188,  loss_train=2.05947,  acc_train=45.31%
2835.1s	997	[ val ]  epoch 21/100,  batch 1/135,  loss_val=3.44967,  acc_val=10.94%
2836.9s	998	[ val ]  epoch 21/100,  batch 11/135,  loss_val=3.10375,  acc_val=20.31%
2838.7s	999	[ val ]  epoch 21/100,  batch 21/135,  loss_val=2.20846,  acc_val=25.00%
2840.4s	1000	[ val ]  epoch 21/100,  batch 31/135,  loss_val=2.63278,  acc_val=34.38%
2842.2s	1001	[ val ]  epoch 21/100,  batch 41/135,  loss_val=3.30420,  acc_val=23.44%
2844.0s	1002	[ val ]  epoch 21/100,  batch 51/135,  loss_val=3.39923,  acc_val=25.00%
2845.9s	1003	[ val ]  epoch 21/100,  batch 61/135,  loss_val=3.04621,  acc_val=39.06%
2847.7s	1004	[ val ]  epoch 21/100,  batch 71/135,  loss_val=2.23765,  acc_val=31.25%
2849.5s	1005	[ val ]  epoch 21/100,  batch 81/135,  loss_val=3.99146,  acc_val=25.00%
2851.2s	1006	[ val ]  epoch 21/100,  batch 91/135,  loss_val=3.44667,  acc_val=14.06%
2853.0s	1007	[ val ]  epoch 21/100,  batch 101/135,  loss_val=0.34569,  acc_val=92.19%
2854.8s	1008	[ val ]  epoch 21/100,  batch 111/135,  loss_val=2.68589,  acc_val=28.12%
2856.7s	1009	[ val ]  epoch 21/100,  batch 121/135,  loss_val=1.99696,  acc_val=46.88%
2858.4s	1010	[ val ]  epoch 21/100,  batch 131/135,  loss_val=3.30455,  acc_val=25.00%
2859.0s	1011	===================================================================================================================
2859.0s	1012	Epoch 21/100 summary: loss_train=2.17080, acc_train=40.09%, loss_val=2.71, acc_val=30.51% (best: 30.51% @ epoch 21)
2859.0s	1013	===================================================================================================================
2859.0s	1014	Starting epoch 22/100, learning_rate=0.1
2860.2s	1015	[train]  epoch 22/100,  batch 1/188,  loss_train=1.95960,  acc_train=48.44%
2865.8s	1016	[train]  epoch 22/100,  batch 11/188,  loss_train=1.73839,  acc_train=45.31%
2871.5s	1017	[train]  epoch 22/100,  batch 21/188,  loss_train=2.37010,  acc_train=29.69%
2877.1s	1018	[train]  epoch 22/100,  batch 31/188,  loss_train=2.34719,  acc_train=35.94%
2882.7s	1019	[train]  epoch 22/100,  batch 41/188,  loss_train=1.87721,  acc_train=48.44%
2888.4s	1020	[train]  epoch 22/100,  batch 51/188,  loss_train=1.67437,  acc_train=60.94%
2894.0s	1021	[train]  epoch 22/100,  batch 61/188,  loss_train=1.87240,  acc_train=43.75%
2899.7s	1022	[train]  epoch 22/100,  batch 71/188,  loss_train=2.25300,  acc_train=40.62%
2905.3s	1023	[train]  epoch 22/100,  batch 81/188,  loss_train=1.83598,  acc_train=51.56%
2911.0s	1024	[train]  epoch 22/100,  batch 91/188,  loss_train=2.28203,  acc_train=35.94%
2916.6s	1025	[train]  epoch 22/100,  batch 101/188,  loss_train=1.84411,  acc_train=50.00%
2922.3s	1026	[train]  epoch 22/100,  batch 111/188,  loss_train=2.19790,  acc_train=42.19%
2927.9s	1027	[train]  epoch 22/100,  batch 121/188,  loss_train=2.36237,  acc_train=32.81%
2933.5s	1028	[train]  epoch 22/100,  batch 131/188,  loss_train=2.03737,  acc_train=39.06%
2939.1s	1029	[train]  epoch 22/100,  batch 141/188,  loss_train=2.23852,  acc_train=37.50%
2944.7s	1030	[train]  epoch 22/100,  batch 151/188,  loss_train=1.92552,  acc_train=56.25%
2950.3s	1031	[train]  epoch 22/100,  batch 161/188,  loss_train=2.11609,  acc_train=40.62%
2956.1s	1032	[train]  epoch 22/100,  batch 171/188,  loss_train=1.69181,  acc_train=42.19%
2961.6s	1033	[train]  epoch 22/100,  batch 181/188,  loss_train=2.02705,  acc_train=46.88%
2966.3s	1034	[ val ]  epoch 22/100,  batch 1/135,  loss_val=2.30796,  acc_val=43.75%
2968.1s	1035	[ val ]  epoch 22/100,  batch 11/135,  loss_val=1.43492,  acc_val=54.69%
2969.8s	1036	[ val ]  epoch 22/100,  batch 21/135,  loss_val=1.55328,  acc_val=48.44%
2971.7s	1037	[ val ]  epoch 22/100,  batch 31/135,  loss_val=3.81980,  acc_val=18.75%
2973.6s	1038	[ val ]  epoch 22/100,  batch 41/135,  loss_val=2.23861,  acc_val=40.62%
2975.4s	1039	[ val ]  epoch 22/100,  batch 51/135,  loss_val=2.06098,  acc_val=46.88%
2977.1s	1040	[ val ]  epoch 22/100,  batch 61/135,  loss_val=3.88058,  acc_val=9.38%
2978.9s	1041	[ val ]  epoch 22/100,  batch 71/135,  loss_val=2.67806,  acc_val=26.56%
2980.7s	1042	[ val ]  epoch 22/100,  batch 81/135,  loss_val=2.98656,  acc_val=28.12%
2982.5s	1043	[ val ]  epoch 22/100,  batch 91/135,  loss_val=2.47805,  acc_val=26.56%
2984.3s	1044	[ val ]  epoch 22/100,  batch 101/135,  loss_val=0.78081,  acc_val=73.44%
2986.0s	1045	[ val ]  epoch 22/100,  batch 111/135,  loss_val=3.13513,  acc_val=25.00%
2987.9s	1046	[ val ]  epoch 22/100,  batch 121/135,  loss_val=1.62139,  acc_val=60.94%
2989.5s	1047	[ val ]  epoch 22/100,  batch 131/135,  loss_val=2.54267,  acc_val=35.94%
2990.2s	1048	===================================================================================================================
2990.2s	1049	Epoch 22/100 summary: loss_train=2.06462, acc_train=43.04%, loss_val=2.65, acc_val=32.42% (best: 32.42% @ epoch 22)
2990.2s	1050	===================================================================================================================
2990.2s	1051	Starting epoch 23/100, learning_rate=0.1
2991.5s	1052	[train]  epoch 23/100,  batch 1/188,  loss_train=1.81921,  acc_train=48.44%
2997.1s	1053	[train]  epoch 23/100,  batch 11/188,  loss_train=1.90201,  acc_train=42.19%
3002.8s	1054	[train]  epoch 23/100,  batch 21/188,  loss_train=1.89083,  acc_train=46.88%
3008.4s	1055	[train]  epoch 23/100,  batch 31/188,  loss_train=2.08153,  acc_train=40.62%
3014.0s	1056	[train]  epoch 23/100,  batch 41/188,  loss_train=1.83501,  acc_train=48.44%
3019.7s	1057	[train]  epoch 23/100,  batch 51/188,  loss_train=2.24771,  acc_train=37.50%
3025.2s	1058	[train]  epoch 23/100,  batch 61/188,  loss_train=1.82244,  acc_train=46.88%
3030.8s	1059	[train]  epoch 23/100,  batch 71/188,  loss_train=1.77744,  acc_train=51.56%
3036.5s	1060	[train]  epoch 23/100,  batch 81/188,  loss_train=1.71081,  acc_train=53.12%
3042.1s	1061	[train]  epoch 23/100,  batch 91/188,  loss_train=2.22650,  acc_train=42.19%
3047.7s	1062	[train]  epoch 23/100,  batch 101/188,  loss_train=2.15002,  acc_train=39.06%
3053.4s	1063	[train]  epoch 23/100,  batch 111/188,  loss_train=1.98715,  acc_train=43.75%
3059.0s	1064	[train]  epoch 23/100,  batch 121/188,  loss_train=1.92800,  acc_train=46.88%
3064.6s	1065	[train]  epoch 23/100,  batch 131/188,  loss_train=1.95936,  acc_train=37.50%
3070.2s	1066	[train]  epoch 23/100,  batch 141/188,  loss_train=2.13969,  acc_train=45.31%
3075.9s	1067	[train]  epoch 23/100,  batch 151/188,  loss_train=1.92955,  acc_train=56.25%
3081.5s	1068	[train]  epoch 23/100,  batch 161/188,  loss_train=1.91595,  acc_train=35.94%
3087.2s	1069	[train]  epoch 23/100,  batch 171/188,  loss_train=1.86302,  acc_train=56.25%
3092.6s	1070	[train]  epoch 23/100,  batch 181/188,  loss_train=1.87150,  acc_train=50.00%
3097.3s	1071	[ val ]  epoch 23/100,  batch 1/135,  loss_val=4.41957,  acc_val=3.12%
3099.1s	1072	[ val ]  epoch 23/100,  batch 11/135,  loss_val=2.89086,  acc_val=35.94%
3101.0s	1073	[ val ]  epoch 23/100,  batch 21/135,  loss_val=2.59745,  acc_val=34.38%
3102.9s	1074	[ val ]  epoch 23/100,  batch 31/135,  loss_val=3.89677,  acc_val=18.75%
3104.6s	1075	[ val ]  epoch 23/100,  batch 41/135,  loss_val=1.80078,  acc_val=51.56%
3106.4s	1076	[ val ]  epoch 23/100,  batch 51/135,  loss_val=2.56418,  acc_val=37.50%
3108.2s	1077	[ val ]  epoch 23/100,  batch 61/135,  loss_val=3.39853,  acc_val=21.88%
3110.0s	1078	[ val ]  epoch 23/100,  batch 71/135,  loss_val=3.00458,  acc_val=15.62%
3111.8s	1079	[ val ]  epoch 23/100,  batch 81/135,  loss_val=3.08187,  acc_val=18.75%
3113.6s	1080	[ val ]  epoch 23/100,  batch 91/135,  loss_val=3.65870,  acc_val=17.19%
3115.4s	1081	[ val ]  epoch 23/100,  batch 101/135,  loss_val=2.71416,  acc_val=26.56%
3117.1s	1082	[ val ]  epoch 23/100,  batch 111/135,  loss_val=3.17778,  acc_val=25.00%
3119.1s	1083	[ val ]  epoch 23/100,  batch 121/135,  loss_val=2.06603,  acc_val=43.75%
3120.7s	1084	[ val ]  epoch 23/100,  batch 131/135,  loss_val=3.33603,  acc_val=21.88%
3121.3s	1085	===================================================================================================================
3121.3s	1086	Epoch 23/100 summary: loss_train=1.99364, acc_train=44.73%, loss_val=2.88, acc_val=28.77% (best: 32.42% @ epoch 22)
3121.3s	1087	===================================================================================================================
3121.3s	1088	Starting epoch 24/100, learning_rate=0.1
3122.6s	1089	[train]  epoch 24/100,  batch 1/188,  loss_train=1.68412,  acc_train=57.81%
3128.2s	1090	[train]  epoch 24/100,  batch 11/188,  loss_train=2.17709,  acc_train=40.62%
3133.9s	1091	[train]  epoch 24/100,  batch 21/188,  loss_train=1.72006,  acc_train=57.81%
3139.5s	1092	[train]  epoch 24/100,  batch 31/188,  loss_train=1.66181,  acc_train=51.56%
3145.1s	1093	[train]  epoch 24/100,  batch 41/188,  loss_train=1.77739,  acc_train=43.75%
3150.8s	1094	[train]  epoch 24/100,  batch 51/188,  loss_train=1.76664,  acc_train=56.25%
3156.3s	1095	[train]  epoch 24/100,  batch 61/188,  loss_train=1.58790,  acc_train=51.56%
3162.0s	1096	[train]  epoch 24/100,  batch 71/188,  loss_train=1.67593,  acc_train=50.00%
3167.6s	1097	[train]  epoch 24/100,  batch 81/188,  loss_train=2.21340,  acc_train=34.38%
3173.2s	1098	[train]  epoch 24/100,  batch 91/188,  loss_train=2.25483,  acc_train=37.50%
3178.7s	1099	[train]  epoch 24/100,  batch 101/188,  loss_train=2.06496,  acc_train=42.19%
3184.5s	1100	[train]  epoch 24/100,  batch 111/188,  loss_train=1.85667,  acc_train=51.56%
3190.0s	1101	[train]  epoch 24/100,  batch 121/188,  loss_train=2.31146,  acc_train=34.38%
3195.6s	1102	[train]  epoch 24/100,  batch 131/188,  loss_train=1.84946,  acc_train=37.50%
3201.3s	1103	[train]  epoch 24/100,  batch 141/188,  loss_train=2.10015,  acc_train=40.62%
3206.9s	1104	[train]  epoch 24/100,  batch 151/188,  loss_train=2.09970,  acc_train=42.19%
3212.5s	1105	[train]  epoch 24/100,  batch 161/188,  loss_train=1.64330,  acc_train=51.56%
3218.3s	1106	[train]  epoch 24/100,  batch 171/188,  loss_train=1.58955,  acc_train=51.56%
3223.8s	1107	[train]  epoch 24/100,  batch 181/188,  loss_train=1.94837,  acc_train=48.44%
3228.7s	1108	[ val ]  epoch 24/100,  batch 1/135,  loss_val=3.88681,  acc_val=18.75%
3230.7s	1109	[ val ]  epoch 24/100,  batch 11/135,  loss_val=2.65504,  acc_val=37.50%
3232.4s	1110	[ val ]  epoch 24/100,  batch 21/135,  loss_val=2.62985,  acc_val=26.56%
3234.2s	1111	[ val ]  epoch 24/100,  batch 31/135,  loss_val=2.07664,  acc_val=43.75%
3236.0s	1112	[ val ]  epoch 24/100,  batch 41/135,  loss_val=1.86443,  acc_val=51.56%
3237.8s	1113	[ val ]  epoch 24/100,  batch 51/135,  loss_val=1.97916,  acc_val=42.19%
3239.6s	1114	[ val ]  epoch 24/100,  batch 61/135,  loss_val=4.60149,  acc_val=1.56%
3241.4s	1115	[ val ]  epoch 24/100,  batch 71/135,  loss_val=4.28723,  acc_val=9.38%
3243.2s	1116	[ val ]  epoch 24/100,  batch 81/135,  loss_val=2.54550,  acc_val=50.00%
3244.9s	1117	[ val ]  epoch 24/100,  batch 91/135,  loss_val=3.34784,  acc_val=14.06%
3246.7s	1118	[ val ]  epoch 24/100,  batch 101/135,  loss_val=1.96464,  acc_val=32.81%
3248.6s	1119	[ val ]  epoch 24/100,  batch 111/135,  loss_val=3.67658,  acc_val=10.94%
3250.3s	1120	[ val ]  epoch 24/100,  batch 121/135,  loss_val=1.87913,  acc_val=45.31%
3252.0s	1121	[ val ]  epoch 24/100,  batch 131/135,  loss_val=3.60886,  acc_val=14.06%
3252.7s	1122	===================================================================================================================
3252.7s	1123	Epoch 24/100 summary: loss_train=1.93682, acc_train=45.80%, loss_val=2.62, acc_val=32.95% (best: 32.95% @ epoch 24)
3252.7s	1124	===================================================================================================================
3252.7s	1125	Starting epoch 25/100, learning_rate=0.1
3253.9s	1126	[train]  epoch 25/100,  batch 1/188,  loss_train=1.68038,  acc_train=57.81%
3259.6s	1127	[train]  epoch 25/100,  batch 11/188,  loss_train=1.82090,  acc_train=50.00%
3265.3s	1128	[train]  epoch 25/100,  batch 21/188,  loss_train=1.79238,  acc_train=48.44%
3270.9s	1129	[train]  epoch 25/100,  batch 31/188,  loss_train=1.91693,  acc_train=53.12%
3276.5s	1130	[train]  epoch 25/100,  batch 41/188,  loss_train=1.73098,  acc_train=54.69%
3282.2s	1131	[train]  epoch 25/100,  batch 51/188,  loss_train=1.55311,  acc_train=56.25%
3287.7s	1132	[train]  epoch 25/100,  batch 61/188,  loss_train=1.67570,  acc_train=53.12%
3293.4s	1133	[train]  epoch 25/100,  batch 71/188,  loss_train=1.78283,  acc_train=51.56%
3299.0s	1134	[train]  epoch 25/100,  batch 81/188,  loss_train=1.98531,  acc_train=42.19%
3304.6s	1135	[train]  epoch 25/100,  batch 91/188,  loss_train=1.64089,  acc_train=60.94%
3310.2s	1136	[train]  epoch 25/100,  batch 101/188,  loss_train=1.77448,  acc_train=53.12%
3316.0s	1137	[train]  epoch 25/100,  batch 111/188,  loss_train=2.00124,  acc_train=46.88%
3321.5s	1138	[train]  epoch 25/100,  batch 121/188,  loss_train=1.73696,  acc_train=46.88%
3327.2s	1139	[train]  epoch 25/100,  batch 131/188,  loss_train=1.95434,  acc_train=51.56%
3332.8s	1140	[train]  epoch 25/100,  batch 141/188,  loss_train=1.77873,  acc_train=62.50%
3338.4s	1141	[train]  epoch 25/100,  batch 151/188,  loss_train=1.92819,  acc_train=43.75%
3344.0s	1142	[train]  epoch 25/100,  batch 161/188,  loss_train=1.60413,  acc_train=54.69%
3349.8s	1143	[train]  epoch 25/100,  batch 171/188,  loss_train=1.90855,  acc_train=50.00%
3355.3s	1144	[train]  epoch 25/100,  batch 181/188,  loss_train=1.70115,  acc_train=51.56%
3359.9s	1145	[ val ]  epoch 25/100,  batch 1/135,  loss_val=3.70747,  acc_val=9.38%
3361.8s	1146	[ val ]  epoch 25/100,  batch 11/135,  loss_val=2.21832,  acc_val=42.19%
3363.5s	1147	[ val ]  epoch 25/100,  batch 21/135,  loss_val=2.05261,  acc_val=40.62%
3365.3s	1148	[ val ]  epoch 25/100,  batch 31/135,  loss_val=1.54589,  acc_val=59.38%
3367.1s	1149	[ val ]  epoch 25/100,  batch 41/135,  loss_val=1.55232,  acc_val=56.25%
3368.9s	1150	[ val ]  epoch 25/100,  batch 51/135,  loss_val=1.80028,  acc_val=45.31%
3370.6s	1151	[ val ]  epoch 25/100,  batch 61/135,  loss_val=3.18778,  acc_val=18.75%
3372.4s	1152	[ val ]  epoch 25/100,  batch 71/135,  loss_val=2.48998,  acc_val=42.19%
3374.2s	1153	[ val ]  epoch 25/100,  batch 81/135,  loss_val=3.74313,  acc_val=21.88%
3376.0s	1154	[ val ]  epoch 25/100,  batch 91/135,  loss_val=2.80004,  acc_val=23.44%
3377.8s	1155	[ val ]  epoch 25/100,  batch 101/135,  loss_val=0.44694,  acc_val=89.06%
3379.5s	1156	[ val ]  epoch 25/100,  batch 111/135,  loss_val=2.59384,  acc_val=39.06%
3381.5s	1157	[ val ]  epoch 25/100,  batch 121/135,  loss_val=1.90932,  acc_val=54.69%
3383.1s	1158	[ val ]  epoch 25/100,  batch 131/135,  loss_val=2.22380,  acc_val=43.75%
3383.7s	1159	===================================================================================================================
3383.7s	1160	Epoch 25/100 summary: loss_train=1.85542, acc_train=47.72%, loss_val=2.56, acc_val=34.07% (best: 34.07% @ epoch 25)
3383.7s	1161	===================================================================================================================
3383.7s	1162	Starting epoch 26/100, learning_rate=0.1
3384.9s	1163	[train]  epoch 26/100,  batch 1/188,  loss_train=1.44181,  acc_train=56.25%
3390.6s	1164	[train]  epoch 26/100,  batch 11/188,  loss_train=1.74849,  acc_train=54.69%
3396.2s	1165	[train]  epoch 26/100,  batch 21/188,  loss_train=1.76429,  acc_train=54.69%
3401.8s	1166	[train]  epoch 26/100,  batch 31/188,  loss_train=1.70646,  acc_train=48.44%
3407.4s	1167	[train]  epoch 26/100,  batch 41/188,  loss_train=2.24270,  acc_train=35.94%
3413.1s	1168	[train]  epoch 26/100,  batch 51/188,  loss_train=1.46006,  acc_train=59.38%
3418.7s	1169	[train]  epoch 26/100,  batch 61/188,  loss_train=1.57980,  acc_train=51.56%
3424.3s	1170	[train]  epoch 26/100,  batch 71/188,  loss_train=1.39266,  acc_train=60.94%
3429.9s	1171	[train]  epoch 26/100,  batch 81/188,  loss_train=1.95058,  acc_train=46.88%
3435.5s	1172	[train]  epoch 26/100,  batch 91/188,  loss_train=1.50882,  acc_train=51.56%
3441.1s	1173	[train]  epoch 26/100,  batch 101/188,  loss_train=1.57000,  acc_train=56.25%
3446.9s	1174	[train]  epoch 26/100,  batch 111/188,  loss_train=2.07544,  acc_train=37.50%
3452.4s	1175	[train]  epoch 26/100,  batch 121/188,  loss_train=1.92175,  acc_train=45.31%
3458.0s	1176	[train]  epoch 26/100,  batch 131/188,  loss_train=1.46110,  acc_train=62.50%
3463.6s	1177	[train]  epoch 26/100,  batch 141/188,  loss_train=1.42871,  acc_train=57.81%
3469.2s	1178	[train]  epoch 26/100,  batch 151/188,  loss_train=1.55058,  acc_train=53.12%
3474.9s	1179	[train]  epoch 26/100,  batch 161/188,  loss_train=1.49839,  acc_train=51.56%
3480.6s	1180	[train]  epoch 26/100,  batch 171/188,  loss_train=1.82859,  acc_train=48.44%
3486.1s	1181	[train]  epoch 26/100,  batch 181/188,  loss_train=2.00354,  acc_train=45.31%
3490.8s	1182	[ val ]  epoch 26/100,  batch 1/135,  loss_val=3.37829,  acc_val=17.19%
3492.6s	1183	[ val ]  epoch 26/100,  batch 11/135,  loss_val=2.07090,  acc_val=50.00%
3494.4s	1184	[ val ]  epoch 26/100,  batch 21/135,  loss_val=2.00086,  acc_val=39.06%
3496.2s	1185	[ val ]  epoch 26/100,  batch 31/135,  loss_val=3.22546,  acc_val=29.69%
3498.0s	1186	[ val ]  epoch 26/100,  batch 41/135,  loss_val=2.39169,  acc_val=35.94%
3499.8s	1187	[ val ]  epoch 26/100,  batch 51/135,  loss_val=2.17257,  acc_val=37.50%
3501.6s	1188	[ val ]  epoch 26/100,  batch 61/135,  loss_val=2.76197,  acc_val=34.38%
3503.3s	1189	[ val ]  epoch 26/100,  batch 71/135,  loss_val=4.23350,  acc_val=6.25%
3505.1s	1190	[ val ]  epoch 26/100,  batch 81/135,  loss_val=2.95018,  acc_val=37.50%
3506.9s	1191	[ val ]  epoch 26/100,  batch 91/135,  loss_val=3.34342,  acc_val=17.19%
3508.7s	1192	[ val ]  epoch 26/100,  batch 101/135,  loss_val=1.85788,  acc_val=28.12%
3510.5s	1193	[ val ]  epoch 26/100,  batch 111/135,  loss_val=3.13013,  acc_val=18.75%
3512.5s	1194	[ val ]  epoch 26/100,  batch 121/135,  loss_val=1.12919,  acc_val=73.44%
3514.1s	1195	[ val ]  epoch 26/100,  batch 131/135,  loss_val=3.86795,  acc_val=21.88%
3514.7s	1196	===================================================================================================================
3514.7s	1197	Epoch 26/100 summary: loss_train=1.77000, acc_train=49.66%, loss_val=2.72, acc_val=31.57% (best: 34.07% @ epoch 25)
3514.7s	1198	===================================================================================================================
3514.7s	1199	Starting epoch 27/100, learning_rate=0.1
3516.3s	1200	[train]  epoch 27/100,  batch 1/188,  loss_train=1.55220,  acc_train=57.81%
3521.9s	1201	[train]  epoch 27/100,  batch 11/188,  loss_train=1.66414,  acc_train=53.12%
3527.5s	1202	[train]  epoch 27/100,  batch 21/188,  loss_train=1.50379,  acc_train=59.38%
3533.2s	1203	[train]  epoch 27/100,  batch 31/188,  loss_train=1.72599,  acc_train=56.25%
3538.8s	1204	[train]  epoch 27/100,  batch 41/188,  loss_train=1.54741,  acc_train=54.69%
3544.5s	1205	[train]  epoch 27/100,  batch 51/188,  loss_train=1.64214,  acc_train=56.25%
3550.0s	1206	[train]  epoch 27/100,  batch 61/188,  loss_train=1.56358,  acc_train=50.00%
3555.6s	1207	[train]  epoch 27/100,  batch 71/188,  loss_train=1.27249,  acc_train=65.62%
3561.3s	1208	[train]  epoch 27/100,  batch 81/188,  loss_train=1.78364,  acc_train=50.00%
3566.9s	1209	[train]  epoch 27/100,  batch 91/188,  loss_train=1.91154,  acc_train=39.06%
3572.5s	1210	[train]  epoch 27/100,  batch 101/188,  loss_train=1.68794,  acc_train=50.00%
3578.3s	1211	[train]  epoch 27/100,  batch 111/188,  loss_train=1.92472,  acc_train=46.88%
3583.8s	1212	[train]  epoch 27/100,  batch 121/188,  loss_train=1.81855,  acc_train=48.44%
3589.4s	1213	[train]  epoch 27/100,  batch 131/188,  loss_train=1.76936,  acc_train=50.00%
3595.0s	1214	[train]  epoch 27/100,  batch 141/188,  loss_train=1.75006,  acc_train=50.00%
3600.7s	1215	[train]  epoch 27/100,  batch 151/188,  loss_train=1.83988,  acc_train=50.00%
3606.3s	1216	[train]  epoch 27/100,  batch 161/188,  loss_train=1.34282,  acc_train=59.38%
3612.1s	1217	[train]  epoch 27/100,  batch 171/188,  loss_train=1.83210,  acc_train=48.44%
3617.5s	1218	[train]  epoch 27/100,  batch 181/188,  loss_train=1.36038,  acc_train=62.50%
3622.1s	1219	[ val ]  epoch 27/100,  batch 1/135,  loss_val=3.75373,  acc_val=20.31%
3623.9s	1220	[ val ]  epoch 27/100,  batch 11/135,  loss_val=3.22353,  acc_val=31.25%
3625.7s	1221	[ val ]  epoch 27/100,  batch 21/135,  loss_val=1.75886,  acc_val=50.00%
3627.5s	1222	[ val ]  epoch 27/100,  batch 31/135,  loss_val=3.43548,  acc_val=20.31%
3629.2s	1223	[ val ]  epoch 27/100,  batch 41/135,  loss_val=2.22935,  acc_val=43.75%
3631.0s	1224	[ val ]  epoch 27/100,  batch 51/135,  loss_val=3.07431,  acc_val=28.12%
3632.8s	1225	[ val ]  epoch 27/100,  batch 61/135,  loss_val=2.65840,  acc_val=42.19%
3634.6s	1226	[ val ]  epoch 27/100,  batch 71/135,  loss_val=3.98975,  acc_val=14.06%
3636.3s	1227	[ val ]  epoch 27/100,  batch 81/135,  loss_val=2.56055,  acc_val=53.12%
3638.1s	1228	[ val ]  epoch 27/100,  batch 91/135,  loss_val=1.88360,  acc_val=45.31%
3639.8s	1229	[ val ]  epoch 27/100,  batch 101/135,  loss_val=1.36404,  acc_val=54.69%
3641.6s	1230	[ val ]  epoch 27/100,  batch 111/135,  loss_val=2.63373,  acc_val=37.50%
3643.7s	1231	[ val ]  epoch 27/100,  batch 121/135,  loss_val=2.24879,  acc_val=45.31%
3645.2s	1232	[ val ]  epoch 27/100,  batch 131/135,  loss_val=4.04386,  acc_val=18.75%
3645.9s	1233	===================================================================================================================
3645.9s	1234	Epoch 27/100 summary: loss_train=1.70107, acc_train=51.79%, loss_val=2.64, acc_val=34.17% (best: 34.17% @ epoch 27)
3645.9s	1235	===================================================================================================================
3645.9s	1236	Starting epoch 28/100, learning_rate=0.1
3647.1s	1237	[train]  epoch 28/100,  batch 1/188,  loss_train=1.60750,  acc_train=57.81%
3652.8s	1238	[train]  epoch 28/100,  batch 11/188,  loss_train=1.60042,  acc_train=60.94%
3658.4s	1239	[train]  epoch 28/100,  batch 21/188,  loss_train=1.72420,  acc_train=48.44%
3664.1s	1240	[train]  epoch 28/100,  batch 31/188,  loss_train=1.12632,  acc_train=75.00%
3669.7s	1241	[train]  epoch 28/100,  batch 41/188,  loss_train=1.50278,  acc_train=50.00%
3675.5s	1242	[train]  epoch 28/100,  batch 51/188,  loss_train=1.35914,  acc_train=60.94%
3680.9s	1243	[train]  epoch 28/100,  batch 61/188,  loss_train=1.45125,  acc_train=62.50%
3686.5s	1244	[train]  epoch 28/100,  batch 71/188,  loss_train=1.76830,  acc_train=56.25%
3692.2s	1245	[train]  epoch 28/100,  batch 81/188,  loss_train=1.62676,  acc_train=53.12%
3697.8s	1246	[train]  epoch 28/100,  batch 91/188,  loss_train=1.94342,  acc_train=42.19%
3703.4s	1247	[train]  epoch 28/100,  batch 101/188,  loss_train=1.75784,  acc_train=51.56%
3709.2s	1248	[train]  epoch 28/100,  batch 111/188,  loss_train=1.77468,  acc_train=48.44%
3714.7s	1249	[train]  epoch 28/100,  batch 121/188,  loss_train=1.49759,  acc_train=56.25%
3720.4s	1250	[train]  epoch 28/100,  batch 131/188,  loss_train=1.16518,  acc_train=65.62%
3726.0s	1251	[train]  epoch 28/100,  batch 141/188,  loss_train=1.91965,  acc_train=40.62%
3731.6s	1252	[train]  epoch 28/100,  batch 151/188,  loss_train=1.68140,  acc_train=56.25%
3737.3s	1253	[train]  epoch 28/100,  batch 161/188,  loss_train=1.70885,  acc_train=50.00%
3742.9s	1254	[train]  epoch 28/100,  batch 171/188,  loss_train=2.16633,  acc_train=39.06%
3748.5s	1255	[train]  epoch 28/100,  batch 181/188,  loss_train=1.51907,  acc_train=60.94%
3753.1s	1256	[ val ]  epoch 28/100,  batch 1/135,  loss_val=2.20416,  acc_val=37.50%
3754.8s	1257	[ val ]  epoch 28/100,  batch 11/135,  loss_val=2.10880,  acc_val=46.88%
3756.6s	1258	[ val ]  epoch 28/100,  batch 21/135,  loss_val=1.99415,  acc_val=39.06%
3758.4s	1259	[ val ]  epoch 28/100,  batch 31/135,  loss_val=1.49481,  acc_val=57.81%
3760.2s	1260	[ val ]  epoch 28/100,  batch 41/135,  loss_val=1.94450,  acc_val=48.44%
3762.0s	1261	[ val ]  epoch 28/100,  batch 51/135,  loss_val=2.03872,  acc_val=51.56%
3763.8s	1262	[ val ]  epoch 28/100,  batch 61/135,  loss_val=2.35330,  acc_val=42.19%
3765.5s	1263	[ val ]  epoch 28/100,  batch 71/135,  loss_val=2.85312,  acc_val=28.12%
3767.3s	1264	[ val ]  epoch 28/100,  batch 81/135,  loss_val=2.58157,  acc_val=50.00%
3769.1s	1265	[ val ]  epoch 28/100,  batch 91/135,  loss_val=2.08314,  acc_val=28.12%
3771.0s	1266	[ val ]  epoch 28/100,  batch 101/135,  loss_val=0.37665,  acc_val=92.19%
3772.8s	1267	[ val ]  epoch 28/100,  batch 111/135,  loss_val=3.12947,  acc_val=29.69%
3774.7s	1268	[ val ]  epoch 28/100,  batch 121/135,  loss_val=2.09697,  acc_val=48.44%
3776.3s	1269	[ val ]  epoch 28/100,  batch 131/135,  loss_val=3.71138,  acc_val=23.44%
3776.9s	1270	===================================================================================================================
3776.9s	1271	Epoch 28/100 summary: loss_train=1.66751, acc_train=52.07%, loss_val=2.43, acc_val=38.88% (best: 38.88% @ epoch 28)
3776.9s	1272	===================================================================================================================
3776.9s	1273	Starting epoch 29/100, learning_rate=0.1
3778.1s	1274	[train]  epoch 29/100,  batch 1/188,  loss_train=1.61209,  acc_train=53.12%
3783.8s	1275	[train]  epoch 29/100,  batch 11/188,  loss_train=1.23989,  acc_train=60.94%
3789.4s	1276	[train]  epoch 29/100,  batch 21/188,  loss_train=1.31121,  acc_train=62.50%
3795.0s	1277	[train]  epoch 29/100,  batch 31/188,  loss_train=1.31968,  acc_train=62.50%
3800.7s	1278	[train]  epoch 29/100,  batch 41/188,  loss_train=1.50156,  acc_train=59.38%
3806.4s	1279	[train]  epoch 29/100,  batch 51/188,  loss_train=1.89801,  acc_train=45.31%
3812.0s	1280	[train]  epoch 29/100,  batch 61/188,  loss_train=1.64334,  acc_train=50.00%
3817.6s	1281	[train]  epoch 29/100,  batch 71/188,  loss_train=1.41732,  acc_train=54.69%
3823.2s	1282	[train]  epoch 29/100,  batch 81/188,  loss_train=1.59971,  acc_train=50.00%
3828.8s	1283	[train]  epoch 29/100,  batch 91/188,  loss_train=1.91188,  acc_train=39.06%
3834.4s	1284	[train]  epoch 29/100,  batch 101/188,  loss_train=1.32783,  acc_train=56.25%
3840.2s	1285	[train]  epoch 29/100,  batch 111/188,  loss_train=1.86723,  acc_train=42.19%
3845.7s	1286	[train]  epoch 29/100,  batch 121/188,  loss_train=1.53842,  acc_train=51.56%
3851.3s	1287	[train]  epoch 29/100,  batch 131/188,  loss_train=1.57657,  acc_train=68.75%
3856.9s	1288	[train]  epoch 29/100,  batch 141/188,  loss_train=1.62568,  acc_train=53.12%
3862.6s	1289	[train]  epoch 29/100,  batch 151/188,  loss_train=1.83140,  acc_train=51.56%
3868.2s	1290	[train]  epoch 29/100,  batch 161/188,  loss_train=1.88541,  acc_train=51.56%
3874.0s	1291	[train]  epoch 29/100,  batch 171/188,  loss_train=1.71367,  acc_train=45.31%
3879.5s	1292	[train]  epoch 29/100,  batch 181/188,  loss_train=1.62552,  acc_train=51.56%
3884.0s	1293	[ val ]  epoch 29/100,  batch 1/135,  loss_val=3.57369,  acc_val=23.44%
3885.8s	1294	[ val ]  epoch 29/100,  batch 11/135,  loss_val=2.96917,  acc_val=31.25%
3887.6s	1295	[ val ]  epoch 29/100,  batch 21/135,  loss_val=1.90852,  acc_val=45.31%
3889.4s	1296	[ val ]  epoch 29/100,  batch 31/135,  loss_val=1.14271,  acc_val=75.00%
3891.2s	1297	[ val ]  epoch 29/100,  batch 41/135,  loss_val=1.55138,  acc_val=59.38%
3892.9s	1298	[ val ]  epoch 29/100,  batch 51/135,  loss_val=2.22681,  acc_val=50.00%
3894.7s	1299	[ val ]  epoch 29/100,  batch 61/135,  loss_val=2.62495,  acc_val=32.81%
3896.5s	1300	[ val ]  epoch 29/100,  batch 71/135,  loss_val=2.49469,  acc_val=34.38%
3898.3s	1301	[ val ]  epoch 29/100,  batch 81/135,  loss_val=2.85701,  acc_val=31.25%
3900.2s	1302	[ val ]  epoch 29/100,  batch 91/135,  loss_val=2.77941,  acc_val=21.88%
3902.0s	1303	[ val ]  epoch 29/100,  batch 101/135,  loss_val=1.29819,  acc_val=54.69%
3903.8s	1304	[ val ]  epoch 29/100,  batch 111/135,  loss_val=1.97772,  acc_val=53.12%
3905.7s	1305	[ val ]  epoch 29/100,  batch 121/135,  loss_val=1.87867,  acc_val=54.69%
3907.3s	1306	[ val ]  epoch 29/100,  batch 131/135,  loss_val=2.41310,  acc_val=35.94%
3908.0s	1307	===================================================================================================================
3908.0s	1308	Epoch 29/100 summary: loss_train=1.59471, acc_train=54.01%, loss_val=2.32, acc_val=39.73% (best: 39.73% @ epoch 29)
3908.0s	1309	===================================================================================================================
3908.0s	1310	Starting epoch 30/100, learning_rate=0.1
3909.2s	1311	[train]  epoch 30/100,  batch 1/188,  loss_train=1.16010,  acc_train=71.88%
3914.9s	1312	[train]  epoch 30/100,  batch 11/188,  loss_train=1.57713,  acc_train=48.44%
3920.5s	1313	[train]  epoch 30/100,  batch 21/188,  loss_train=1.54692,  acc_train=56.25%
3926.1s	1314	[train]  epoch 30/100,  batch 31/188,  loss_train=1.58059,  acc_train=60.94%
3931.8s	1315	[train]  epoch 30/100,  batch 41/188,  loss_train=1.15092,  acc_train=68.75%
3937.5s	1316	[train]  epoch 30/100,  batch 51/188,  loss_train=1.85550,  acc_train=46.88%
3943.1s	1317	[train]  epoch 30/100,  batch 61/188,  loss_train=1.57121,  acc_train=57.81%
3948.8s	1318	[train]  epoch 30/100,  batch 71/188,  loss_train=1.28932,  acc_train=64.06%
3954.4s	1319	[train]  epoch 30/100,  batch 81/188,  loss_train=1.56990,  acc_train=48.44%
3960.0s	1320	[train]  epoch 30/100,  batch 91/188,  loss_train=1.44860,  acc_train=60.94%
3965.7s	1321	[train]  epoch 30/100,  batch 101/188,  loss_train=1.65114,  acc_train=45.31%
3971.4s	1322	[train]  epoch 30/100,  batch 111/188,  loss_train=1.49533,  acc_train=53.12%
3976.9s	1323	[train]  epoch 30/100,  batch 121/188,  loss_train=1.45371,  acc_train=65.62%
3982.5s	1324	[train]  epoch 30/100,  batch 131/188,  loss_train=1.40037,  acc_train=62.50%
3988.1s	1325	[train]  epoch 30/100,  batch 141/188,  loss_train=1.55196,  acc_train=56.25%
3993.8s	1326	[train]  epoch 30/100,  batch 151/188,  loss_train=1.68581,  acc_train=57.81%
3999.4s	1327	[train]  epoch 30/100,  batch 161/188,  loss_train=1.70725,  acc_train=46.88%
4005.1s	1328	[train]  epoch 30/100,  batch 171/188,  loss_train=1.40366,  acc_train=54.69%
4010.7s	1329	[train]  epoch 30/100,  batch 181/188,  loss_train=1.50059,  acc_train=50.00%
4015.2s	1330	[ val ]  epoch 30/100,  batch 1/135,  loss_val=3.00617,  acc_val=12.50%
4017.0s	1331	[ val ]  epoch 30/100,  batch 11/135,  loss_val=2.42578,  acc_val=28.12%
4018.8s	1332	[ val ]  epoch 30/100,  batch 21/135,  loss_val=2.69582,  acc_val=25.00%
4020.5s	1333	[ val ]  epoch 30/100,  batch 31/135,  loss_val=1.96835,  acc_val=45.31%
4022.3s	1334	[ val ]  epoch 30/100,  batch 41/135,  loss_val=3.25856,  acc_val=23.44%
4024.1s	1335	[ val ]  epoch 30/100,  batch 51/135,  loss_val=4.16248,  acc_val=18.75%
4025.9s	1336	[ val ]  epoch 30/100,  batch 61/135,  loss_val=4.41445,  acc_val=4.69%
4027.7s	1337	[ val ]  epoch 30/100,  batch 71/135,  loss_val=2.26003,  acc_val=50.00%
4029.5s	1338	[ val ]  epoch 30/100,  batch 81/135,  loss_val=3.45901,  acc_val=35.94%
4031.3s	1339	[ val ]  epoch 30/100,  batch 91/135,  loss_val=3.14706,  acc_val=18.75%
4033.1s	1340	[ val ]  epoch 30/100,  batch 101/135,  loss_val=0.85070,  acc_val=75.00%
4034.9s	1341	[ val ]  epoch 30/100,  batch 111/135,  loss_val=3.33419,  acc_val=25.00%
4036.8s	1342	[ val ]  epoch 30/100,  batch 121/135,  loss_val=1.42297,  acc_val=50.00%
4038.4s	1343	[ val ]  epoch 30/100,  batch 131/135,  loss_val=2.44092,  acc_val=40.62%
4039.0s	1344	===================================================================================================================
4039.0s	1345	Epoch 30/100 summary: loss_train=1.53436, acc_train=55.34%, loss_val=2.79, acc_val=32.51% (best: 39.73% @ epoch 29)
4039.0s	1346	===================================================================================================================
4039.0s	1347	Starting epoch 31/100, learning_rate=0.1
4040.3s	1348	[train]  epoch 31/100,  batch 1/188,  loss_train=1.25069,  acc_train=65.62%
4046.0s	1349	[train]  epoch 31/100,  batch 11/188,  loss_train=1.35677,  acc_train=62.50%
4051.6s	1350	[train]  epoch 31/100,  batch 21/188,  loss_train=1.26448,  acc_train=67.19%
4057.2s	1351	[train]  epoch 31/100,  batch 31/188,  loss_train=1.50124,  acc_train=62.50%
4062.9s	1352	[train]  epoch 31/100,  batch 41/188,  loss_train=1.38130,  acc_train=57.81%
4068.7s	1353	[train]  epoch 31/100,  batch 51/188,  loss_train=1.65492,  acc_train=53.12%
4074.1s	1354	[train]  epoch 31/100,  batch 61/188,  loss_train=1.84968,  acc_train=54.69%
4079.8s	1355	[train]  epoch 31/100,  batch 71/188,  loss_train=1.49067,  acc_train=53.12%
4085.4s	1356	[train]  epoch 31/100,  batch 81/188,  loss_train=1.26530,  acc_train=64.06%
4091.0s	1357	[train]  epoch 31/100,  batch 91/188,  loss_train=1.39744,  acc_train=62.50%
4096.6s	1358	[train]  epoch 31/100,  batch 101/188,  loss_train=1.72459,  acc_train=46.88%
4102.4s	1359	[train]  epoch 31/100,  batch 111/188,  loss_train=1.58149,  acc_train=51.56%
4107.9s	1360	[train]  epoch 31/100,  batch 121/188,  loss_train=1.38869,  acc_train=54.69%
4113.5s	1361	[train]  epoch 31/100,  batch 131/188,  loss_train=1.28683,  acc_train=54.69%
4119.1s	1362	[train]  epoch 31/100,  batch 141/188,  loss_train=1.51884,  acc_train=54.69%
4124.7s	1363	[train]  epoch 31/100,  batch 151/188,  loss_train=1.50644,  acc_train=50.00%
4130.4s	1364	[train]  epoch 31/100,  batch 161/188,  loss_train=1.66785,  acc_train=45.31%
4136.2s	1365	[train]  epoch 31/100,  batch 171/188,  loss_train=1.45744,  acc_train=62.50%
4141.7s	1366	[train]  epoch 31/100,  batch 181/188,  loss_train=1.38088,  acc_train=56.25%
4146.3s	1367	[ val ]  epoch 31/100,  batch 1/135,  loss_val=3.86316,  acc_val=18.75%
4148.1s	1368	[ val ]  epoch 31/100,  batch 11/135,  loss_val=2.49290,  acc_val=34.38%
4149.9s	1369	[ val ]  epoch 31/100,  batch 21/135,  loss_val=2.00666,  acc_val=50.00%
4151.7s	1370	[ val ]  epoch 31/100,  batch 31/135,  loss_val=1.99559,  acc_val=48.44%
4153.5s	1371	[ val ]  epoch 31/100,  batch 41/135,  loss_val=1.53719,  acc_val=54.69%
4155.4s	1372	[ val ]  epoch 31/100,  batch 51/135,  loss_val=2.10653,  acc_val=43.75%
4157.2s	1373	[ val ]  epoch 31/100,  batch 61/135,  loss_val=3.12051,  acc_val=35.94%
4159.0s	1374	[ val ]  epoch 31/100,  batch 71/135,  loss_val=3.13824,  acc_val=29.69%
4160.7s	1375	[ val ]  epoch 31/100,  batch 81/135,  loss_val=2.62753,  acc_val=45.31%
4162.5s	1376	[ val ]  epoch 31/100,  batch 91/135,  loss_val=3.10993,  acc_val=28.12%
4164.3s	1377	[ val ]  epoch 31/100,  batch 101/135,  loss_val=1.23756,  acc_val=53.12%
4166.1s	1378	[ val ]  epoch 31/100,  batch 111/135,  loss_val=3.47356,  acc_val=23.44%
4168.1s	1379	[ val ]  epoch 31/100,  batch 121/135,  loss_val=2.50266,  acc_val=35.94%
4169.6s	1380	[ val ]  epoch 31/100,  batch 131/135,  loss_val=2.23754,  acc_val=43.75%
4170.2s	1381	===================================================================================================================
4170.2s	1382	Epoch 31/100 summary: loss_train=1.49457, acc_train=56.99%, loss_val=2.63, acc_val=35.96% (best: 39.73% @ epoch 29)
4170.2s	1383	===================================================================================================================
4170.2s	1384	Starting epoch 32/100, learning_rate=0.1
4171.5s	1385	[train]  epoch 32/100,  batch 1/188,  loss_train=1.25978,  acc_train=60.94%
4177.2s	1386	[train]  epoch 32/100,  batch 11/188,  loss_train=1.30778,  acc_train=53.12%
4182.8s	1387	[train]  epoch 32/100,  batch 21/188,  loss_train=1.26704,  acc_train=62.50%
4188.5s	1388	[train]  epoch 32/100,  batch 31/188,  loss_train=1.40531,  acc_train=59.38%
4194.1s	1389	[train]  epoch 32/100,  batch 41/188,  loss_train=1.17987,  acc_train=65.62%
4199.9s	1390	[train]  epoch 32/100,  batch 51/188,  loss_train=1.25328,  acc_train=67.19%
4205.3s	1391	[train]  epoch 32/100,  batch 61/188,  loss_train=1.51181,  acc_train=56.25%
4211.0s	1392	[train]  epoch 32/100,  batch 71/188,  loss_train=1.79949,  acc_train=51.56%
4216.7s	1393	[train]  epoch 32/100,  batch 81/188,  loss_train=1.61947,  acc_train=56.25%
4222.3s	1394	[train]  epoch 32/100,  batch 91/188,  loss_train=1.40691,  acc_train=51.56%
4227.9s	1395	[train]  epoch 32/100,  batch 101/188,  loss_train=1.10877,  acc_train=67.19%
4233.7s	1396	[train]  epoch 32/100,  batch 111/188,  loss_train=1.60335,  acc_train=48.44%
4239.2s	1397	[train]  epoch 32/100,  batch 121/188,  loss_train=1.26502,  acc_train=64.06%
4244.8s	1398	[train]  epoch 32/100,  batch 131/188,  loss_train=1.66632,  acc_train=53.12%
4250.4s	1399	[train]  epoch 32/100,  batch 141/188,  loss_train=1.59125,  acc_train=51.56%
4256.0s	1400	[train]  epoch 32/100,  batch 151/188,  loss_train=1.99847,  acc_train=46.88%
4261.6s	1401	[train]  epoch 32/100,  batch 161/188,  loss_train=1.54651,  acc_train=51.56%
4267.4s	1402	[train]  epoch 32/100,  batch 171/188,  loss_train=1.67557,  acc_train=53.12%
4272.9s	1403	[train]  epoch 32/100,  batch 181/188,  loss_train=1.48328,  acc_train=56.25%
4277.5s	1404	[ val ]  epoch 32/100,  batch 1/135,  loss_val=2.66805,  acc_val=37.50%
4279.3s	1405	[ val ]  epoch 32/100,  batch 11/135,  loss_val=1.90361,  acc_val=57.81%
4281.1s	1406	[ val ]  epoch 32/100,  batch 21/135,  loss_val=1.93792,  acc_val=45.31%
4282.9s	1407	[ val ]  epoch 32/100,  batch 31/135,  loss_val=2.12259,  acc_val=51.56%
4284.7s	1408	[ val ]  epoch 32/100,  batch 41/135,  loss_val=1.93963,  acc_val=50.00%
4286.5s	1409	[ val ]  epoch 32/100,  batch 51/135,  loss_val=2.41097,  acc_val=48.44%
4288.3s	1410	[ val ]  epoch 32/100,  batch 61/135,  loss_val=1.98176,  acc_val=51.56%
4290.1s	1411	[ val ]  epoch 32/100,  batch 71/135,  loss_val=2.51053,  acc_val=34.38%
4291.9s	1412	[ val ]  epoch 32/100,  batch 81/135,  loss_val=3.04693,  acc_val=37.50%
4293.7s	1413	[ val ]  epoch 32/100,  batch 91/135,  loss_val=2.25761,  acc_val=31.25%
4295.4s	1414	[ val ]  epoch 32/100,  batch 101/135,  loss_val=1.35929,  acc_val=56.25%
4297.2s	1415	[ val ]  epoch 32/100,  batch 111/135,  loss_val=2.33592,  acc_val=39.06%
4299.2s	1416	[ val ]  epoch 32/100,  batch 121/135,  loss_val=2.23188,  acc_val=42.19%
4300.8s	1417	[ val ]  epoch 32/100,  batch 131/135,  loss_val=2.06578,  acc_val=40.62%
4301.4s	1418	===================================================================================================================
4301.4s	1419	Epoch 32/100 summary: loss_train=1.42977, acc_train=58.21%, loss_val=2.40, acc_val=38.08% (best: 39.73% @ epoch 29)
4301.4s	1420	===================================================================================================================
4301.4s	1421	Starting epoch 33/100, learning_rate=0.1
4302.6s	1422	[train]  epoch 33/100,  batch 1/188,  loss_train=1.20662,  acc_train=65.62%
4308.3s	1423	[train]  epoch 33/100,  batch 11/188,  loss_train=1.53081,  acc_train=57.81%
4313.9s	1424	[train]  epoch 33/100,  batch 21/188,  loss_train=1.62162,  acc_train=59.38%
4319.5s	1425	[train]  epoch 33/100,  batch 31/188,  loss_train=1.69950,  acc_train=54.69%
4325.1s	1426	[train]  epoch 33/100,  batch 41/188,  loss_train=1.40854,  acc_train=56.25%
4330.8s	1427	[train]  epoch 33/100,  batch 51/188,  loss_train=1.57712,  acc_train=57.81%
4336.3s	1428	[train]  epoch 33/100,  batch 61/188,  loss_train=1.65552,  acc_train=62.50%
4341.9s	1429	[train]  epoch 33/100,  batch 71/188,  loss_train=1.33951,  acc_train=59.38%
4347.6s	1430	[train]  epoch 33/100,  batch 81/188,  loss_train=1.40830,  acc_train=60.94%
4353.2s	1431	[train]  epoch 33/100,  batch 91/188,  loss_train=1.33065,  acc_train=60.94%
4358.8s	1432	[train]  epoch 33/100,  batch 101/188,  loss_train=1.61303,  acc_train=51.56%
4364.6s	1433	[train]  epoch 33/100,  batch 111/188,  loss_train=1.62703,  acc_train=50.00%
4370.1s	1434	[train]  epoch 33/100,  batch 121/188,  loss_train=1.82299,  acc_train=45.31%
4375.7s	1435	[train]  epoch 33/100,  batch 131/188,  loss_train=1.26841,  acc_train=67.19%
4381.4s	1436	[train]  epoch 33/100,  batch 141/188,  loss_train=1.45606,  acc_train=60.94%
4387.0s	1437	[train]  epoch 33/100,  batch 151/188,  loss_train=1.24300,  acc_train=62.50%
4392.6s	1438	[train]  epoch 33/100,  batch 161/188,  loss_train=1.36412,  acc_train=53.12%
4398.4s	1439	[train]  epoch 33/100,  batch 171/188,  loss_train=1.24823,  acc_train=67.19%
4403.9s	1440	[train]  epoch 33/100,  batch 181/188,  loss_train=1.32228,  acc_train=62.50%
4408.6s	1441	[ val ]  epoch 33/100,  batch 1/135,  loss_val=3.38562,  acc_val=20.31%
4410.5s	1442	[ val ]  epoch 33/100,  batch 11/135,  loss_val=2.87938,  acc_val=37.50%
4412.4s	1443	[ val ]  epoch 33/100,  batch 21/135,  loss_val=2.53589,  acc_val=26.56%
4414.1s	1444	[ val ]  epoch 33/100,  batch 31/135,  loss_val=2.67674,  acc_val=34.38%
4415.9s	1445	[ val ]  epoch 33/100,  batch 41/135,  loss_val=2.15028,  acc_val=42.19%
4417.7s	1446	[ val ]  epoch 33/100,  batch 51/135,  loss_val=2.12910,  acc_val=42.19%
4419.5s	1447	[ val ]  epoch 33/100,  batch 61/135,  loss_val=2.30304,  acc_val=42.19%
4421.3s	1448	[ val ]  epoch 33/100,  batch 71/135,  loss_val=2.80068,  acc_val=17.19%
4423.1s	1449	[ val ]  epoch 33/100,  batch 81/135,  loss_val=2.64709,  acc_val=43.75%
4424.8s	1450	[ val ]  epoch 33/100,  batch 91/135,  loss_val=1.78403,  acc_val=48.44%
4426.6s	1451	[ val ]  epoch 33/100,  batch 101/135,  loss_val=0.39882,  acc_val=87.50%
4428.4s	1452	[ val ]  epoch 33/100,  batch 111/135,  loss_val=2.64168,  acc_val=29.69%
4430.3s	1453	[ val ]  epoch 33/100,  batch 121/135,  loss_val=1.23388,  acc_val=60.94%
4432.0s	1454	[ val ]  epoch 33/100,  batch 131/135,  loss_val=4.03199,  acc_val=15.62%
4432.6s	1455	===================================================================================================================
4432.6s	1456	Epoch 33/100 summary: loss_train=1.39751, acc_train=58.64%, loss_val=2.39, acc_val=37.33% (best: 39.73% @ epoch 29)
4432.6s	1457	===================================================================================================================
4432.6s	1458	Starting epoch 34/100, learning_rate=0.1
4433.8s	1459	[train]  epoch 34/100,  batch 1/188,  loss_train=1.24254,  acc_train=65.62%
4439.5s	1460	[train]  epoch 34/100,  batch 11/188,  loss_train=1.21446,  acc_train=65.62%
4445.1s	1461	[train]  epoch 34/100,  batch 21/188,  loss_train=1.04489,  acc_train=62.50%
4450.7s	1462	[train]  epoch 34/100,  batch 31/188,  loss_train=1.29498,  acc_train=62.50%
4456.3s	1463	[train]  epoch 34/100,  batch 41/188,  loss_train=0.99678,  acc_train=68.75%
4462.1s	1464	[train]  epoch 34/100,  batch 51/188,  loss_train=1.12842,  acc_train=64.06%
4467.6s	1465	[train]  epoch 34/100,  batch 61/188,  loss_train=1.34777,  acc_train=57.81%
4473.3s	1466	[train]  epoch 34/100,  batch 71/188,  loss_train=1.35765,  acc_train=64.06%
4478.9s	1467	[train]  epoch 34/100,  batch 81/188,  loss_train=1.40402,  acc_train=53.12%
4484.5s	1468	[train]  epoch 34/100,  batch 91/188,  loss_train=1.30886,  acc_train=59.38%
4490.2s	1469	[train]  epoch 34/100,  batch 101/188,  loss_train=1.30737,  acc_train=60.94%
4496.0s	1470	[train]  epoch 34/100,  batch 111/188,  loss_train=1.53378,  acc_train=56.25%
4501.5s	1471	[train]  epoch 34/100,  batch 121/188,  loss_train=1.09874,  acc_train=64.06%
4507.1s	1472	[train]  epoch 34/100,  batch 131/188,  loss_train=1.51076,  acc_train=53.12%
4512.7s	1473	[train]  epoch 34/100,  batch 141/188,  loss_train=1.73034,  acc_train=50.00%
4518.4s	1474	[train]  epoch 34/100,  batch 151/188,  loss_train=1.41481,  acc_train=53.12%
4524.0s	1475	[train]  epoch 34/100,  batch 161/188,  loss_train=1.25925,  acc_train=62.50%
4529.7s	1476	[train]  epoch 34/100,  batch 171/188,  loss_train=1.55464,  acc_train=57.81%
4535.2s	1477	[train]  epoch 34/100,  batch 181/188,  loss_train=1.25694,  acc_train=64.06%
4539.8s	1478	[ val ]  epoch 34/100,  batch 1/135,  loss_val=3.57501,  acc_val=20.31%
4541.6s	1479	[ val ]  epoch 34/100,  batch 11/135,  loss_val=1.49028,  acc_val=65.62%
4543.4s	1480	[ val ]  epoch 34/100,  batch 21/135,  loss_val=1.68557,  acc_val=51.56%
4545.1s	1481	[ val ]  epoch 34/100,  batch 31/135,  loss_val=1.40187,  acc_val=67.19%
4546.9s	1482	[ val ]  epoch 34/100,  batch 41/135,  loss_val=3.25852,  acc_val=26.56%
4548.7s	1483	[ val ]  epoch 34/100,  batch 51/135,  loss_val=2.94498,  acc_val=37.50%
4550.4s	1484	[ val ]  epoch 34/100,  batch 61/135,  loss_val=3.01870,  acc_val=20.31%
4552.2s	1485	[ val ]  epoch 34/100,  batch 71/135,  loss_val=3.04683,  acc_val=31.25%
4554.0s	1486	[ val ]  epoch 34/100,  batch 81/135,  loss_val=2.48557,  acc_val=48.44%
4555.7s	1487	[ val ]  epoch 34/100,  batch 91/135,  loss_val=2.54414,  acc_val=45.31%
4557.5s	1488	[ val ]  epoch 34/100,  batch 101/135,  loss_val=0.62741,  acc_val=84.38%
4559.3s	1489	[ val ]  epoch 34/100,  batch 111/135,  loss_val=2.94876,  acc_val=29.69%
4561.3s	1490	[ val ]  epoch 34/100,  batch 121/135,  loss_val=1.97640,  acc_val=43.75%
4562.8s	1491	[ val ]  epoch 34/100,  batch 131/135,  loss_val=3.10884,  acc_val=37.50%
4563.5s	1492	===================================================================================================================
4563.5s	1493	Epoch 34/100 summary: loss_train=1.34488, acc_train=60.55%, loss_val=2.63, acc_val=37.43% (best: 39.73% @ epoch 29)
4563.5s	1494	===================================================================================================================
4563.5s	1495	Starting epoch 35/100, learning_rate=0.1
4564.6s	1496	[train]  epoch 35/100,  batch 1/188,  loss_train=1.14691,  acc_train=59.38%
4570.3s	1497	[train]  epoch 35/100,  batch 11/188,  loss_train=1.57266,  acc_train=51.56%
4575.9s	1498	[train]  epoch 35/100,  batch 21/188,  loss_train=1.00059,  acc_train=68.75%
4581.5s	1499	[train]  epoch 35/100,  batch 31/188,  loss_train=1.26631,  acc_train=65.62%
4587.2s	1500	[train]  epoch 35/100,  batch 41/188,  loss_train=1.00737,  acc_train=62.50%
4592.9s	1501	[train]  epoch 35/100,  batch 51/188,  loss_train=1.48602,  acc_train=54.69%
4598.4s	1502	[train]  epoch 35/100,  batch 61/188,  loss_train=1.33164,  acc_train=57.81%
4604.1s	1503	[train]  epoch 35/100,  batch 71/188,  loss_train=1.10090,  acc_train=59.38%
4609.8s	1504	[train]  epoch 35/100,  batch 81/188,  loss_train=1.25466,  acc_train=62.50%
4615.4s	1505	[train]  epoch 35/100,  batch 91/188,  loss_train=1.18039,  acc_train=62.50%
4621.0s	1506	[train]  epoch 35/100,  batch 101/188,  loss_train=1.16823,  acc_train=64.06%
4626.7s	1507	[train]  epoch 35/100,  batch 111/188,  loss_train=1.52811,  acc_train=54.69%
4632.2s	1508	[train]  epoch 35/100,  batch 121/188,  loss_train=1.23841,  acc_train=62.50%
4637.9s	1509	[train]  epoch 35/100,  batch 131/188,  loss_train=1.43145,  acc_train=57.81%
4643.5s	1510	[train]  epoch 35/100,  batch 141/188,  loss_train=1.50971,  acc_train=56.25%
4649.1s	1511	[train]  epoch 35/100,  batch 151/188,  loss_train=1.07233,  acc_train=73.44%
4654.7s	1512	[train]  epoch 35/100,  batch 161/188,  loss_train=1.55819,  acc_train=51.56%
4660.4s	1513	[train]  epoch 35/100,  batch 171/188,  loss_train=0.97801,  acc_train=64.06%
4665.9s	1514	[train]  epoch 35/100,  batch 181/188,  loss_train=1.42685,  acc_train=54.69%
4670.6s	1515	[ val ]  epoch 35/100,  batch 1/135,  loss_val=2.62504,  acc_val=35.94%
4672.4s	1516	[ val ]  epoch 35/100,  batch 11/135,  loss_val=1.63371,  acc_val=57.81%
4674.2s	1517	[ val ]  epoch 35/100,  batch 21/135,  loss_val=2.69843,  acc_val=25.00%
4676.0s	1518	[ val ]  epoch 35/100,  batch 31/135,  loss_val=1.84743,  acc_val=59.38%
4677.8s	1519	[ val ]  epoch 35/100,  batch 41/135,  loss_val=1.61211,  acc_val=60.94%
4679.5s	1520	[ val ]  epoch 35/100,  batch 51/135,  loss_val=3.34212,  acc_val=26.56%
4681.3s	1521	[ val ]  epoch 35/100,  batch 61/135,  loss_val=1.85844,  acc_val=53.12%
4683.1s	1522	[ val ]  epoch 35/100,  batch 71/135,  loss_val=2.04997,  acc_val=39.06%
4684.9s	1523	[ val ]  epoch 35/100,  batch 81/135,  loss_val=2.39209,  acc_val=48.44%
4686.7s	1524	[ val ]  epoch 35/100,  batch 91/135,  loss_val=2.16838,  acc_val=35.94%
4688.5s	1525	[ val ]  epoch 35/100,  batch 101/135,  loss_val=1.24869,  acc_val=56.25%
4690.3s	1526	[ val ]  epoch 35/100,  batch 111/135,  loss_val=3.17371,  acc_val=20.31%
4692.3s	1527	[ val ]  epoch 35/100,  batch 121/135,  loss_val=1.77166,  acc_val=50.00%
4693.8s	1528	[ val ]  epoch 35/100,  batch 131/135,  loss_val=2.59629,  acc_val=37.50%
4694.5s	1529	===================================================================================================================
4694.5s	1530	Epoch 35/100 summary: loss_train=1.28751, acc_train=61.64%, loss_val=2.21, acc_val=42.20% (best: 42.20% @ epoch 35)
4694.5s	1531	===================================================================================================================
4694.5s	1532	Starting epoch 36/100, learning_rate=0.1
4696.0s	1533	[train]  epoch 36/100,  batch 1/188,  loss_train=0.62655,  acc_train=82.81%
4701.6s	1534	[train]  epoch 36/100,  batch 11/188,  loss_train=1.02767,  acc_train=65.62%
4707.3s	1535	[train]  epoch 36/100,  batch 21/188,  loss_train=1.04081,  acc_train=67.19%
4712.9s	1536	[train]  epoch 36/100,  batch 31/188,  loss_train=1.12713,  acc_train=64.06%
4718.5s	1537	[train]  epoch 36/100,  batch 41/188,  loss_train=1.27743,  acc_train=57.81%
4724.3s	1538	[train]  epoch 36/100,  batch 51/188,  loss_train=0.96178,  acc_train=70.31%
4729.7s	1539	[train]  epoch 36/100,  batch 61/188,  loss_train=1.31282,  acc_train=59.38%
4735.3s	1540	[train]  epoch 36/100,  batch 71/188,  loss_train=1.33982,  acc_train=59.38%
4741.0s	1541	[train]  epoch 36/100,  batch 81/188,  loss_train=1.22923,  acc_train=64.06%
4746.6s	1542	[train]  epoch 36/100,  batch 91/188,  loss_train=1.13060,  acc_train=64.06%
4752.2s	1543	[train]  epoch 36/100,  batch 101/188,  loss_train=1.20996,  acc_train=67.19%
4758.0s	1544	[train]  epoch 36/100,  batch 111/188,  loss_train=1.58662,  acc_train=53.12%
4763.5s	1545	[train]  epoch 36/100,  batch 121/188,  loss_train=1.52987,  acc_train=60.94%
4769.1s	1546	[train]  epoch 36/100,  batch 131/188,  loss_train=1.30954,  acc_train=60.94%
4774.7s	1547	[train]  epoch 36/100,  batch 141/188,  loss_train=1.24947,  acc_train=59.38%
4780.3s	1548	[train]  epoch 36/100,  batch 151/188,  loss_train=1.20794,  acc_train=67.19%
4785.9s	1549	[train]  epoch 36/100,  batch 161/188,  loss_train=1.11922,  acc_train=67.19%
4791.7s	1550	[train]  epoch 36/100,  batch 171/188,  loss_train=1.35341,  acc_train=56.25%
4797.2s	1551	[train]  epoch 36/100,  batch 181/188,  loss_train=1.30120,  acc_train=56.25%
4801.8s	1552	[ val ]  epoch 36/100,  batch 1/135,  loss_val=3.18786,  acc_val=28.12%
4803.6s	1553	[ val ]  epoch 36/100,  batch 11/135,  loss_val=2.04823,  acc_val=43.75%
4805.3s	1554	[ val ]  epoch 36/100,  batch 21/135,  loss_val=3.27839,  acc_val=17.19%
4807.1s	1555	[ val ]  epoch 36/100,  batch 31/135,  loss_val=1.70810,  acc_val=51.56%
4808.9s	1556	[ val ]  epoch 36/100,  batch 41/135,  loss_val=1.22973,  acc_val=68.75%
4810.7s	1557	[ val ]  epoch 36/100,  batch 51/135,  loss_val=2.24660,  acc_val=40.62%
4812.5s	1558	[ val ]  epoch 36/100,  batch 61/135,  loss_val=2.56002,  acc_val=42.19%
4814.2s	1559	[ val ]  epoch 36/100,  batch 71/135,  loss_val=2.95507,  acc_val=32.81%
4816.0s	1560	[ val ]  epoch 36/100,  batch 81/135,  loss_val=2.55741,  acc_val=48.44%
4817.8s	1561	[ val ]  epoch 36/100,  batch 91/135,  loss_val=2.20890,  acc_val=40.62%
4819.6s	1562	[ val ]  epoch 36/100,  batch 101/135,  loss_val=1.77590,  acc_val=60.94%
4821.4s	1563	[ val ]  epoch 36/100,  batch 111/135,  loss_val=4.48244,  acc_val=10.94%
4823.4s	1564	[ val ]  epoch 36/100,  batch 121/135,  loss_val=1.75574,  acc_val=54.69%
4825.0s	1565	[ val ]  epoch 36/100,  batch 131/135,  loss_val=2.83146,  acc_val=35.94%
4825.6s	1566	===================================================================================================================
4825.6s	1567	Epoch 36/100 summary: loss_train=1.24187, acc_train=62.87%, loss_val=2.56, acc_val=37.99% (best: 42.20% @ epoch 35)
4825.6s	1568	===================================================================================================================
4825.6s	1569	Starting epoch 37/100, learning_rate=0.1
4826.8s	1570	[train]  epoch 37/100,  batch 1/188,  loss_train=1.50603,  acc_train=64.06%
4832.4s	1571	[train]  epoch 37/100,  batch 11/188,  loss_train=1.00304,  acc_train=73.44%
4838.0s	1572	[train]  epoch 37/100,  batch 21/188,  loss_train=0.95457,  acc_train=64.06%
4843.6s	1573	[train]  epoch 37/100,  batch 31/188,  loss_train=1.04427,  acc_train=67.19%
4849.2s	1574	[train]  epoch 37/100,  batch 41/188,  loss_train=1.28619,  acc_train=65.62%
4855.0s	1575	[train]  epoch 37/100,  batch 51/188,  loss_train=1.46809,  acc_train=56.25%
4860.5s	1576	[train]  epoch 37/100,  batch 61/188,  loss_train=1.46207,  acc_train=53.12%
4866.2s	1577	[train]  epoch 37/100,  batch 71/188,  loss_train=1.19405,  acc_train=64.06%
4871.8s	1578	[train]  epoch 37/100,  batch 81/188,  loss_train=1.69189,  acc_train=51.56%
4877.5s	1579	[train]  epoch 37/100,  batch 91/188,  loss_train=1.05599,  acc_train=60.94%
4883.2s	1580	[train]  epoch 37/100,  batch 101/188,  loss_train=1.63443,  acc_train=53.12%
4888.8s	1581	[train]  epoch 37/100,  batch 111/188,  loss_train=1.31639,  acc_train=64.06%
4894.4s	1582	[train]  epoch 37/100,  batch 121/188,  loss_train=1.01101,  acc_train=65.62%
4900.1s	1583	[train]  epoch 37/100,  batch 131/188,  loss_train=0.85347,  acc_train=68.75%
4905.7s	1584	[train]  epoch 37/100,  batch 141/188,  loss_train=1.07026,  acc_train=70.31%
4911.3s	1585	[train]  epoch 37/100,  batch 151/188,  loss_train=1.34515,  acc_train=60.94%
4916.9s	1586	[train]  epoch 37/100,  batch 161/188,  loss_train=0.97322,  acc_train=67.19%
4922.7s	1587	[train]  epoch 37/100,  batch 171/188,  loss_train=1.71442,  acc_train=46.88%
4928.2s	1588	[train]  epoch 37/100,  batch 181/188,  loss_train=1.36637,  acc_train=60.94%
4932.8s	1589	[ val ]  epoch 37/100,  batch 1/135,  loss_val=2.86519,  acc_val=37.50%
4934.6s	1590	[ val ]  epoch 37/100,  batch 11/135,  loss_val=2.16129,  acc_val=45.31%
4936.4s	1591	[ val ]  epoch 37/100,  batch 21/135,  loss_val=2.63837,  acc_val=23.44%
4938.2s	1592	[ val ]  epoch 37/100,  batch 31/135,  loss_val=1.92429,  acc_val=50.00%
4940.0s	1593	[ val ]  epoch 37/100,  batch 41/135,  loss_val=2.67793,  acc_val=34.38%
4941.7s	1594	[ val ]  epoch 37/100,  batch 51/135,  loss_val=1.84572,  acc_val=59.38%
4943.5s	1595	[ val ]  epoch 37/100,  batch 61/135,  loss_val=2.01775,  acc_val=57.81%
4945.3s	1596	[ val ]  epoch 37/100,  batch 71/135,  loss_val=2.40734,  acc_val=37.50%
4947.1s	1597	[ val ]  epoch 37/100,  batch 81/135,  loss_val=2.04710,  acc_val=57.81%
4948.9s	1598	[ val ]  epoch 37/100,  batch 91/135,  loss_val=3.30855,  acc_val=26.56%
4950.7s	1599	[ val ]  epoch 37/100,  batch 101/135,  loss_val=1.04009,  acc_val=64.06%
4952.6s	1600	[ val ]  epoch 37/100,  batch 111/135,  loss_val=3.36990,  acc_val=21.88%
4954.5s	1601	[ val ]  epoch 37/100,  batch 121/135,  loss_val=1.92780,  acc_val=50.00%
4956.1s	1602	[ val ]  epoch 37/100,  batch 131/135,  loss_val=3.47037,  acc_val=32.81%
4956.7s	1603	===================================================================================================================
4956.7s	1604	Epoch 37/100 summary: loss_train=1.22383, acc_train=63.05%, loss_val=2.23, acc_val=43.39% (best: 43.39% @ epoch 37)
4956.7s	1605	===================================================================================================================
4956.7s	1606	Starting epoch 38/100, learning_rate=0.1
4958.0s	1607	[train]  epoch 38/100,  batch 1/188,  loss_train=1.03768,  acc_train=57.81%
4963.6s	1608	[train]  epoch 38/100,  batch 11/188,  loss_train=1.02898,  acc_train=67.19%
4969.2s	1609	[train]  epoch 38/100,  batch 21/188,  loss_train=1.02025,  acc_train=68.75%
4974.8s	1610	[train]  epoch 38/100,  batch 31/188,  loss_train=0.90345,  acc_train=71.88%
4980.5s	1611	[train]  epoch 38/100,  batch 41/188,  loss_train=1.03853,  acc_train=67.19%
4986.3s	1612	[train]  epoch 38/100,  batch 51/188,  loss_train=1.23566,  acc_train=60.94%
4991.8s	1613	[train]  epoch 38/100,  batch 61/188,  loss_train=1.20175,  acc_train=62.50%
4997.4s	1614	[train]  epoch 38/100,  batch 71/188,  loss_train=1.56178,  acc_train=60.94%
5003.0s	1615	[train]  epoch 38/100,  batch 81/188,  loss_train=1.27769,  acc_train=54.69%
5008.6s	1616	[train]  epoch 38/100,  batch 91/188,  loss_train=1.07225,  acc_train=64.06%
5014.2s	1617	[train]  epoch 38/100,  batch 101/188,  loss_train=1.23814,  acc_train=56.25%
5019.9s	1618	[train]  epoch 38/100,  batch 111/188,  loss_train=1.13256,  acc_train=62.50%
5025.5s	1619	[train]  epoch 38/100,  batch 121/188,  loss_train=1.61212,  acc_train=51.56%
5031.2s	1620	[train]  epoch 38/100,  batch 131/188,  loss_train=0.82715,  acc_train=76.56%
5036.8s	1621	[train]  epoch 38/100,  batch 141/188,  loss_train=1.62758,  acc_train=57.81%
5042.4s	1622	[train]  epoch 38/100,  batch 151/188,  loss_train=1.11225,  acc_train=70.31%
5048.0s	1623	[train]  epoch 38/100,  batch 161/188,  loss_train=1.23319,  acc_train=60.94%
5053.8s	1624	[train]  epoch 38/100,  batch 171/188,  loss_train=1.28052,  acc_train=68.75%
5059.3s	1625	[train]  epoch 38/100,  batch 181/188,  loss_train=1.03917,  acc_train=67.19%
5063.9s	1626	[ val ]  epoch 38/100,  batch 1/135,  loss_val=3.02486,  acc_val=35.94%
5065.7s	1627	[ val ]  epoch 38/100,  batch 11/135,  loss_val=2.49017,  acc_val=39.06%
5067.6s	1628	[ val ]  epoch 38/100,  batch 21/135,  loss_val=1.71342,  acc_val=43.75%
5069.4s	1629	[ val ]  epoch 38/100,  batch 31/135,  loss_val=1.26665,  acc_val=68.75%
5071.2s	1630	[ val ]  epoch 38/100,  batch 41/135,  loss_val=2.15330,  acc_val=48.44%
5073.0s	1631	[ val ]  epoch 38/100,  batch 51/135,  loss_val=2.96671,  acc_val=31.25%
5074.8s	1632	[ val ]  epoch 38/100,  batch 61/135,  loss_val=2.12410,  acc_val=62.50%
5076.6s	1633	[ val ]  epoch 38/100,  batch 71/135,  loss_val=1.36117,  acc_val=65.62%
5078.4s	1634	[ val ]  epoch 38/100,  batch 81/135,  loss_val=2.81982,  acc_val=45.31%
5080.4s	1635	[ val ]  epoch 38/100,  batch 91/135,  loss_val=2.61866,  acc_val=37.50%
5082.4s	1636	[ val ]  epoch 38/100,  batch 101/135,  loss_val=1.46341,  acc_val=54.69%
5084.3s	1637	[ val ]  epoch 38/100,  batch 111/135,  loss_val=2.76209,  acc_val=29.69%
5086.0s	1638	[ val ]  epoch 38/100,  batch 121/135,  loss_val=1.36879,  acc_val=56.25%
5087.7s	1639	[ val ]  epoch 38/100,  batch 131/135,  loss_val=2.17810,  acc_val=42.19%
5088.3s	1640	===================================================================================================================
5088.3s	1641	Epoch 38/100 summary: loss_train=1.18248, acc_train=64.37%, loss_val=2.33, acc_val=41.59% (best: 43.39% @ epoch 37)
5088.3s	1642	===================================================================================================================
5088.3s	1643	Starting epoch 39/100, learning_rate=0.1
5089.5s	1644	[train]  epoch 39/100,  batch 1/188,  loss_train=1.09360,  acc_train=64.06%
5095.2s	1645	[train]  epoch 39/100,  batch 11/188,  loss_train=1.09409,  acc_train=65.62%
5100.9s	1646	[train]  epoch 39/100,  batch 21/188,  loss_train=0.83922,  acc_train=71.88%
5106.5s	1647	[train]  epoch 39/100,  batch 31/188,  loss_train=1.02914,  acc_train=68.75%
5112.2s	1648	[train]  epoch 39/100,  batch 41/188,  loss_train=1.20327,  acc_train=71.88%
5117.9s	1649	[train]  epoch 39/100,  batch 51/188,  loss_train=1.40369,  acc_train=59.38%
5123.4s	1650	[train]  epoch 39/100,  batch 61/188,  loss_train=1.35889,  acc_train=53.12%
5129.1s	1651	[train]  epoch 39/100,  batch 71/188,  loss_train=1.24051,  acc_train=64.06%
5134.7s	1652	[train]  epoch 39/100,  batch 81/188,  loss_train=1.24296,  acc_train=65.62%
5140.3s	1653	[train]  epoch 39/100,  batch 91/188,  loss_train=1.03586,  acc_train=62.50%
5146.0s	1654	[train]  epoch 39/100,  batch 101/188,  loss_train=0.86058,  acc_train=73.44%
5151.8s	1655	[train]  epoch 39/100,  batch 111/188,  loss_train=1.38841,  acc_train=57.81%
5157.3s	1656	[train]  epoch 39/100,  batch 121/188,  loss_train=1.01787,  acc_train=73.44%
5162.9s	1657	[train]  epoch 39/100,  batch 131/188,  loss_train=1.21027,  acc_train=70.31%
5168.6s	1658	[train]  epoch 39/100,  batch 141/188,  loss_train=0.87706,  acc_train=73.44%
5174.2s	1659	[train]  epoch 39/100,  batch 151/188,  loss_train=0.94374,  acc_train=70.31%
5179.8s	1660	[train]  epoch 39/100,  batch 161/188,  loss_train=1.33202,  acc_train=54.69%
5185.6s	1661	[train]  epoch 39/100,  batch 171/188,  loss_train=1.09451,  acc_train=68.75%
5191.1s	1662	[train]  epoch 39/100,  batch 181/188,  loss_train=1.65702,  acc_train=43.75%
5195.7s	1663	[ val ]  epoch 39/100,  batch 1/135,  loss_val=4.02381,  acc_val=21.88%
5197.5s	1664	[ val ]  epoch 39/100,  batch 11/135,  loss_val=3.19681,  acc_val=29.69%
5199.3s	1665	[ val ]  epoch 39/100,  batch 21/135,  loss_val=2.10672,  acc_val=39.06%
5201.0s	1666	[ val ]  epoch 39/100,  batch 31/135,  loss_val=3.95142,  acc_val=17.19%
5202.8s	1667	[ val ]  epoch 39/100,  batch 41/135,  loss_val=3.23135,  acc_val=35.94%
5204.5s	1668	[ val ]  epoch 39/100,  batch 51/135,  loss_val=2.02927,  acc_val=48.44%
5206.3s	1669	[ val ]  epoch 39/100,  batch 61/135,  loss_val=3.05397,  acc_val=40.62%
5208.1s	1670	[ val ]  epoch 39/100,  batch 71/135,  loss_val=2.60552,  acc_val=32.81%
5209.9s	1671	[ val ]  epoch 39/100,  batch 81/135,  loss_val=3.34447,  acc_val=45.31%
5211.7s	1672	[ val ]  epoch 39/100,  batch 91/135,  loss_val=2.77139,  acc_val=31.25%
5213.5s	1673	[ val ]  epoch 39/100,  batch 101/135,  loss_val=1.13819,  acc_val=53.12%
5215.3s	1674	[ val ]  epoch 39/100,  batch 111/135,  loss_val=1.77703,  acc_val=59.38%
5217.1s	1675	[ val ]  epoch 39/100,  batch 121/135,  loss_val=1.40640,  acc_val=65.62%
5218.8s	1676	[ val ]  epoch 39/100,  batch 131/135,  loss_val=3.53089,  acc_val=26.56%
5219.3s	1677	===================================================================================================================
5219.3s	1678	Epoch 39/100 summary: loss_train=1.15037, acc_train=64.89%, loss_val=2.42, acc_val=41.52% (best: 43.39% @ epoch 37)
5219.3s	1679	===================================================================================================================
5219.3s	1680	Starting epoch 40/100, learning_rate=0.1
5220.7s	1681	[train]  epoch 40/100,  batch 1/188,  loss_train=1.11072,  acc_train=65.62%
5226.3s	1682	[train]  epoch 40/100,  batch 11/188,  loss_train=1.05894,  acc_train=60.94%
5231.9s	1683	[train]  epoch 40/100,  batch 21/188,  loss_train=1.25780,  acc_train=60.94%
5237.5s	1684	[train]  epoch 40/100,  batch 31/188,  loss_train=0.90009,  acc_train=76.56%
5243.2s	1685	[train]  epoch 40/100,  batch 41/188,  loss_train=1.17928,  acc_train=60.94%
5248.9s	1686	[train]  epoch 40/100,  batch 51/188,  loss_train=0.91323,  acc_train=73.44%
5254.4s	1687	[train]  epoch 40/100,  batch 61/188,  loss_train=1.17835,  acc_train=59.38%
5260.0s	1688	[train]  epoch 40/100,  batch 71/188,  loss_train=1.34214,  acc_train=59.38%
5265.6s	1689	[train]  epoch 40/100,  batch 81/188,  loss_train=1.06513,  acc_train=71.88%
5271.2s	1690	[train]  epoch 40/100,  batch 91/188,  loss_train=1.09407,  acc_train=73.44%
5276.9s	1691	[train]  epoch 40/100,  batch 101/188,  loss_train=1.16634,  acc_train=62.50%
5282.7s	1692	[train]  epoch 40/100,  batch 111/188,  loss_train=1.39990,  acc_train=60.94%
5288.1s	1693	[train]  epoch 40/100,  batch 121/188,  loss_train=0.95892,  acc_train=68.75%
5293.7s	1694	[train]  epoch 40/100,  batch 131/188,  loss_train=0.99198,  acc_train=65.62%
5299.3s	1695	[train]  epoch 40/100,  batch 141/188,  loss_train=1.00926,  acc_train=64.06%
5304.9s	1696	[train]  epoch 40/100,  batch 151/188,  loss_train=0.98198,  acc_train=70.31%
5310.6s	1697	[train]  epoch 40/100,  batch 161/188,  loss_train=1.10759,  acc_train=70.31%
5316.4s	1698	[train]  epoch 40/100,  batch 171/188,  loss_train=0.83404,  acc_train=75.00%
5321.9s	1699	[train]  epoch 40/100,  batch 181/188,  loss_train=1.33687,  acc_train=64.06%
5326.5s	1700	[ val ]  epoch 40/100,  batch 1/135,  loss_val=3.30547,  acc_val=23.44%
5328.3s	1701	[ val ]  epoch 40/100,  batch 11/135,  loss_val=1.75150,  acc_val=56.25%
5330.1s	1702	[ val ]  epoch 40/100,  batch 21/135,  loss_val=2.25897,  acc_val=43.75%
5331.8s	1703	[ val ]  epoch 40/100,  batch 31/135,  loss_val=2.40448,  acc_val=40.62%
5333.6s	1704	[ val ]  epoch 40/100,  batch 41/135,  loss_val=2.21723,  acc_val=43.75%
5335.5s	1705	[ val ]  epoch 40/100,  batch 51/135,  loss_val=1.97213,  acc_val=56.25%
5337.3s	1706	[ val ]  epoch 40/100,  batch 61/135,  loss_val=1.96473,  acc_val=54.69%
5339.0s	1707	[ val ]  epoch 40/100,  batch 71/135,  loss_val=2.50151,  acc_val=23.44%
5340.8s	1708	[ val ]  epoch 40/100,  batch 81/135,  loss_val=2.21943,  acc_val=54.69%
5342.6s	1709	[ val ]  epoch 40/100,  batch 91/135,  loss_val=3.70509,  acc_val=17.19%
5344.4s	1710	[ val ]  epoch 40/100,  batch 101/135,  loss_val=2.58807,  acc_val=29.69%
5346.1s	1711	[ val ]  epoch 40/100,  batch 111/135,  loss_val=2.63403,  acc_val=29.69%
5348.1s	1712	[ val ]  epoch 40/100,  batch 121/135,  loss_val=1.69552,  acc_val=59.38%
5349.7s	1713	[ val ]  epoch 40/100,  batch 131/135,  loss_val=3.74694,  acc_val=32.81%
5350.3s	1714	===================================================================================================================
5350.3s	1715	Epoch 40/100 summary: loss_train=1.11768, acc_train=66.15%, loss_val=2.39, acc_val=42.28% (best: 43.39% @ epoch 37)
5350.3s	1716	===================================================================================================================
5350.3s	1717	Starting epoch 41/100, learning_rate=0.1
5351.6s	1718	[train]  epoch 41/100,  batch 1/188,  loss_train=1.12147,  acc_train=65.62%
5357.2s	1719	[train]  epoch 41/100,  batch 11/188,  loss_train=0.94880,  acc_train=70.31%
5362.8s	1720	[train]  epoch 41/100,  batch 21/188,  loss_train=0.94114,  acc_train=68.75%
5368.4s	1721	[train]  epoch 41/100,  batch 31/188,  loss_train=0.81245,  acc_train=75.00%
5374.1s	1722	[train]  epoch 41/100,  batch 41/188,  loss_train=1.26256,  acc_train=60.94%
5379.9s	1723	[train]  epoch 41/100,  batch 51/188,  loss_train=1.16036,  acc_train=73.44%
5385.4s	1724	[train]  epoch 41/100,  batch 61/188,  loss_train=1.16551,  acc_train=62.50%
5391.0s	1725	[train]  epoch 41/100,  batch 71/188,  loss_train=0.79821,  acc_train=76.56%
5396.6s	1726	[train]  epoch 41/100,  batch 81/188,  loss_train=1.13078,  acc_train=68.75%
5402.3s	1727	[train]  epoch 41/100,  batch 91/188,  loss_train=1.22391,  acc_train=70.31%
5407.9s	1728	[train]  epoch 41/100,  batch 101/188,  loss_train=1.33439,  acc_train=64.06%
5413.7s	1729	[train]  epoch 41/100,  batch 111/188,  loss_train=1.08126,  acc_train=64.06%
5419.2s	1730	[train]  epoch 41/100,  batch 121/188,  loss_train=1.37236,  acc_train=57.81%
5424.8s	1731	[train]  epoch 41/100,  batch 131/188,  loss_train=1.07408,  acc_train=65.62%
5430.4s	1732	[train]  epoch 41/100,  batch 141/188,  loss_train=1.04426,  acc_train=67.19%
5436.0s	1733	[train]  epoch 41/100,  batch 151/188,  loss_train=0.95145,  acc_train=70.31%
5441.6s	1734	[train]  epoch 41/100,  batch 161/188,  loss_train=1.25827,  acc_train=65.62%
5447.4s	1735	[train]  epoch 41/100,  batch 171/188,  loss_train=1.21660,  acc_train=56.25%
5452.9s	1736	[train]  epoch 41/100,  batch 181/188,  loss_train=0.86292,  acc_train=75.00%
5457.5s	1737	[ val ]  epoch 41/100,  batch 1/135,  loss_val=4.02328,  acc_val=25.00%
5459.3s	1738	[ val ]  epoch 41/100,  batch 11/135,  loss_val=4.44989,  acc_val=17.19%
5461.1s	1739	[ val ]  epoch 41/100,  batch 21/135,  loss_val=2.13863,  acc_val=40.62%
5463.1s	1740	[ val ]  epoch 41/100,  batch 31/135,  loss_val=2.61370,  acc_val=43.75%
5464.9s	1741	[ val ]  epoch 41/100,  batch 41/135,  loss_val=2.79530,  acc_val=39.06%
5466.7s	1742	[ val ]  epoch 41/100,  batch 51/135,  loss_val=2.36081,  acc_val=46.88%
5468.4s	1743	[ val ]  epoch 41/100,  batch 61/135,  loss_val=4.75700,  acc_val=14.06%
5470.2s	1744	[ val ]  epoch 41/100,  batch 71/135,  loss_val=2.97121,  acc_val=34.38%
5472.0s	1745	[ val ]  epoch 41/100,  batch 81/135,  loss_val=3.22252,  acc_val=31.25%
5473.8s	1746	[ val ]  epoch 41/100,  batch 91/135,  loss_val=2.62124,  acc_val=29.69%
5475.6s	1747	[ val ]  epoch 41/100,  batch 101/135,  loss_val=0.59381,  acc_val=82.81%
5477.6s	1748	[ val ]  epoch 41/100,  batch 111/135,  loss_val=4.38231,  acc_val=12.50%
5479.2s	1749	[ val ]  epoch 41/100,  batch 121/135,  loss_val=1.36073,  acc_val=65.62%
5480.9s	1750	[ val ]  epoch 41/100,  batch 131/135,  loss_val=3.12020,  acc_val=37.50%
5481.5s	1751	===================================================================================================================
5481.5s	1752	Epoch 41/100 summary: loss_train=1.07034, acc_train=67.21%, loss_val=2.80, acc_val=35.81% (best: 43.39% @ epoch 37)
5481.5s	1753	===================================================================================================================
5481.5s	1754	Starting epoch 42/100, learning_rate=0.1
5482.8s	1755	[train]  epoch 42/100,  batch 1/188,  loss_train=1.02869,  acc_train=68.75%
5488.4s	1756	[train]  epoch 42/100,  batch 11/188,  loss_train=1.01466,  acc_train=67.19%
5494.1s	1757	[train]  epoch 42/100,  batch 21/188,  loss_train=1.07261,  acc_train=64.06%
5499.7s	1758	[train]  epoch 42/100,  batch 31/188,  loss_train=0.88997,  acc_train=73.44%
5505.4s	1759	[train]  epoch 42/100,  batch 41/188,  loss_train=1.23972,  acc_train=56.25%
5511.2s	1760	[train]  epoch 42/100,  batch 51/188,  loss_train=0.96958,  acc_train=70.31%
5516.7s	1761	[train]  epoch 42/100,  batch 61/188,  loss_train=0.91549,  acc_train=76.56%
5522.3s	1762	[train]  epoch 42/100,  batch 71/188,  loss_train=1.22848,  acc_train=59.38%
5528.0s	1763	[train]  epoch 42/100,  batch 81/188,  loss_train=1.00668,  acc_train=70.31%
5533.6s	1764	[train]  epoch 42/100,  batch 91/188,  loss_train=1.02463,  acc_train=70.31%
5539.2s	1765	[train]  epoch 42/100,  batch 101/188,  loss_train=1.12434,  acc_train=67.19%
5545.0s	1766	[train]  epoch 42/100,  batch 111/188,  loss_train=1.47589,  acc_train=56.25%
5550.4s	1767	[train]  epoch 42/100,  batch 121/188,  loss_train=1.19504,  acc_train=68.75%
5556.1s	1768	[train]  epoch 42/100,  batch 131/188,  loss_train=0.97914,  acc_train=70.31%
5561.8s	1769	[train]  epoch 42/100,  batch 141/188,  loss_train=0.66550,  acc_train=84.38%
5567.4s	1770	[train]  epoch 42/100,  batch 151/188,  loss_train=1.12311,  acc_train=56.25%
5573.0s	1771	[train]  epoch 42/100,  batch 161/188,  loss_train=0.83059,  acc_train=71.88%
5578.8s	1772	[train]  epoch 42/100,  batch 171/188,  loss_train=1.13593,  acc_train=73.44%
5584.3s	1773	[train]  epoch 42/100,  batch 181/188,  loss_train=1.25329,  acc_train=67.19%
5588.9s	1774	[ val ]  epoch 42/100,  batch 1/135,  loss_val=3.21660,  acc_val=21.88%
5590.9s	1775	[ val ]  epoch 42/100,  batch 11/135,  loss_val=2.26774,  acc_val=45.31%
5592.7s	1776	[ val ]  epoch 42/100,  batch 21/135,  loss_val=2.32994,  acc_val=48.44%
5594.5s	1777	[ val ]  epoch 42/100,  batch 31/135,  loss_val=1.65325,  acc_val=64.06%
5596.3s	1778	[ val ]  epoch 42/100,  batch 41/135,  loss_val=3.78902,  acc_val=18.75%
5598.1s	1779	[ val ]  epoch 42/100,  batch 51/135,  loss_val=4.04254,  acc_val=29.69%
5599.8s	1780	[ val ]  epoch 42/100,  batch 61/135,  loss_val=2.97598,  acc_val=37.50%
5601.7s	1781	[ val ]  epoch 42/100,  batch 71/135,  loss_val=1.95644,  acc_val=43.75%
5603.4s	1782	[ val ]  epoch 42/100,  batch 81/135,  loss_val=2.64247,  acc_val=48.44%
5605.2s	1783	[ val ]  epoch 42/100,  batch 91/135,  loss_val=2.25500,  acc_val=45.31%
5607.0s	1784	[ val ]  epoch 42/100,  batch 101/135,  loss_val=1.62847,  acc_val=43.75%
5608.8s	1785	[ val ]  epoch 42/100,  batch 111/135,  loss_val=2.31873,  acc_val=39.06%
5610.8s	1786	[ val ]  epoch 42/100,  batch 121/135,  loss_val=1.61717,  acc_val=62.50%
5612.3s	1787	[ val ]  epoch 42/100,  batch 131/135,  loss_val=2.92500,  acc_val=40.62%
5612.9s	1788	===================================================================================================================
5612.9s	1789	Epoch 42/100 summary: loss_train=1.06442, acc_train=67.74%, loss_val=2.37, acc_val=42.66% (best: 43.39% @ epoch 37)
5612.9s	1790	===================================================================================================================
5612.9s	1791	Starting epoch 43/100, learning_rate=0.1
5614.2s	1792	[train]  epoch 43/100,  batch 1/188,  loss_train=0.94590,  acc_train=71.88%
5619.8s	1793	[train]  epoch 43/100,  batch 11/188,  loss_train=1.10116,  acc_train=75.00%
5625.5s	1794	[train]  epoch 43/100,  batch 21/188,  loss_train=0.89042,  acc_train=73.44%
5631.1s	1795	[train]  epoch 43/100,  batch 31/188,  loss_train=1.04708,  acc_train=71.88%
5636.8s	1796	[train]  epoch 43/100,  batch 41/188,  loss_train=0.99735,  acc_train=67.19%
5642.7s	1797	[train]  epoch 43/100,  batch 51/188,  loss_train=0.89195,  acc_train=75.00%
5648.0s	1798	[train]  epoch 43/100,  batch 61/188,  loss_train=1.01005,  acc_train=68.75%
5653.6s	1799	[train]  epoch 43/100,  batch 71/188,  loss_train=1.20478,  acc_train=67.19%
5659.3s	1800	[train]  epoch 43/100,  batch 81/188,  loss_train=0.92491,  acc_train=67.19%
5664.9s	1801	[train]  epoch 43/100,  batch 91/188,  loss_train=1.03093,  acc_train=68.75%
5670.5s	1802	[train]  epoch 43/100,  batch 101/188,  loss_train=0.97329,  acc_train=73.44%
5676.3s	1803	[train]  epoch 43/100,  batch 111/188,  loss_train=1.07428,  acc_train=68.75%
5681.8s	1804	[train]  epoch 43/100,  batch 121/188,  loss_train=1.22653,  acc_train=64.06%
5687.4s	1805	[train]  epoch 43/100,  batch 131/188,  loss_train=1.32409,  acc_train=59.38%
5693.0s	1806	[train]  epoch 43/100,  batch 141/188,  loss_train=1.16765,  acc_train=64.06%
5698.6s	1807	[train]  epoch 43/100,  batch 151/188,  loss_train=1.16807,  acc_train=62.50%
5704.3s	1808	[train]  epoch 43/100,  batch 161/188,  loss_train=1.08856,  acc_train=65.62%
5710.0s	1809	[train]  epoch 43/100,  batch 171/188,  loss_train=1.06149,  acc_train=67.19%
5715.6s	1810	[train]  epoch 43/100,  batch 181/188,  loss_train=0.92566,  acc_train=71.88%
5720.2s	1811	[ val ]  epoch 43/100,  batch 1/135,  loss_val=3.46690,  acc_val=23.44%
5722.0s	1812	[ val ]  epoch 43/100,  batch 11/135,  loss_val=2.33647,  acc_val=45.31%
5723.8s	1813	[ val ]  epoch 43/100,  batch 21/135,  loss_val=3.58446,  acc_val=17.19%
5725.6s	1814	[ val ]  epoch 43/100,  batch 31/135,  loss_val=3.59509,  acc_val=26.56%
5727.4s	1815	[ val ]  epoch 43/100,  batch 41/135,  loss_val=2.19944,  acc_val=45.31%
5729.2s	1816	[ val ]  epoch 43/100,  batch 51/135,  loss_val=2.37130,  acc_val=51.56%
5730.9s	1817	[ val ]  epoch 43/100,  batch 61/135,  loss_val=3.13921,  acc_val=34.38%
5732.7s	1818	[ val ]  epoch 43/100,  batch 71/135,  loss_val=2.39883,  acc_val=35.94%
5734.5s	1819	[ val ]  epoch 43/100,  batch 81/135,  loss_val=2.09900,  acc_val=57.81%
5736.2s	1820	[ val ]  epoch 43/100,  batch 91/135,  loss_val=2.65808,  acc_val=29.69%
5738.0s	1821	[ val ]  epoch 43/100,  batch 101/135,  loss_val=1.54611,  acc_val=46.88%
5739.8s	1822	[ val ]  epoch 43/100,  batch 111/135,  loss_val=3.54125,  acc_val=18.75%
5741.7s	1823	[ val ]  epoch 43/100,  batch 121/135,  loss_val=1.29997,  acc_val=60.94%
5743.3s	1824	[ val ]  epoch 43/100,  batch 131/135,  loss_val=2.30269,  acc_val=45.31%
5743.9s	1825	===================================================================================================================
5743.9s	1826	Epoch 43/100 summary: loss_train=1.02692, acc_train=69.02%, loss_val=2.31, acc_val=42.50% (best: 43.39% @ epoch 37)
5743.9s	1827	===================================================================================================================
5743.9s	1828	Starting epoch 44/100, learning_rate=0.1
5745.2s	1829	[train]  epoch 44/100,  batch 1/188,  loss_train=0.70312,  acc_train=78.12%
5750.8s	1830	[train]  epoch 44/100,  batch 11/188,  loss_train=1.11868,  acc_train=64.06%
5756.4s	1831	[train]  epoch 44/100,  batch 21/188,  loss_train=0.68542,  acc_train=79.69%
5762.0s	1832	[train]  epoch 44/100,  batch 31/188,  loss_train=0.79166,  acc_train=79.69%
5767.7s	1833	[train]  epoch 44/100,  batch 41/188,  loss_train=0.74471,  acc_train=73.44%
5773.5s	1834	[train]  epoch 44/100,  batch 51/188,  loss_train=1.18663,  acc_train=65.62%
5778.9s	1835	[train]  epoch 44/100,  batch 61/188,  loss_train=0.70143,  acc_train=78.12%
5784.6s	1836	[train]  epoch 44/100,  batch 71/188,  loss_train=0.85719,  acc_train=71.88%
5790.2s	1837	[train]  epoch 44/100,  batch 81/188,  loss_train=0.91706,  acc_train=71.88%
5795.9s	1838	[train]  epoch 44/100,  batch 91/188,  loss_train=0.70573,  acc_train=81.25%
5801.5s	1839	[train]  epoch 44/100,  batch 101/188,  loss_train=0.90881,  acc_train=73.44%
5807.3s	1840	[train]  epoch 44/100,  batch 111/188,  loss_train=0.72793,  acc_train=70.31%
5812.7s	1841	[train]  epoch 44/100,  batch 121/188,  loss_train=0.94820,  acc_train=71.88%
5818.3s	1842	[train]  epoch 44/100,  batch 131/188,  loss_train=1.01418,  acc_train=68.75%
5824.0s	1843	[train]  epoch 44/100,  batch 141/188,  loss_train=1.02771,  acc_train=67.19%
5829.6s	1844	[train]  epoch 44/100,  batch 151/188,  loss_train=0.85947,  acc_train=76.56%
5835.2s	1845	[train]  epoch 44/100,  batch 161/188,  loss_train=1.14656,  acc_train=65.62%
5841.1s	1846	[train]  epoch 44/100,  batch 171/188,  loss_train=1.01167,  acc_train=67.19%
5846.6s	1847	[train]  epoch 44/100,  batch 181/188,  loss_train=0.94340,  acc_train=68.75%
5851.3s	1848	[ val ]  epoch 44/100,  batch 1/135,  loss_val=3.82304,  acc_val=18.75%
5853.1s	1849	[ val ]  epoch 44/100,  batch 11/135,  loss_val=2.80050,  acc_val=40.62%
5854.8s	1850	[ val ]  epoch 44/100,  batch 21/135,  loss_val=3.11312,  acc_val=26.56%
5856.6s	1851	[ val ]  epoch 44/100,  batch 31/135,  loss_val=4.02559,  acc_val=17.19%
5858.4s	1852	[ val ]  epoch 44/100,  batch 41/135,  loss_val=2.03331,  acc_val=43.75%
5860.2s	1853	[ val ]  epoch 44/100,  batch 51/135,  loss_val=3.07940,  acc_val=31.25%
5862.0s	1854	[ val ]  epoch 44/100,  batch 61/135,  loss_val=3.65332,  acc_val=26.56%
5863.8s	1855	[ val ]  epoch 44/100,  batch 71/135,  loss_val=3.40727,  acc_val=21.88%
5865.5s	1856	[ val ]  epoch 44/100,  batch 81/135,  loss_val=3.68035,  acc_val=32.81%
5867.3s	1857	[ val ]  epoch 44/100,  batch 91/135,  loss_val=2.45859,  acc_val=32.81%
5869.1s	1858	[ val ]  epoch 44/100,  batch 101/135,  loss_val=0.92239,  acc_val=70.31%
5870.9s	1859	[ val ]  epoch 44/100,  batch 111/135,  loss_val=3.88415,  acc_val=21.88%
5872.9s	1860	[ val ]  epoch 44/100,  batch 121/135,  loss_val=2.18039,  acc_val=45.31%
5874.5s	1861	[ val ]  epoch 44/100,  batch 131/135,  loss_val=3.32637,  acc_val=32.81%
5875.1s	1862	===================================================================================================================
5875.1s	1863	Epoch 44/100 summary: loss_train=0.97072, acc_train=69.76%, loss_val=2.72, acc_val=37.99% (best: 43.39% @ epoch 37)
5875.1s	1864	===================================================================================================================
5875.1s	1865	Starting epoch 45/100, learning_rate=0.1
5876.4s	1866	[train]  epoch 45/100,  batch 1/188,  loss_train=0.97740,  acc_train=64.06%
5882.0s	1867	[train]  epoch 45/100,  batch 11/188,  loss_train=1.11172,  acc_train=75.00%
5887.7s	1868	[train]  epoch 45/100,  batch 21/188,  loss_train=0.77160,  acc_train=73.44%
5893.3s	1869	[train]  epoch 45/100,  batch 31/188,  loss_train=1.09135,  acc_train=73.44%
5898.9s	1870	[train]  epoch 45/100,  batch 41/188,  loss_train=0.70112,  acc_train=79.69%
5904.7s	1871	[train]  epoch 45/100,  batch 51/188,  loss_train=0.95187,  acc_train=67.19%
5910.2s	1872	[train]  epoch 45/100,  batch 61/188,  loss_train=0.97606,  acc_train=71.88%
5915.8s	1873	[train]  epoch 45/100,  batch 71/188,  loss_train=0.89356,  acc_train=71.88%
5921.4s	1874	[train]  epoch 45/100,  batch 81/188,  loss_train=1.11885,  acc_train=64.06%
5927.1s	1875	[train]  epoch 45/100,  batch 91/188,  loss_train=0.84636,  acc_train=76.56%
5932.7s	1876	[train]  epoch 45/100,  batch 101/188,  loss_train=1.08706,  acc_train=67.19%
5938.5s	1877	[train]  epoch 45/100,  batch 111/188,  loss_train=0.73227,  acc_train=81.25%
5944.0s	1878	[train]  epoch 45/100,  batch 121/188,  loss_train=1.37396,  acc_train=60.94%
5949.6s	1879	[train]  epoch 45/100,  batch 131/188,  loss_train=1.02326,  acc_train=73.44%
5955.3s	1880	[train]  epoch 45/100,  batch 141/188,  loss_train=1.26109,  acc_train=67.19%
5960.9s	1881	[train]  epoch 45/100,  batch 151/188,  loss_train=0.84813,  acc_train=76.56%
5966.5s	1882	[train]  epoch 45/100,  batch 161/188,  loss_train=0.74719,  acc_train=78.12%
5972.3s	1883	[train]  epoch 45/100,  batch 171/188,  loss_train=1.33691,  acc_train=51.56%
5977.8s	1884	[train]  epoch 45/100,  batch 181/188,  loss_train=0.93283,  acc_train=75.00%
5982.4s	1885	[ val ]  epoch 45/100,  batch 1/135,  loss_val=4.46641,  acc_val=23.44%
5984.2s	1886	[ val ]  epoch 45/100,  batch 11/135,  loss_val=2.67236,  acc_val=43.75%
5986.0s	1887	[ val ]  epoch 45/100,  batch 21/135,  loss_val=3.78428,  acc_val=26.56%
5987.8s	1888	[ val ]  epoch 45/100,  batch 31/135,  loss_val=1.07330,  acc_val=68.75%
5989.5s	1889	[ val ]  epoch 45/100,  batch 41/135,  loss_val=1.50716,  acc_val=67.19%
5991.3s	1890	[ val ]  epoch 45/100,  batch 51/135,  loss_val=1.99980,  acc_val=50.00%
5993.1s	1891	[ val ]  epoch 45/100,  batch 61/135,  loss_val=3.85868,  acc_val=23.44%
5994.9s	1892	[ val ]  epoch 45/100,  batch 71/135,  loss_val=4.59966,  acc_val=7.81%
5996.7s	1893	[ val ]  epoch 45/100,  batch 81/135,  loss_val=3.12808,  acc_val=50.00%
5998.5s	1894	[ val ]  epoch 45/100,  batch 91/135,  loss_val=3.07643,  acc_val=25.00%
6000.2s	1895	[ val ]  epoch 45/100,  batch 101/135,  loss_val=2.09496,  acc_val=39.06%
6002.0s	1896	[ val ]  epoch 45/100,  batch 111/135,  loss_val=4.54956,  acc_val=18.75%
6004.0s	1897	[ val ]  epoch 45/100,  batch 121/135,  loss_val=1.82453,  acc_val=50.00%
6005.6s	1898	[ val ]  epoch 45/100,  batch 131/135,  loss_val=3.33239,  acc_val=25.00%
6006.2s	1899	===================================================================================================================
6006.2s	1900	Epoch 45/100 summary: loss_train=0.94826, acc_train=70.95%, loss_val=3.01, acc_val=35.24% (best: 43.39% @ epoch 37)
6006.2s	1901	===================================================================================================================
6006.2s	1902	Starting epoch 46/100, learning_rate=0.1
6007.5s	1903	[train]  epoch 46/100,  batch 1/188,  loss_train=1.18423,  acc_train=64.06%
6013.1s	1904	[train]  epoch 46/100,  batch 11/188,  loss_train=0.66515,  acc_train=84.38%
6018.7s	1905	[train]  epoch 46/100,  batch 21/188,  loss_train=1.01077,  acc_train=64.06%
6024.3s	1906	[train]  epoch 46/100,  batch 31/188,  loss_train=0.86283,  acc_train=76.56%
6030.0s	1907	[train]  epoch 46/100,  batch 41/188,  loss_train=0.80109,  acc_train=75.00%
6035.8s	1908	[train]  epoch 46/100,  batch 51/188,  loss_train=0.74768,  acc_train=76.56%
6041.2s	1909	[train]  epoch 46/100,  batch 61/188,  loss_train=0.99913,  acc_train=65.62%
6046.8s	1910	[train]  epoch 46/100,  batch 71/188,  loss_train=0.92659,  acc_train=76.56%
6052.5s	1911	[train]  epoch 46/100,  batch 81/188,  loss_train=0.68303,  acc_train=78.12%
6058.1s	1912	[train]  epoch 46/100,  batch 91/188,  loss_train=0.80539,  acc_train=76.56%
6063.8s	1913	[train]  epoch 46/100,  batch 101/188,  loss_train=1.23887,  acc_train=53.12%
6069.6s	1914	[train]  epoch 46/100,  batch 111/188,  loss_train=1.03258,  acc_train=65.62%
6075.1s	1915	[train]  epoch 46/100,  batch 121/188,  loss_train=0.68578,  acc_train=81.25%
6080.7s	1916	[train]  epoch 46/100,  batch 131/188,  loss_train=0.91942,  acc_train=70.31%
6086.3s	1917	[train]  epoch 46/100,  batch 141/188,  loss_train=1.54596,  acc_train=53.12%
6091.9s	1918	[train]  epoch 46/100,  batch 151/188,  loss_train=0.69273,  acc_train=76.56%
6097.6s	1919	[train]  epoch 46/100,  batch 161/188,  loss_train=0.94764,  acc_train=62.50%
6103.4s	1920	[train]  epoch 46/100,  batch 171/188,  loss_train=0.83776,  acc_train=71.88%
6108.9s	1921	[train]  epoch 46/100,  batch 181/188,  loss_train=1.22713,  acc_train=59.38%
6113.4s	1922	[ val ]  epoch 46/100,  batch 1/135,  loss_val=2.07015,  acc_val=32.81%
6115.3s	1923	[ val ]  epoch 46/100,  batch 11/135,  loss_val=3.84571,  acc_val=18.75%
6117.1s	1924	[ val ]  epoch 46/100,  batch 21/135,  loss_val=1.63596,  acc_val=45.31%
6118.8s	1925	[ val ]  epoch 46/100,  batch 31/135,  loss_val=1.45068,  acc_val=65.62%
6120.6s	1926	[ val ]  epoch 46/100,  batch 41/135,  loss_val=1.22419,  acc_val=65.62%
6122.4s	1927	[ val ]  epoch 46/100,  batch 51/135,  loss_val=2.08769,  acc_val=56.25%
6124.1s	1928	[ val ]  epoch 46/100,  batch 61/135,  loss_val=2.98968,  acc_val=32.81%
6125.9s	1929	[ val ]  epoch 46/100,  batch 71/135,  loss_val=3.99816,  acc_val=20.31%
6127.7s	1930	[ val ]  epoch 46/100,  batch 81/135,  loss_val=2.90724,  acc_val=51.56%
6129.5s	1931	[ val ]  epoch 46/100,  batch 91/135,  loss_val=2.16214,  acc_val=29.69%
6131.3s	1932	[ val ]  epoch 46/100,  batch 101/135,  loss_val=0.56464,  acc_val=82.81%
6133.1s	1933	[ val ]  epoch 46/100,  batch 111/135,  loss_val=2.76980,  acc_val=29.69%
6135.2s	1934	[ val ]  epoch 46/100,  batch 121/135,  loss_val=2.61514,  acc_val=35.94%
6136.7s	1935	[ val ]  epoch 46/100,  batch 131/135,  loss_val=3.82121,  acc_val=21.88%
6137.3s	1936	===================================================================================================================
6137.3s	1937	Epoch 46/100 summary: loss_train=0.90402, acc_train=72.21%, loss_val=2.36, acc_val=42.86% (best: 43.39% @ epoch 37)
6137.3s	1938	===================================================================================================================
6137.3s	1939	Starting epoch 47/100, learning_rate=0.1
6138.6s	1940	[train]  epoch 47/100,  batch 1/188,  loss_train=0.99946,  acc_train=67.19%
6144.2s	1941	[train]  epoch 47/100,  batch 11/188,  loss_train=0.55315,  acc_train=81.25%
6149.8s	1942	[train]  epoch 47/100,  batch 21/188,  loss_train=0.81589,  acc_train=68.75%
6155.5s	1943	[train]  epoch 47/100,  batch 31/188,  loss_train=1.00749,  acc_train=64.06%
6161.1s	1944	[train]  epoch 47/100,  batch 41/188,  loss_train=0.87423,  acc_train=73.44%
6167.0s	1945	[train]  epoch 47/100,  batch 51/188,  loss_train=0.91803,  acc_train=71.88%
6172.4s	1946	[train]  epoch 47/100,  batch 61/188,  loss_train=0.95129,  acc_train=73.44%
6178.0s	1947	[train]  epoch 47/100,  batch 71/188,  loss_train=0.74890,  acc_train=76.56%
6183.7s	1948	[train]  epoch 47/100,  batch 81/188,  loss_train=0.62365,  acc_train=81.25%
6189.4s	1949	[train]  epoch 47/100,  batch 91/188,  loss_train=0.81144,  acc_train=75.00%
6195.0s	1950	[train]  epoch 47/100,  batch 101/188,  loss_train=1.02448,  acc_train=68.75%
6200.8s	1951	[train]  epoch 47/100,  batch 111/188,  loss_train=0.83097,  acc_train=78.12%
6206.3s	1952	[train]  epoch 47/100,  batch 121/188,  loss_train=0.74708,  acc_train=76.56%
6211.9s	1953	[train]  epoch 47/100,  batch 131/188,  loss_train=0.86548,  acc_train=73.44%
6217.6s	1954	[train]  epoch 47/100,  batch 141/188,  loss_train=1.01048,  acc_train=73.44%
6223.2s	1955	[train]  epoch 47/100,  batch 151/188,  loss_train=0.74385,  acc_train=71.88%
6228.8s	1956	[train]  epoch 47/100,  batch 161/188,  loss_train=0.77010,  acc_train=75.00%
6234.7s	1957	[train]  epoch 47/100,  batch 171/188,  loss_train=0.84439,  acc_train=71.88%
6240.1s	1958	[train]  epoch 47/100,  batch 181/188,  loss_train=1.04890,  acc_train=70.31%
6244.7s	1959	[ val ]  epoch 47/100,  batch 1/135,  loss_val=2.97854,  acc_val=31.25%
6246.5s	1960	[ val ]  epoch 47/100,  batch 11/135,  loss_val=2.07635,  acc_val=56.25%
6248.3s	1961	[ val ]  epoch 47/100,  batch 21/135,  loss_val=2.59022,  acc_val=31.25%
6250.1s	1962	[ val ]  epoch 47/100,  batch 31/135,  loss_val=0.52911,  acc_val=81.25%
6251.9s	1963	[ val ]  epoch 47/100,  batch 41/135,  loss_val=3.14713,  acc_val=34.38%
6253.7s	1964	[ val ]  epoch 47/100,  batch 51/135,  loss_val=2.37824,  acc_val=42.19%
6255.4s	1965	[ val ]  epoch 47/100,  batch 61/135,  loss_val=3.27942,  acc_val=35.94%
6257.2s	1966	[ val ]  epoch 47/100,  batch 71/135,  loss_val=2.28236,  acc_val=40.62%
6259.0s	1967	[ val ]  epoch 47/100,  batch 81/135,  loss_val=2.81964,  acc_val=54.69%
6260.8s	1968	[ val ]  epoch 47/100,  batch 91/135,  loss_val=4.16195,  acc_val=14.06%
6262.8s	1969	[ val ]  epoch 47/100,  batch 101/135,  loss_val=1.40078,  acc_val=65.62%
6264.6s	1970	[ val ]  epoch 47/100,  batch 111/135,  loss_val=4.42199,  acc_val=20.31%
6266.5s	1971	[ val ]  epoch 47/100,  batch 121/135,  loss_val=1.22431,  acc_val=65.62%
6268.1s	1972	[ val ]  epoch 47/100,  batch 131/135,  loss_val=2.84739,  acc_val=29.69%
6268.7s	1973	===================================================================================================================
6268.7s	1974	Epoch 47/100 summary: loss_train=0.87210, acc_train=72.92%, loss_val=2.58, acc_val=41.93% (best: 43.39% @ epoch 37)
6268.7s	1975	===================================================================================================================
6268.7s	1976	Starting epoch 48/100, learning_rate=0.1
6270.0s	1977	[train]  epoch 48/100,  batch 1/188,  loss_train=0.54537,  acc_train=84.38%
6275.6s	1978	[train]  epoch 48/100,  batch 11/188,  loss_train=1.23703,  acc_train=60.94%
6281.3s	1979	[train]  epoch 48/100,  batch 21/188,  loss_train=0.64159,  acc_train=81.25%
6286.9s	1980	[train]  epoch 48/100,  batch 31/188,  loss_train=0.89762,  acc_train=71.88%
6292.5s	1981	[train]  epoch 48/100,  batch 41/188,  loss_train=0.83047,  acc_train=71.88%
6298.4s	1982	[train]  epoch 48/100,  batch 51/188,  loss_train=0.42392,  acc_train=89.06%
6303.8s	1983	[train]  epoch 48/100,  batch 61/188,  loss_train=0.75647,  acc_train=73.44%
6309.4s	1984	[train]  epoch 48/100,  batch 71/188,  loss_train=0.77434,  acc_train=73.44%
6315.1s	1985	[train]  epoch 48/100,  batch 81/188,  loss_train=0.82558,  acc_train=70.31%
6320.7s	1986	[train]  epoch 48/100,  batch 91/188,  loss_train=0.85861,  acc_train=71.88%
6326.3s	1987	[train]  epoch 48/100,  batch 101/188,  loss_train=0.57849,  acc_train=82.81%
6332.2s	1988	[train]  epoch 48/100,  batch 111/188,  loss_train=0.79029,  acc_train=75.00%
6337.6s	1989	[train]  epoch 48/100,  batch 121/188,  loss_train=0.79316,  acc_train=76.56%
6343.3s	1990	[train]  epoch 48/100,  batch 131/188,  loss_train=1.15650,  acc_train=71.88%
6348.9s	1991	[train]  epoch 48/100,  batch 141/188,  loss_train=0.79444,  acc_train=73.44%
6354.5s	1992	[train]  epoch 48/100,  batch 151/188,  loss_train=1.02506,  acc_train=68.75%
6360.2s	1993	[train]  epoch 48/100,  batch 161/188,  loss_train=0.74362,  acc_train=79.69%
6365.9s	1994	[train]  epoch 48/100,  batch 171/188,  loss_train=1.34808,  acc_train=59.38%
6371.4s	1995	[train]  epoch 48/100,  batch 181/188,  loss_train=1.15018,  acc_train=60.94%
6376.0s	1996	[ val ]  epoch 48/100,  batch 1/135,  loss_val=2.13438,  acc_val=45.31%
6377.8s	1997	[ val ]  epoch 48/100,  batch 11/135,  loss_val=2.92351,  acc_val=34.38%
6379.5s	1998	[ val ]  epoch 48/100,  batch 21/135,  loss_val=2.91352,  acc_val=21.88%
6381.3s	1999	[ val ]  epoch 48/100,  batch 31/135,  loss_val=2.33164,  acc_val=45.31%
6383.1s	2000	[ val ]  epoch 48/100,  batch 41/135,  loss_val=1.54964,  acc_val=57.81%
6384.9s	2001	[ val ]  epoch 48/100,  batch 51/135,  loss_val=2.16135,  acc_val=43.75%
6386.7s	2002	[ val ]  epoch 48/100,  batch 61/135,  loss_val=1.92331,  acc_val=60.94%
6388.5s	2003	[ val ]  epoch 48/100,  batch 71/135,  loss_val=2.00851,  acc_val=54.69%
6390.3s	2004	[ val ]  epoch 48/100,  batch 81/135,  loss_val=2.20428,  acc_val=46.88%
6392.1s	2005	[ val ]  epoch 48/100,  batch 91/135,  loss_val=3.43443,  acc_val=25.00%
6393.9s	2006	[ val ]  epoch 48/100,  batch 101/135,  loss_val=0.66923,  acc_val=84.38%
6395.7s	2007	[ val ]  epoch 48/100,  batch 111/135,  loss_val=3.07986,  acc_val=31.25%
6397.7s	2008	[ val ]  epoch 48/100,  batch 121/135,  loss_val=1.21417,  acc_val=62.50%
6399.2s	2009	[ val ]  epoch 48/100,  batch 131/135,  loss_val=2.46804,  acc_val=40.62%
6399.8s	2010	===================================================================================================================
6399.8s	2011	Epoch 48/100 summary: loss_train=0.86449, acc_train=73.06%, loss_val=2.31, acc_val=42.75% (best: 43.39% @ epoch 37)
6399.8s	2012	===================================================================================================================
6399.8s	2013	Starting epoch 49/100, learning_rate=0.1
6401.1s	2014	[train]  epoch 49/100,  batch 1/188,  loss_train=0.60335,  acc_train=84.38%
6406.8s	2015	[train]  epoch 49/100,  batch 11/188,  loss_train=0.85775,  acc_train=70.31%
6412.4s	2016	[train]  epoch 49/100,  batch 21/188,  loss_train=0.70263,  acc_train=76.56%
6418.0s	2017	[train]  epoch 49/100,  batch 31/188,  loss_train=0.73729,  acc_train=76.56%
6423.7s	2018	[train]  epoch 49/100,  batch 41/188,  loss_train=1.05052,  acc_train=67.19%
6429.5s	2019	[train]  epoch 49/100,  batch 51/188,  loss_train=0.72423,  acc_train=81.25%
6435.0s	2020	[train]  epoch 49/100,  batch 61/188,  loss_train=0.70332,  acc_train=76.56%
6440.6s	2021	[train]  epoch 49/100,  batch 71/188,  loss_train=0.99838,  acc_train=65.62%
6446.2s	2022	[train]  epoch 49/100,  batch 81/188,  loss_train=0.60310,  acc_train=78.12%
6451.8s	2023	[train]  epoch 49/100,  batch 91/188,  loss_train=0.83604,  acc_train=68.75%
6457.5s	2024	[train]  epoch 49/100,  batch 101/188,  loss_train=0.76727,  acc_train=78.12%
6463.3s	2025	[train]  epoch 49/100,  batch 111/188,  loss_train=0.76922,  acc_train=81.25%
6468.7s	2026	[train]  epoch 49/100,  batch 121/188,  loss_train=0.80921,  acc_train=76.56%
6474.3s	2027	[train]  epoch 49/100,  batch 131/188,  loss_train=1.10150,  acc_train=62.50%
6480.0s	2028	[train]  epoch 49/100,  batch 141/188,  loss_train=0.98481,  acc_train=70.31%
6485.6s	2029	[train]  epoch 49/100,  batch 151/188,  loss_train=1.11628,  acc_train=65.62%
6491.3s	2030	[train]  epoch 49/100,  batch 161/188,  loss_train=0.93836,  acc_train=71.88%
6497.1s	2031	[train]  epoch 49/100,  batch 171/188,  loss_train=0.93987,  acc_train=75.00%
6502.5s	2032	[train]  epoch 49/100,  batch 181/188,  loss_train=0.59095,  acc_train=82.81%
6507.2s	2033	[ val ]  epoch 49/100,  batch 1/135,  loss_val=5.31621,  acc_val=17.19%
6509.0s	2034	[ val ]  epoch 49/100,  batch 11/135,  loss_val=3.44296,  acc_val=23.44%
6510.8s	2035	[ val ]  epoch 49/100,  batch 21/135,  loss_val=3.14771,  acc_val=29.69%
6512.5s	2036	[ val ]  epoch 49/100,  batch 31/135,  loss_val=0.70984,  acc_val=81.25%
6514.3s	2037	[ val ]  epoch 49/100,  batch 41/135,  loss_val=2.17354,  acc_val=46.88%
6516.1s	2038	[ val ]  epoch 49/100,  batch 51/135,  loss_val=2.04955,  acc_val=50.00%
6518.0s	2039	[ val ]  epoch 49/100,  batch 61/135,  loss_val=2.80406,  acc_val=28.12%
6519.8s	2040	[ val ]  epoch 49/100,  batch 71/135,  loss_val=2.81396,  acc_val=26.56%
6521.6s	2041	[ val ]  epoch 49/100,  batch 81/135,  loss_val=3.28374,  acc_val=51.56%
6523.4s	2042	[ val ]  epoch 49/100,  batch 91/135,  loss_val=3.02108,  acc_val=20.31%
6525.1s	2043	[ val ]  epoch 49/100,  batch 101/135,  loss_val=0.52040,  acc_val=84.38%
6526.9s	2044	[ val ]  epoch 49/100,  batch 111/135,  loss_val=3.34676,  acc_val=14.06%
6528.9s	2045	[ val ]  epoch 49/100,  batch 121/135,  loss_val=0.91419,  acc_val=78.12%
6530.5s	2046	[ val ]  epoch 49/100,  batch 131/135,  loss_val=2.42305,  acc_val=46.88%
6531.1s	2047	===================================================================================================================
6531.1s	2048	Epoch 49/100 summary: loss_train=0.83638, acc_train=74.02%, loss_val=2.34, acc_val=43.94% (best: 43.94% @ epoch 49)
6531.1s	2049	===================================================================================================================
6531.1s	2050	Starting epoch 50/100, learning_rate=0.1
6532.2s	2051	[train]  epoch 50/100,  batch 1/188,  loss_train=0.66343,  acc_train=75.00%
6537.9s	2052	[train]  epoch 50/100,  batch 11/188,  loss_train=0.76372,  acc_train=73.44%
6543.6s	2053	[train]  epoch 50/100,  batch 21/188,  loss_train=0.60109,  acc_train=85.94%
6549.2s	2054	[train]  epoch 50/100,  batch 31/188,  loss_train=0.94761,  acc_train=71.88%
6554.9s	2055	[train]  epoch 50/100,  batch 41/188,  loss_train=0.64612,  acc_train=75.00%
6560.6s	2056	[train]  epoch 50/100,  batch 51/188,  loss_train=0.83363,  acc_train=67.19%
6566.2s	2057	[train]  epoch 50/100,  batch 61/188,  loss_train=0.84946,  acc_train=79.69%
6571.8s	2058	[train]  epoch 50/100,  batch 71/188,  loss_train=0.75757,  acc_train=76.56%
6577.4s	2059	[train]  epoch 50/100,  batch 81/188,  loss_train=0.55481,  acc_train=87.50%
6583.0s	2060	[train]  epoch 50/100,  batch 91/188,  loss_train=0.66232,  acc_train=81.25%
6588.6s	2061	[train]  epoch 50/100,  batch 101/188,  loss_train=0.91386,  acc_train=71.88%
6594.4s	2062	[train]  epoch 50/100,  batch 111/188,  loss_train=0.70399,  acc_train=78.12%
6599.9s	2063	[train]  epoch 50/100,  batch 121/188,  loss_train=0.80886,  acc_train=73.44%
6605.5s	2064	[train]  epoch 50/100,  batch 131/188,  loss_train=0.87184,  acc_train=68.75%
6611.1s	2065	[train]  epoch 50/100,  batch 141/188,  loss_train=0.85443,  acc_train=79.69%
6616.7s	2066	[train]  epoch 50/100,  batch 151/188,  loss_train=0.98729,  acc_train=68.75%
6622.4s	2067	[train]  epoch 50/100,  batch 161/188,  loss_train=1.04432,  acc_train=65.62%
6628.2s	2068	[train]  epoch 50/100,  batch 171/188,  loss_train=0.99935,  acc_train=64.06%
6633.7s	2069	[train]  epoch 50/100,  batch 181/188,  loss_train=0.91617,  acc_train=73.44%
6638.5s	2070	[ val ]  epoch 50/100,  batch 1/135,  loss_val=3.06446,  acc_val=32.81%
6640.3s	2071	[ val ]  epoch 50/100,  batch 11/135,  loss_val=2.31833,  acc_val=45.31%
6642.1s	2072	[ val ]  epoch 50/100,  batch 21/135,  loss_val=2.27614,  acc_val=42.19%
6643.8s	2073	[ val ]  epoch 50/100,  batch 31/135,  loss_val=2.56994,  acc_val=48.44%
6645.7s	2074	[ val ]  epoch 50/100,  batch 41/135,  loss_val=3.25713,  acc_val=35.94%
6647.5s	2075	[ val ]  epoch 50/100,  batch 51/135,  loss_val=1.60493,  acc_val=67.19%
6649.3s	2076	[ val ]  epoch 50/100,  batch 61/135,  loss_val=2.76090,  acc_val=42.19%
6651.1s	2077	[ val ]  epoch 50/100,  batch 71/135,  loss_val=1.98700,  acc_val=45.31%
6652.9s	2078	[ val ]  epoch 50/100,  batch 81/135,  loss_val=2.35946,  acc_val=60.94%
6654.7s	2079	[ val ]  epoch 50/100,  batch 91/135,  loss_val=3.20986,  acc_val=29.69%
6656.5s	2080	[ val ]  epoch 50/100,  batch 101/135,  loss_val=1.85883,  acc_val=43.75%
6658.5s	2081	[ val ]  epoch 50/100,  batch 111/135,  loss_val=4.50049,  acc_val=14.06%
6660.1s	2082	[ val ]  epoch 50/100,  batch 121/135,  loss_val=1.48240,  acc_val=59.38%
6661.9s	2083	[ val ]  epoch 50/100,  batch 131/135,  loss_val=3.44714,  acc_val=39.06%
6662.5s	2084	===================================================================================================================
6662.5s	2085	Epoch 50/100 summary: loss_train=0.78637, acc_train=75.84%, loss_val=2.58, acc_val=42.59% (best: 43.94% @ epoch 49)
6662.5s	2086	===================================================================================================================
6662.5s	2087	Starting epoch 51/100, learning_rate=0.1
6663.8s	2088	[train]  epoch 51/100,  batch 1/188,  loss_train=0.47135,  acc_train=85.94%
6669.5s	2089	[train]  epoch 51/100,  batch 11/188,  loss_train=0.55670,  acc_train=85.94%
6675.1s	2090	[train]  epoch 51/100,  batch 21/188,  loss_train=0.64001,  acc_train=76.56%
6680.7s	2091	[train]  epoch 51/100,  batch 31/188,  loss_train=0.65424,  acc_train=75.00%
6686.4s	2092	[train]  epoch 51/100,  batch 41/188,  loss_train=0.99219,  acc_train=70.31%
6692.2s	2093	[train]  epoch 51/100,  batch 51/188,  loss_train=0.70617,  acc_train=75.00%
6697.6s	2094	[train]  epoch 51/100,  batch 61/188,  loss_train=0.90136,  acc_train=73.44%
6703.2s	2095	[train]  epoch 51/100,  batch 71/188,  loss_train=0.88973,  acc_train=73.44%
6708.9s	2096	[train]  epoch 51/100,  batch 81/188,  loss_train=0.74343,  acc_train=76.56%
6714.5s	2097	[train]  epoch 51/100,  batch 91/188,  loss_train=0.85789,  acc_train=70.31%
6720.1s	2098	[train]  epoch 51/100,  batch 101/188,  loss_train=0.78911,  acc_train=73.44%
6725.9s	2099	[train]  epoch 51/100,  batch 111/188,  loss_train=0.99950,  acc_train=67.19%
6731.3s	2100	[train]  epoch 51/100,  batch 121/188,  loss_train=1.00262,  acc_train=67.19%
6737.0s	2101	[train]  epoch 51/100,  batch 131/188,  loss_train=0.86644,  acc_train=70.31%
6742.6s	2102	[train]  epoch 51/100,  batch 141/188,  loss_train=0.90352,  acc_train=76.56%
6748.3s	2103	[train]  epoch 51/100,  batch 151/188,  loss_train=0.83990,  acc_train=73.44%
6754.0s	2104	[train]  epoch 51/100,  batch 161/188,  loss_train=0.69048,  acc_train=81.25%
6759.7s	2105	[train]  epoch 51/100,  batch 171/188,  loss_train=0.85288,  acc_train=71.88%
6765.2s	2106	[train]  epoch 51/100,  batch 181/188,  loss_train=0.63881,  acc_train=81.25%
6770.0s	2107	[ val ]  epoch 51/100,  batch 1/135,  loss_val=3.08591,  acc_val=34.38%
6771.9s	2108	[ val ]  epoch 51/100,  batch 11/135,  loss_val=3.93496,  acc_val=26.56%
6773.8s	2109	[ val ]  epoch 51/100,  batch 21/135,  loss_val=3.65282,  acc_val=35.94%
6775.6s	2110	[ val ]  epoch 51/100,  batch 31/135,  loss_val=1.67951,  acc_val=60.94%
6777.4s	2111	[ val ]  epoch 51/100,  batch 41/135,  loss_val=1.91755,  acc_val=57.81%
6779.2s	2112	[ val ]  epoch 51/100,  batch 51/135,  loss_val=3.96103,  acc_val=18.75%
6781.0s	2113	[ val ]  epoch 51/100,  batch 61/135,  loss_val=2.75040,  acc_val=50.00%
6782.8s	2114	[ val ]  epoch 51/100,  batch 71/135,  loss_val=2.44996,  acc_val=40.62%
6784.5s	2115	[ val ]  epoch 51/100,  batch 81/135,  loss_val=3.74939,  acc_val=50.00%
6786.3s	2116	[ val ]  epoch 51/100,  batch 91/135,  loss_val=3.80918,  acc_val=29.69%
6788.1s	2117	[ val ]  epoch 51/100,  batch 101/135,  loss_val=2.93784,  acc_val=26.56%
6790.1s	2118	[ val ]  epoch 51/100,  batch 111/135,  loss_val=2.81225,  acc_val=42.19%
6791.7s	2119	[ val ]  epoch 51/100,  batch 121/135,  loss_val=2.46269,  acc_val=35.94%
6793.5s	2120	[ val ]  epoch 51/100,  batch 131/135,  loss_val=3.28449,  acc_val=31.25%
6794.0s	2121	===================================================================================================================
6794.0s	2122	Epoch 51/100 summary: loss_train=0.76718, acc_train=75.75%, loss_val=2.84, acc_val=39.29% (best: 43.94% @ epoch 49)
6794.0s	2123	===================================================================================================================
6794.0s	2124	Starting epoch 52/100, learning_rate=0.1
6795.6s	2125	[train]  epoch 52/100,  batch 1/188,  loss_train=0.67731,  acc_train=81.25%
6801.3s	2126	[train]  epoch 52/100,  batch 11/188,  loss_train=1.14599,  acc_train=62.50%
6807.0s	2127	[train]  epoch 52/100,  batch 21/188,  loss_train=0.67102,  acc_train=79.69%
6812.6s	2128	[train]  epoch 52/100,  batch 31/188,  loss_train=0.48719,  acc_train=84.38%
6818.2s	2129	[train]  epoch 52/100,  batch 41/188,  loss_train=0.84573,  acc_train=71.88%
6824.1s	2130	[train]  epoch 52/100,  batch 51/188,  loss_train=0.60983,  acc_train=76.56%
6829.5s	2131	[train]  epoch 52/100,  batch 61/188,  loss_train=0.64628,  acc_train=76.56%
6835.2s	2132	[train]  epoch 52/100,  batch 71/188,  loss_train=0.58350,  acc_train=79.69%
6840.8s	2133	[train]  epoch 52/100,  batch 81/188,  loss_train=0.68861,  acc_train=84.38%
6846.5s	2134	[train]  epoch 52/100,  batch 91/188,  loss_train=0.62993,  acc_train=82.81%
6852.1s	2135	[train]  epoch 52/100,  batch 101/188,  loss_train=0.80464,  acc_train=73.44%
6857.9s	2136	[train]  epoch 52/100,  batch 111/188,  loss_train=0.70899,  acc_train=78.12%
6863.4s	2137	[train]  epoch 52/100,  batch 121/188,  loss_train=0.79882,  acc_train=81.25%
6869.1s	2138	[train]  epoch 52/100,  batch 131/188,  loss_train=0.88307,  acc_train=75.00%
6874.7s	2139	[train]  epoch 52/100,  batch 141/188,  loss_train=0.52736,  acc_train=85.94%
6880.4s	2140	[train]  epoch 52/100,  batch 151/188,  loss_train=0.76541,  acc_train=78.12%
6886.0s	2141	[train]  epoch 52/100,  batch 161/188,  loss_train=0.81078,  acc_train=76.56%
6891.8s	2142	[train]  epoch 52/100,  batch 171/188,  loss_train=0.63592,  acc_train=79.69%
6897.2s	2143	[train]  epoch 52/100,  batch 181/188,  loss_train=1.05628,  acc_train=67.19%
6901.8s	2144	[ val ]  epoch 52/100,  batch 1/135,  loss_val=4.17451,  acc_val=20.31%
6903.6s	2145	[ val ]  epoch 52/100,  batch 11/135,  loss_val=2.00431,  acc_val=46.88%
6905.4s	2146	[ val ]  epoch 52/100,  batch 21/135,  loss_val=3.72018,  acc_val=17.19%
6907.2s	2147	[ val ]  epoch 52/100,  batch 31/135,  loss_val=2.02434,  acc_val=50.00%
6909.0s	2148	[ val ]  epoch 52/100,  batch 41/135,  loss_val=2.44791,  acc_val=50.00%
6910.8s	2149	[ val ]  epoch 52/100,  batch 51/135,  loss_val=2.10967,  acc_val=43.75%
6912.5s	2150	[ val ]  epoch 52/100,  batch 61/135,  loss_val=2.79480,  acc_val=39.06%
6914.3s	2151	[ val ]  epoch 52/100,  batch 71/135,  loss_val=1.91975,  acc_val=46.88%
6916.0s	2152	[ val ]  epoch 52/100,  batch 81/135,  loss_val=3.21563,  acc_val=40.62%
6917.8s	2153	[ val ]  epoch 52/100,  batch 91/135,  loss_val=3.62072,  acc_val=26.56%
6919.6s	2154	[ val ]  epoch 52/100,  batch 101/135,  loss_val=1.85112,  acc_val=46.88%
6921.4s	2155	[ val ]  epoch 52/100,  batch 111/135,  loss_val=4.34504,  acc_val=15.62%
6923.3s	2156	[ val ]  epoch 52/100,  batch 121/135,  loss_val=1.44118,  acc_val=59.38%
6924.9s	2157	[ val ]  epoch 52/100,  batch 131/135,  loss_val=4.20740,  acc_val=14.06%
6925.5s	2158	===================================================================================================================
6925.5s	2159	Epoch 52/100 summary: loss_train=0.74819, acc_train=76.70%, loss_val=2.57, acc_val=40.94% (best: 43.94% @ epoch 49)
6925.5s	2160	===================================================================================================================
6925.5s	2161	Starting epoch 53/100, learning_rate=0.1
6926.8s	2162	[train]  epoch 53/100,  batch 1/188,  loss_train=0.68408,  acc_train=76.56%
6932.4s	2163	[train]  epoch 53/100,  batch 11/188,  loss_train=0.46342,  acc_train=84.38%
6938.0s	2164	[train]  epoch 53/100,  batch 21/188,  loss_train=0.81011,  acc_train=70.31%
6943.7s	2165	[train]  epoch 53/100,  batch 31/188,  loss_train=0.71818,  acc_train=78.12%
6949.3s	2166	[train]  epoch 53/100,  batch 41/188,  loss_train=0.74127,  acc_train=76.56%
6955.0s	2167	[train]  epoch 53/100,  batch 51/188,  loss_train=0.72736,  acc_train=78.12%
6960.6s	2168	[train]  epoch 53/100,  batch 61/188,  loss_train=0.77116,  acc_train=73.44%
6966.2s	2169	[train]  epoch 53/100,  batch 71/188,  loss_train=0.73808,  acc_train=70.31%
6971.9s	2170	[train]  epoch 53/100,  batch 81/188,  loss_train=0.63104,  acc_train=79.69%
6977.5s	2171	[train]  epoch 53/100,  batch 91/188,  loss_train=0.60001,  acc_train=78.12%
6983.1s	2172	[train]  epoch 53/100,  batch 101/188,  loss_train=0.74125,  acc_train=82.81%
6988.9s	2173	[train]  epoch 53/100,  batch 111/188,  loss_train=0.65308,  acc_train=76.56%
6994.4s	2174	[train]  epoch 53/100,  batch 121/188,  loss_train=0.80221,  acc_train=81.25%
7000.0s	2175	[train]  epoch 53/100,  batch 131/188,  loss_train=0.74361,  acc_train=76.56%
7005.7s	2176	[train]  epoch 53/100,  batch 141/188,  loss_train=0.90884,  acc_train=71.88%
7011.3s	2177	[train]  epoch 53/100,  batch 151/188,  loss_train=0.68801,  acc_train=79.69%
7016.9s	2178	[train]  epoch 53/100,  batch 161/188,  loss_train=0.50702,  acc_train=82.81%
7022.8s	2179	[train]  epoch 53/100,  batch 171/188,  loss_train=0.95717,  acc_train=68.75%
7028.2s	2180	[train]  epoch 53/100,  batch 181/188,  loss_train=0.63812,  acc_train=79.69%
7032.8s	2181	[ val ]  epoch 53/100,  batch 1/135,  loss_val=2.44889,  acc_val=42.19%
7034.6s	2182	[ val ]  epoch 53/100,  batch 11/135,  loss_val=2.30342,  acc_val=48.44%
7036.4s	2183	[ val ]  epoch 53/100,  batch 21/135,  loss_val=2.70742,  acc_val=29.69%
7038.2s	2184	[ val ]  epoch 53/100,  batch 31/135,  loss_val=0.74560,  acc_val=79.69%
7040.0s	2185	[ val ]  epoch 53/100,  batch 41/135,  loss_val=2.09385,  acc_val=53.12%
7041.8s	2186	[ val ]  epoch 53/100,  batch 51/135,  loss_val=2.25093,  acc_val=46.88%
7043.5s	2187	[ val ]  epoch 53/100,  batch 61/135,  loss_val=2.62717,  acc_val=37.50%
7045.3s	2188	[ val ]  epoch 53/100,  batch 71/135,  loss_val=2.44637,  acc_val=45.31%
7047.1s	2189	[ val ]  epoch 53/100,  batch 81/135,  loss_val=2.35681,  acc_val=57.81%
7048.9s	2190	[ val ]  epoch 53/100,  batch 91/135,  loss_val=3.64590,  acc_val=10.94%
7050.7s	2191	[ val ]  epoch 53/100,  batch 101/135,  loss_val=1.25902,  acc_val=62.50%
7052.5s	2192	[ val ]  epoch 53/100,  batch 111/135,  loss_val=2.59711,  acc_val=34.38%
7054.5s	2193	[ val ]  epoch 53/100,  batch 121/135,  loss_val=1.76923,  acc_val=59.38%
7056.1s	2194	[ val ]  epoch 53/100,  batch 131/135,  loss_val=2.94007,  acc_val=40.62%
7056.7s	2195	===================================================================================================================
7056.7s	2196	Epoch 53/100 summary: loss_train=0.74754, acc_train=76.68%, loss_val=2.27, acc_val=46.23% (best: 46.23% @ epoch 53)
7056.7s	2197	===================================================================================================================
7056.7s	2198	Starting epoch 54/100, learning_rate=0.1
7058.0s	2199	[train]  epoch 54/100,  batch 1/188,  loss_train=0.48535,  acc_train=84.38%
7063.7s	2200	[train]  epoch 54/100,  batch 11/188,  loss_train=0.77685,  acc_train=79.69%
7069.4s	2201	[train]  epoch 54/100,  batch 21/188,  loss_train=0.90031,  acc_train=67.19%
7075.0s	2202	[train]  epoch 54/100,  batch 31/188,  loss_train=0.55801,  acc_train=81.25%
7080.6s	2203	[train]  epoch 54/100,  batch 41/188,  loss_train=0.63011,  acc_train=78.12%
7086.4s	2204	[train]  epoch 54/100,  batch 51/188,  loss_train=0.90792,  acc_train=70.31%
7091.9s	2205	[train]  epoch 54/100,  batch 61/188,  loss_train=0.72651,  acc_train=67.19%
7097.5s	2206	[train]  epoch 54/100,  batch 71/188,  loss_train=0.83140,  acc_train=81.25%
7103.1s	2207	[train]  epoch 54/100,  batch 81/188,  loss_train=0.84795,  acc_train=71.88%
7108.7s	2208	[train]  epoch 54/100,  batch 91/188,  loss_train=0.53632,  acc_train=79.69%
7114.4s	2209	[train]  epoch 54/100,  batch 101/188,  loss_train=0.58335,  acc_train=81.25%
7120.2s	2210	[train]  epoch 54/100,  batch 111/188,  loss_train=0.74144,  acc_train=71.88%
7125.7s	2211	[train]  epoch 54/100,  batch 121/188,  loss_train=0.85629,  acc_train=78.12%
7131.3s	2212	[train]  epoch 54/100,  batch 131/188,  loss_train=0.71036,  acc_train=79.69%
7136.9s	2213	[train]  epoch 54/100,  batch 141/188,  loss_train=0.96155,  acc_train=70.31%
7142.5s	2214	[train]  epoch 54/100,  batch 151/188,  loss_train=0.79499,  acc_train=73.44%
7148.1s	2215	[train]  epoch 54/100,  batch 161/188,  loss_train=0.57731,  acc_train=81.25%
7153.9s	2216	[train]  epoch 54/100,  batch 171/188,  loss_train=0.60316,  acc_train=85.94%
7159.4s	2217	[train]  epoch 54/100,  batch 181/188,  loss_train=0.74648,  acc_train=76.56%
7164.0s	2218	[ val ]  epoch 54/100,  batch 1/135,  loss_val=4.17334,  acc_val=26.56%
7165.8s	2219	[ val ]  epoch 54/100,  batch 11/135,  loss_val=2.45407,  acc_val=45.31%
7167.6s	2220	[ val ]  epoch 54/100,  batch 21/135,  loss_val=2.11821,  acc_val=45.31%
7169.4s	2221	[ val ]  epoch 54/100,  batch 31/135,  loss_val=2.50207,  acc_val=45.31%
7171.2s	2222	[ val ]  epoch 54/100,  batch 41/135,  loss_val=1.89757,  acc_val=54.69%
7172.9s	2223	[ val ]  epoch 54/100,  batch 51/135,  loss_val=1.47865,  acc_val=60.94%
7174.7s	2224	[ val ]  epoch 54/100,  batch 61/135,  loss_val=3.15072,  acc_val=25.00%
7176.5s	2225	[ val ]  epoch 54/100,  batch 71/135,  loss_val=2.28404,  acc_val=53.12%
7178.3s	2226	[ val ]  epoch 54/100,  batch 81/135,  loss_val=2.70276,  acc_val=54.69%
7180.1s	2227	[ val ]  epoch 54/100,  batch 91/135,  loss_val=3.23218,  acc_val=25.00%
7181.9s	2228	[ val ]  epoch 54/100,  batch 101/135,  loss_val=1.37408,  acc_val=62.50%
7183.7s	2229	[ val ]  epoch 54/100,  batch 111/135,  loss_val=2.86313,  acc_val=39.06%
7185.8s	2230	[ val ]  epoch 54/100,  batch 121/135,  loss_val=4.00306,  acc_val=21.88%
7187.3s	2231	[ val ]  epoch 54/100,  batch 131/135,  loss_val=2.65975,  acc_val=42.19%
7187.9s	2232	===================================================================================================================
7187.9s	2233	Epoch 54/100 summary: loss_train=0.70054, acc_train=78.07%, loss_val=2.61, acc_val=41.88% (best: 46.23% @ epoch 53)
7187.9s	2234	===================================================================================================================
7187.9s	2235	Starting epoch 55/100, learning_rate=0.1
7189.1s	2236	[train]  epoch 55/100,  batch 1/188,  loss_train=0.57475,  acc_train=79.69%
7194.8s	2237	[train]  epoch 55/100,  batch 11/188,  loss_train=0.79882,  acc_train=75.00%
7200.4s	2238	[train]  epoch 55/100,  batch 21/188,  loss_train=0.44684,  acc_train=87.50%
7206.0s	2239	[train]  epoch 55/100,  batch 31/188,  loss_train=0.85608,  acc_train=71.88%
7211.7s	2240	[train]  epoch 55/100,  batch 41/188,  loss_train=0.65149,  acc_train=81.25%
7217.5s	2241	[train]  epoch 55/100,  batch 51/188,  loss_train=0.54048,  acc_train=85.94%
7223.0s	2242	[train]  epoch 55/100,  batch 61/188,  loss_train=0.45372,  acc_train=82.81%
7228.6s	2243	[train]  epoch 55/100,  batch 71/188,  loss_train=0.67860,  acc_train=81.25%
7234.2s	2244	[train]  epoch 55/100,  batch 81/188,  loss_train=0.54675,  acc_train=78.12%
7239.9s	2245	[train]  epoch 55/100,  batch 91/188,  loss_train=0.51341,  acc_train=87.50%
7245.6s	2246	[train]  epoch 55/100,  batch 101/188,  loss_train=0.75616,  acc_train=70.31%
7251.4s	2247	[train]  epoch 55/100,  batch 111/188,  loss_train=0.93033,  acc_train=68.75%
7256.8s	2248	[train]  epoch 55/100,  batch 121/188,  loss_train=0.78580,  acc_train=75.00%
7262.5s	2249	[train]  epoch 55/100,  batch 131/188,  loss_train=0.63971,  acc_train=82.81%
7268.1s	2250	[train]  epoch 55/100,  batch 141/188,  loss_train=0.67595,  acc_train=76.56%
7273.7s	2251	[train]  epoch 55/100,  batch 151/188,  loss_train=1.04783,  acc_train=64.06%
7279.3s	2252	[train]  epoch 55/100,  batch 161/188,  loss_train=0.80153,  acc_train=68.75%
7285.1s	2253	[train]  epoch 55/100,  batch 171/188,  loss_train=0.66496,  acc_train=78.12%
7290.6s	2254	[train]  epoch 55/100,  batch 181/188,  loss_train=0.88328,  acc_train=76.56%
7295.3s	2255	[ val ]  epoch 55/100,  batch 1/135,  loss_val=3.24081,  acc_val=26.56%
7297.0s	2256	[ val ]  epoch 55/100,  batch 11/135,  loss_val=1.93488,  acc_val=48.44%
7298.8s	2257	[ val ]  epoch 55/100,  batch 21/135,  loss_val=1.66812,  acc_val=57.81%
7300.6s	2258	[ val ]  epoch 55/100,  batch 31/135,  loss_val=1.91072,  acc_val=57.81%
7302.4s	2259	[ val ]  epoch 55/100,  batch 41/135,  loss_val=2.26579,  acc_val=43.75%
7304.1s	2260	[ val ]  epoch 55/100,  batch 51/135,  loss_val=3.15096,  acc_val=37.50%
7305.9s	2261	[ val ]  epoch 55/100,  batch 61/135,  loss_val=2.34143,  acc_val=46.88%
7307.7s	2262	[ val ]  epoch 55/100,  batch 71/135,  loss_val=2.79472,  acc_val=28.12%
7309.4s	2263	[ val ]  epoch 55/100,  batch 81/135,  loss_val=1.55486,  acc_val=64.06%
7311.2s	2264	[ val ]  epoch 55/100,  batch 91/135,  loss_val=2.91361,  acc_val=25.00%
7313.0s	2265	[ val ]  epoch 55/100,  batch 101/135,  loss_val=1.69967,  acc_val=51.56%
7314.8s	2266	[ val ]  epoch 55/100,  batch 111/135,  loss_val=2.37793,  acc_val=42.19%
7316.9s	2267	[ val ]  epoch 55/100,  batch 121/135,  loss_val=1.23888,  acc_val=60.94%
7318.4s	2268	[ val ]  epoch 55/100,  batch 131/135,  loss_val=3.56708,  acc_val=21.88%
7319.0s	2269	===================================================================================================================
7319.0s	2270	Epoch 55/100 summary: loss_train=0.69975, acc_train=78.05%, loss_val=2.36, acc_val=44.69% (best: 46.23% @ epoch 53)
7319.0s	2271	===================================================================================================================
7319.0s	2272	Starting epoch 56/100, learning_rate=0.1
7320.2s	2273	[train]  epoch 56/100,  batch 1/188,  loss_train=0.60213,  acc_train=75.00%
7325.8s	2274	[train]  epoch 56/100,  batch 11/188,  loss_train=0.66645,  acc_train=84.38%
7331.5s	2275	[train]  epoch 56/100,  batch 21/188,  loss_train=0.60348,  acc_train=82.81%
7337.1s	2276	[train]  epoch 56/100,  batch 31/188,  loss_train=0.51329,  acc_train=85.94%
7342.7s	2277	[train]  epoch 56/100,  batch 41/188,  loss_train=0.72087,  acc_train=79.69%
7348.6s	2278	[train]  epoch 56/100,  batch 51/188,  loss_train=0.62100,  acc_train=81.25%
7354.0s	2279	[train]  epoch 56/100,  batch 61/188,  loss_train=0.62331,  acc_train=81.25%
7359.6s	2280	[train]  epoch 56/100,  batch 71/188,  loss_train=0.72828,  acc_train=76.56%
7365.3s	2281	[train]  epoch 56/100,  batch 81/188,  loss_train=0.68128,  acc_train=79.69%
7370.9s	2282	[train]  epoch 56/100,  batch 91/188,  loss_train=0.51438,  acc_train=85.94%
7376.5s	2283	[train]  epoch 56/100,  batch 101/188,  loss_train=0.47496,  acc_train=84.38%
7382.4s	2284	[train]  epoch 56/100,  batch 111/188,  loss_train=1.15720,  acc_train=64.06%
7387.8s	2285	[train]  epoch 56/100,  batch 121/188,  loss_train=0.76283,  acc_train=76.56%
7393.4s	2286	[train]  epoch 56/100,  batch 131/188,  loss_train=0.68125,  acc_train=71.88%
7399.1s	2287	[train]  epoch 56/100,  batch 141/188,  loss_train=0.62357,  acc_train=81.25%
7404.7s	2288	[train]  epoch 56/100,  batch 151/188,  loss_train=0.87427,  acc_train=73.44%
7410.3s	2289	[train]  epoch 56/100,  batch 161/188,  loss_train=0.76380,  acc_train=73.44%
7416.1s	2290	[train]  epoch 56/100,  batch 171/188,  loss_train=1.04126,  acc_train=64.06%
7421.5s	2291	[train]  epoch 56/100,  batch 181/188,  loss_train=0.51904,  acc_train=85.94%
7426.2s	2292	[ val ]  epoch 56/100,  batch 1/135,  loss_val=3.67039,  acc_val=32.81%
7428.0s	2293	[ val ]  epoch 56/100,  batch 11/135,  loss_val=2.87199,  acc_val=40.62%
7429.8s	2294	[ val ]  epoch 56/100,  batch 21/135,  loss_val=2.11093,  acc_val=39.06%
7431.6s	2295	[ val ]  epoch 56/100,  batch 31/135,  loss_val=0.78909,  acc_val=78.12%
7433.4s	2296	[ val ]  epoch 56/100,  batch 41/135,  loss_val=1.15073,  acc_val=75.00%
7435.2s	2297	[ val ]  epoch 56/100,  batch 51/135,  loss_val=1.46217,  acc_val=62.50%
7436.9s	2298	[ val ]  epoch 56/100,  batch 61/135,  loss_val=3.36295,  acc_val=34.38%
7438.7s	2299	[ val ]  epoch 56/100,  batch 71/135,  loss_val=3.72399,  acc_val=21.88%
7440.5s	2300	[ val ]  epoch 56/100,  batch 81/135,  loss_val=3.02971,  acc_val=40.62%
7442.3s	2301	[ val ]  epoch 56/100,  batch 91/135,  loss_val=2.78485,  acc_val=28.12%
7444.2s	2302	[ val ]  epoch 56/100,  batch 101/135,  loss_val=0.92030,  acc_val=75.00%
7446.0s	2303	[ val ]  epoch 56/100,  batch 111/135,  loss_val=2.38449,  acc_val=42.19%
7448.0s	2304	[ val ]  epoch 56/100,  batch 121/135,  loss_val=1.26576,  acc_val=71.88%
7449.6s	2305	[ val ]  epoch 56/100,  batch 131/135,  loss_val=3.08367,  acc_val=31.25%
7450.2s	2306	===================================================================================================================
7450.2s	2307	Epoch 56/100 summary: loss_train=0.67122, acc_train=79.11%, loss_val=2.24, acc_val=46.24% (best: 46.24% @ epoch 56)
7450.2s	2308	===================================================================================================================
7450.2s	2309	Starting epoch 57/100, learning_rate=0.1
7451.5s	2310	[train]  epoch 57/100,  batch 1/188,  loss_train=0.38778,  acc_train=87.50%
7457.1s	2311	[train]  epoch 57/100,  batch 11/188,  loss_train=0.51321,  acc_train=82.81%
7462.7s	2312	[train]  epoch 57/100,  batch 21/188,  loss_train=0.43584,  acc_train=87.50%
7468.4s	2313	[train]  epoch 57/100,  batch 31/188,  loss_train=0.43844,  acc_train=85.94%
7474.0s	2314	[train]  epoch 57/100,  batch 41/188,  loss_train=0.62661,  acc_train=76.56%
7479.8s	2315	[train]  epoch 57/100,  batch 51/188,  loss_train=0.57052,  acc_train=76.56%
7485.3s	2316	[train]  epoch 57/100,  batch 61/188,  loss_train=0.57476,  acc_train=85.94%
7491.0s	2317	[train]  epoch 57/100,  batch 71/188,  loss_train=0.88880,  acc_train=76.56%
7496.7s	2318	[train]  epoch 57/100,  batch 81/188,  loss_train=0.51375,  acc_train=84.38%
7502.3s	2319	[train]  epoch 57/100,  batch 91/188,  loss_train=0.68076,  acc_train=78.12%
7508.0s	2320	[train]  epoch 57/100,  batch 101/188,  loss_train=0.50034,  acc_train=85.94%
7513.8s	2321	[train]  epoch 57/100,  batch 111/188,  loss_train=0.58262,  acc_train=81.25%
7519.2s	2322	[train]  epoch 57/100,  batch 121/188,  loss_train=0.48240,  acc_train=87.50%
7524.9s	2323	[train]  epoch 57/100,  batch 131/188,  loss_train=0.52289,  acc_train=81.25%
7530.5s	2324	[train]  epoch 57/100,  batch 141/188,  loss_train=0.58308,  acc_train=82.81%
7536.1s	2325	[train]  epoch 57/100,  batch 151/188,  loss_train=0.93160,  acc_train=70.31%
7541.8s	2326	[train]  epoch 57/100,  batch 161/188,  loss_train=0.72327,  acc_train=78.12%
7547.6s	2327	[train]  epoch 57/100,  batch 171/188,  loss_train=0.56093,  acc_train=84.38%
7553.1s	2328	[train]  epoch 57/100,  batch 181/188,  loss_train=0.72456,  acc_train=78.12%
7557.7s	2329	[ val ]  epoch 57/100,  batch 1/135,  loss_val=3.53425,  acc_val=29.69%
7559.4s	2330	[ val ]  epoch 57/100,  batch 11/135,  loss_val=1.33858,  acc_val=68.75%
7561.2s	2331	[ val ]  epoch 57/100,  batch 21/135,  loss_val=2.76287,  acc_val=37.50%
7563.0s	2332	[ val ]  epoch 57/100,  batch 31/135,  loss_val=1.32400,  acc_val=68.75%
7564.8s	2333	[ val ]  epoch 57/100,  batch 41/135,  loss_val=1.16598,  acc_val=70.31%
7566.6s	2334	[ val ]  epoch 57/100,  batch 51/135,  loss_val=1.57707,  acc_val=65.62%
7568.4s	2335	[ val ]  epoch 57/100,  batch 61/135,  loss_val=2.73214,  acc_val=46.88%
7570.2s	2336	[ val ]  epoch 57/100,  batch 71/135,  loss_val=4.64153,  acc_val=9.38%
7572.0s	2337	[ val ]  epoch 57/100,  batch 81/135,  loss_val=3.18275,  acc_val=43.75%
7573.8s	2338	[ val ]  epoch 57/100,  batch 91/135,  loss_val=3.89017,  acc_val=23.44%
7575.6s	2339	[ val ]  epoch 57/100,  batch 101/135,  loss_val=1.33643,  acc_val=64.06%
7577.4s	2340	[ val ]  epoch 57/100,  batch 111/135,  loss_val=4.15905,  acc_val=18.75%
7579.3s	2341	[ val ]  epoch 57/100,  batch 121/135,  loss_val=1.85024,  acc_val=51.56%
7580.9s	2342	[ val ]  epoch 57/100,  batch 131/135,  loss_val=2.99150,  acc_val=45.31%
7581.5s	2343	===================================================================================================================
7581.5s	2344	Epoch 57/100 summary: loss_train=0.64905, acc_train=79.70%, loss_val=2.63, acc_val=42.58% (best: 46.24% @ epoch 56)
7581.5s	2345	===================================================================================================================
7581.5s	2346	Starting epoch 58/100, learning_rate=0.1
7582.7s	2347	[train]  epoch 58/100,  batch 1/188,  loss_train=0.41887,  acc_train=85.94%
7588.4s	2348	[train]  epoch 58/100,  batch 11/188,  loss_train=0.46891,  acc_train=85.94%
7594.0s	2349	[train]  epoch 58/100,  batch 21/188,  loss_train=0.71765,  acc_train=78.12%
7599.6s	2350	[train]  epoch 58/100,  batch 31/188,  loss_train=0.43321,  acc_train=85.94%
7605.3s	2351	[train]  epoch 58/100,  batch 41/188,  loss_train=0.98385,  acc_train=68.75%
7611.1s	2352	[train]  epoch 58/100,  batch 51/188,  loss_train=0.48413,  acc_train=87.50%
7616.5s	2353	[train]  epoch 58/100,  batch 61/188,  loss_train=0.56599,  acc_train=78.12%
7622.1s	2354	[train]  epoch 58/100,  batch 71/188,  loss_train=0.71833,  acc_train=76.56%
7627.7s	2355	[train]  epoch 58/100,  batch 81/188,  loss_train=0.62146,  acc_train=79.69%
7633.3s	2356	[train]  epoch 58/100,  batch 91/188,  loss_train=0.47058,  acc_train=89.06%
7639.0s	2357	[train]  epoch 58/100,  batch 101/188,  loss_train=0.53759,  acc_train=81.25%
7644.7s	2358	[train]  epoch 58/100,  batch 111/188,  loss_train=0.43012,  acc_train=81.25%
7650.2s	2359	[train]  epoch 58/100,  batch 121/188,  loss_train=0.41897,  acc_train=89.06%
7655.8s	2360	[train]  epoch 58/100,  batch 131/188,  loss_train=0.65791,  acc_train=75.00%
7661.5s	2361	[train]  epoch 58/100,  batch 141/188,  loss_train=0.61349,  acc_train=82.81%
7667.1s	2362	[train]  epoch 58/100,  batch 151/188,  loss_train=0.65684,  acc_train=78.12%
7672.7s	2363	[train]  epoch 58/100,  batch 161/188,  loss_train=0.55747,  acc_train=85.94%
7678.6s	2364	[train]  epoch 58/100,  batch 171/188,  loss_train=0.49450,  acc_train=85.94%
7683.9s	2365	[train]  epoch 58/100,  batch 181/188,  loss_train=0.62464,  acc_train=76.56%
7688.6s	2366	[ val ]  epoch 58/100,  batch 1/135,  loss_val=3.13193,  acc_val=29.69%
7690.4s	2367	[ val ]  epoch 58/100,  batch 11/135,  loss_val=2.28481,  acc_val=46.88%
7692.2s	2368	[ val ]  epoch 58/100,  batch 21/135,  loss_val=1.02159,  acc_val=65.62%
7694.0s	2369	[ val ]  epoch 58/100,  batch 31/135,  loss_val=1.09587,  acc_val=76.56%
7695.8s	2370	[ val ]  epoch 58/100,  batch 41/135,  loss_val=1.84936,  acc_val=53.12%
7697.6s	2371	[ val ]  epoch 58/100,  batch 51/135,  loss_val=2.14378,  acc_val=50.00%
7699.4s	2372	[ val ]  epoch 58/100,  batch 61/135,  loss_val=4.34039,  acc_val=23.44%
7701.2s	2373	[ val ]  epoch 58/100,  batch 71/135,  loss_val=3.32053,  acc_val=21.88%
7703.0s	2374	[ val ]  epoch 58/100,  batch 81/135,  loss_val=3.66241,  acc_val=34.38%
7704.8s	2375	[ val ]  epoch 58/100,  batch 91/135,  loss_val=4.75735,  acc_val=17.19%
7706.6s	2376	[ val ]  epoch 58/100,  batch 101/135,  loss_val=1.87226,  acc_val=57.81%
7708.4s	2377	[ val ]  epoch 58/100,  batch 111/135,  loss_val=2.91781,  acc_val=31.25%
7710.4s	2378	[ val ]  epoch 58/100,  batch 121/135,  loss_val=2.21920,  acc_val=37.50%
7711.9s	2379	[ val ]  epoch 58/100,  batch 131/135,  loss_val=3.22064,  acc_val=29.69%
7712.5s	2380	===================================================================================================================
7712.5s	2381	Epoch 58/100 summary: loss_train=0.63905, acc_train=79.56%, loss_val=2.34, acc_val=44.26% (best: 46.24% @ epoch 56)
7712.5s	2382	===================================================================================================================
7712.5s	2383	Starting epoch 59/100, learning_rate=0.1
7713.7s	2384	[train]  epoch 59/100,  batch 1/188,  loss_train=0.56818,  acc_train=84.38%
7719.3s	2385	[train]  epoch 59/100,  batch 11/188,  loss_train=0.55259,  acc_train=85.94%
7725.0s	2386	[train]  epoch 59/100,  batch 21/188,  loss_train=0.49274,  acc_train=84.38%
7730.6s	2387	[train]  epoch 59/100,  batch 31/188,  loss_train=0.51893,  acc_train=87.50%
7736.2s	2388	[train]  epoch 59/100,  batch 41/188,  loss_train=0.45130,  acc_train=87.50%
7742.1s	2389	[train]  epoch 59/100,  batch 51/188,  loss_train=0.42644,  acc_train=89.06%
7747.5s	2390	[train]  epoch 59/100,  batch 61/188,  loss_train=0.49003,  acc_train=85.94%
7753.1s	2391	[train]  epoch 59/100,  batch 71/188,  loss_train=0.61130,  acc_train=79.69%
7758.7s	2392	[train]  epoch 59/100,  batch 81/188,  loss_train=0.52130,  acc_train=85.94%
7764.4s	2393	[train]  epoch 59/100,  batch 91/188,  loss_train=0.59999,  acc_train=82.81%
7770.0s	2394	[train]  epoch 59/100,  batch 101/188,  loss_train=0.44423,  acc_train=87.50%
7775.8s	2395	[train]  epoch 59/100,  batch 111/188,  loss_train=0.55780,  acc_train=84.38%
7781.2s	2396	[train]  epoch 59/100,  batch 121/188,  loss_train=0.45681,  acc_train=85.94%
7786.9s	2397	[train]  epoch 59/100,  batch 131/188,  loss_train=0.63956,  acc_train=79.69%
7792.5s	2398	[train]  epoch 59/100,  batch 141/188,  loss_train=0.96585,  acc_train=70.31%
7798.1s	2399	[train]  epoch 59/100,  batch 151/188,  loss_train=0.63402,  acc_train=79.69%
7803.7s	2400	[train]  epoch 59/100,  batch 161/188,  loss_train=0.83285,  acc_train=76.56%
7809.6s	2401	[train]  epoch 59/100,  batch 171/188,  loss_train=0.67005,  acc_train=75.00%
7815.0s	2402	[train]  epoch 59/100,  batch 181/188,  loss_train=0.72669,  acc_train=75.00%
7819.6s	2403	[ val ]  epoch 59/100,  batch 1/135,  loss_val=3.92043,  acc_val=31.25%
7821.4s	2404	[ val ]  epoch 59/100,  batch 11/135,  loss_val=0.67591,  acc_val=78.12%
7823.2s	2405	[ val ]  epoch 59/100,  batch 21/135,  loss_val=3.06123,  acc_val=34.38%
7825.0s	2406	[ val ]  epoch 59/100,  batch 31/135,  loss_val=1.83567,  acc_val=65.62%
7826.9s	2407	[ val ]  epoch 59/100,  batch 41/135,  loss_val=1.59056,  acc_val=65.62%
7828.6s	2408	[ val ]  epoch 59/100,  batch 51/135,  loss_val=2.25025,  acc_val=48.44%
7830.4s	2409	[ val ]  epoch 59/100,  batch 61/135,  loss_val=3.30648,  acc_val=39.06%
7832.2s	2410	[ val ]  epoch 59/100,  batch 71/135,  loss_val=2.42502,  acc_val=40.62%
7834.0s	2411	[ val ]  epoch 59/100,  batch 81/135,  loss_val=4.15323,  acc_val=34.38%
7835.8s	2412	[ val ]  epoch 59/100,  batch 91/135,  loss_val=2.81082,  acc_val=32.81%
7837.5s	2413	[ val ]  epoch 59/100,  batch 101/135,  loss_val=1.20880,  acc_val=64.06%
7839.3s	2414	[ val ]  epoch 59/100,  batch 111/135,  loss_val=2.03735,  acc_val=50.00%
7841.3s	2415	[ val ]  epoch 59/100,  batch 121/135,  loss_val=1.15948,  acc_val=75.00%
7842.8s	2416	[ val ]  epoch 59/100,  batch 131/135,  loss_val=2.65718,  acc_val=40.62%
7843.5s	2417	===================================================================================================================
7843.5s	2418	Epoch 59/100 summary: loss_train=0.60710, acc_train=81.24%, loss_val=2.51, acc_val=45.45% (best: 46.24% @ epoch 56)
7843.5s	2419	===================================================================================================================
7843.5s	2420	Starting epoch 60/100, learning_rate=0.1
7844.7s	2421	[train]  epoch 60/100,  batch 1/188,  loss_train=0.50428,  acc_train=85.94%
7850.3s	2422	[train]  epoch 60/100,  batch 11/188,  loss_train=0.49673,  acc_train=82.81%
7856.0s	2423	[train]  epoch 60/100,  batch 21/188,  loss_train=0.53032,  acc_train=84.38%
7861.6s	2424	[train]  epoch 60/100,  batch 31/188,  loss_train=0.50784,  acc_train=82.81%
7867.2s	2425	[train]  epoch 60/100,  batch 41/188,  loss_train=0.55135,  acc_train=81.25%
7873.1s	2426	[train]  epoch 60/100,  batch 51/188,  loss_train=0.47083,  acc_train=85.94%
7878.5s	2427	[train]  epoch 60/100,  batch 61/188,  loss_train=0.48376,  acc_train=82.81%
7884.1s	2428	[train]  epoch 60/100,  batch 71/188,  loss_train=0.78135,  acc_train=79.69%
7889.8s	2429	[train]  epoch 60/100,  batch 81/188,  loss_train=0.70494,  acc_train=76.56%
7895.4s	2430	[train]  epoch 60/100,  batch 91/188,  loss_train=0.67427,  acc_train=79.69%
7901.0s	2431	[train]  epoch 60/100,  batch 101/188,  loss_train=0.60898,  acc_train=78.12%
7906.9s	2432	[train]  epoch 60/100,  batch 111/188,  loss_train=0.61361,  acc_train=76.56%
7912.3s	2433	[train]  epoch 60/100,  batch 121/188,  loss_train=0.83292,  acc_train=73.44%
7917.9s	2434	[train]  epoch 60/100,  batch 131/188,  loss_train=0.52024,  acc_train=85.94%
7923.6s	2435	[train]  epoch 60/100,  batch 141/188,  loss_train=0.87121,  acc_train=76.56%
7929.2s	2436	[train]  epoch 60/100,  batch 151/188,  loss_train=0.83884,  acc_train=79.69%
7934.9s	2437	[train]  epoch 60/100,  batch 161/188,  loss_train=0.67281,  acc_train=71.88%
7940.7s	2438	[train]  epoch 60/100,  batch 171/188,  loss_train=0.56210,  acc_train=84.38%
7946.1s	2439	[train]  epoch 60/100,  batch 181/188,  loss_train=0.63729,  acc_train=81.25%
7950.7s	2440	[ val ]  epoch 60/100,  batch 1/135,  loss_val=4.53468,  acc_val=26.56%
7952.5s	2441	[ val ]  epoch 60/100,  batch 11/135,  loss_val=2.79763,  acc_val=46.88%
7954.4s	2442	[ val ]  epoch 60/100,  batch 21/135,  loss_val=2.68177,  acc_val=43.75%
7956.2s	2443	[ val ]  epoch 60/100,  batch 31/135,  loss_val=1.62863,  acc_val=64.06%
7958.0s	2444	[ val ]  epoch 60/100,  batch 41/135,  loss_val=1.68908,  acc_val=59.38%
7959.8s	2445	[ val ]  epoch 60/100,  batch 51/135,  loss_val=3.41043,  acc_val=35.94%
7961.6s	2446	[ val ]  epoch 60/100,  batch 61/135,  loss_val=2.85276,  acc_val=48.44%
7963.4s	2447	[ val ]  epoch 60/100,  batch 71/135,  loss_val=1.71048,  acc_val=59.38%
7965.2s	2448	[ val ]  epoch 60/100,  batch 81/135,  loss_val=3.54351,  acc_val=42.19%
7967.0s	2449	[ val ]  epoch 60/100,  batch 91/135,  loss_val=3.88482,  acc_val=21.88%
7968.8s	2450	[ val ]  epoch 60/100,  batch 101/135,  loss_val=0.87327,  acc_val=68.75%
7970.5s	2451	[ val ]  epoch 60/100,  batch 111/135,  loss_val=2.99062,  acc_val=34.38%
7972.6s	2452	[ val ]  epoch 60/100,  batch 121/135,  loss_val=2.37123,  acc_val=45.31%
7974.1s	2453	[ val ]  epoch 60/100,  batch 131/135,  loss_val=3.16790,  acc_val=29.69%
7974.7s	2454	===================================================================================================================
7974.7s	2455	Epoch 60/100 summary: loss_train=0.61523, acc_train=80.52%, loss_val=2.51, acc_val=43.37% (best: 46.24% @ epoch 56)
7974.7s	2456	===================================================================================================================
7974.7s	2457	Starting epoch 61/100, learning_rate=0.1
7976.0s	2458	[train]  epoch 61/100,  batch 1/188,  loss_train=0.36706,  acc_train=85.94%
7981.7s	2459	[train]  epoch 61/100,  batch 11/188,  loss_train=0.45253,  acc_train=85.94%
7987.3s	2460	[train]  epoch 61/100,  batch 21/188,  loss_train=0.50812,  acc_train=79.69%
7992.9s	2461	[train]  epoch 61/100,  batch 31/188,  loss_train=0.54346,  acc_train=81.25%
7998.6s	2462	[train]  epoch 61/100,  batch 41/188,  loss_train=0.45918,  acc_train=85.94%
8004.3s	2463	[train]  epoch 61/100,  batch 51/188,  loss_train=0.53426,  acc_train=81.25%
8009.8s	2464	[train]  epoch 61/100,  batch 61/188,  loss_train=0.49490,  acc_train=84.38%
8015.5s	2465	[train]  epoch 61/100,  batch 71/188,  loss_train=0.60267,  acc_train=87.50%
8021.1s	2466	[train]  epoch 61/100,  batch 81/188,  loss_train=0.78317,  acc_train=78.12%
8026.7s	2467	[train]  epoch 61/100,  batch 91/188,  loss_train=0.55450,  acc_train=81.25%
8032.3s	2468	[train]  epoch 61/100,  batch 101/188,  loss_train=0.55611,  acc_train=78.12%
8038.1s	2469	[train]  epoch 61/100,  batch 111/188,  loss_train=0.47903,  acc_train=84.38%
8043.6s	2470	[train]  epoch 61/100,  batch 121/188,  loss_train=0.56759,  acc_train=79.69%
8049.2s	2471	[train]  epoch 61/100,  batch 131/188,  loss_train=0.65777,  acc_train=76.56%
8054.8s	2472	[train]  epoch 61/100,  batch 141/188,  loss_train=0.87562,  acc_train=68.75%
8060.4s	2473	[train]  epoch 61/100,  batch 151/188,  loss_train=0.53629,  acc_train=82.81%
8066.1s	2474	[train]  epoch 61/100,  batch 161/188,  loss_train=0.65642,  acc_train=71.88%
8071.9s	2475	[train]  epoch 61/100,  batch 171/188,  loss_train=0.51350,  acc_train=84.38%
8077.3s	2476	[train]  epoch 61/100,  batch 181/188,  loss_train=0.85290,  acc_train=76.56%
8081.9s	2477	[ val ]  epoch 61/100,  batch 1/135,  loss_val=3.40766,  acc_val=29.69%
8083.7s	2478	[ val ]  epoch 61/100,  batch 11/135,  loss_val=1.44351,  acc_val=56.25%
8085.5s	2479	[ val ]  epoch 61/100,  batch 21/135,  loss_val=1.97453,  acc_val=54.69%
8087.3s	2480	[ val ]  epoch 61/100,  batch 31/135,  loss_val=2.72558,  acc_val=37.50%
8089.1s	2481	[ val ]  epoch 61/100,  batch 41/135,  loss_val=1.91174,  acc_val=56.25%
8090.9s	2482	[ val ]  epoch 61/100,  batch 51/135,  loss_val=1.75482,  acc_val=57.81%
8092.7s	2483	[ val ]  epoch 61/100,  batch 61/135,  loss_val=4.09455,  acc_val=23.44%
8094.5s	2484	[ val ]  epoch 61/100,  batch 71/135,  loss_val=2.41505,  acc_val=37.50%
8096.2s	2485	[ val ]  epoch 61/100,  batch 81/135,  loss_val=2.68315,  acc_val=53.12%
8098.0s	2486	[ val ]  epoch 61/100,  batch 91/135,  loss_val=2.41667,  acc_val=32.81%
8099.8s	2487	[ val ]  epoch 61/100,  batch 101/135,  loss_val=1.30562,  acc_val=53.12%
8101.6s	2488	[ val ]  epoch 61/100,  batch 111/135,  loss_val=2.20798,  acc_val=45.31%
8103.7s	2489	[ val ]  epoch 61/100,  batch 121/135,  loss_val=0.68305,  acc_val=79.69%
8105.2s	2490	[ val ]  epoch 61/100,  batch 131/135,  loss_val=2.61763,  acc_val=39.06%
8105.8s	2491	===================================================================================================================
8105.8s	2492	Epoch 61/100 summary: loss_train=0.55542, acc_train=82.41%, loss_val=2.45, acc_val=43.94% (best: 46.24% @ epoch 56)
8105.8s	2493	===================================================================================================================
8105.8s	2494	Starting epoch 62/100, learning_rate=0.1
8107.1s	2495	[train]  epoch 62/100,  batch 1/188,  loss_train=0.59326,  acc_train=78.12%
8112.7s	2496	[train]  epoch 62/100,  batch 11/188,  loss_train=0.51999,  acc_train=82.81%
8118.3s	2497	[train]  epoch 62/100,  batch 21/188,  loss_train=0.61360,  acc_train=81.25%
8124.0s	2498	[train]  epoch 62/100,  batch 31/188,  loss_train=0.47299,  acc_train=85.94%
8129.6s	2499	[train]  epoch 62/100,  batch 41/188,  loss_train=0.51067,  acc_train=89.06%
8135.4s	2500	[train]  epoch 62/100,  batch 51/188,  loss_train=0.59523,  acc_train=81.25%
8140.8s	2501	[train]  epoch 62/100,  batch 61/188,  loss_train=0.48263,  acc_train=85.94%
8146.5s	2502	[train]  epoch 62/100,  batch 71/188,  loss_train=0.67440,  acc_train=78.12%
8152.1s	2503	[train]  epoch 62/100,  batch 81/188,  loss_train=0.44460,  acc_train=87.50%
8157.7s	2504	[train]  epoch 62/100,  batch 91/188,  loss_train=0.49922,  acc_train=84.38%
8163.3s	2505	[train]  epoch 62/100,  batch 101/188,  loss_train=0.42497,  acc_train=84.38%
8169.2s	2506	[train]  epoch 62/100,  batch 111/188,  loss_train=0.51609,  acc_train=89.06%
8174.6s	2507	[train]  epoch 62/100,  batch 121/188,  loss_train=0.61607,  acc_train=78.12%
8180.2s	2508	[train]  epoch 62/100,  batch 131/188,  loss_train=0.69269,  acc_train=76.56%
8185.9s	2509	[train]  epoch 62/100,  batch 141/188,  loss_train=0.53375,  acc_train=87.50%
8191.5s	2510	[train]  epoch 62/100,  batch 151/188,  loss_train=1.01945,  acc_train=71.88%
8197.1s	2511	[train]  epoch 62/100,  batch 161/188,  loss_train=0.74131,  acc_train=81.25%
8203.0s	2512	[train]  epoch 62/100,  batch 171/188,  loss_train=0.68354,  acc_train=79.69%
8208.4s	2513	[train]  epoch 62/100,  batch 181/188,  loss_train=0.66669,  acc_train=78.12%
8213.0s	2514	[ val ]  epoch 62/100,  batch 1/135,  loss_val=2.64737,  acc_val=43.75%
8214.8s	2515	[ val ]  epoch 62/100,  batch 11/135,  loss_val=3.65806,  acc_val=29.69%
8216.6s	2516	[ val ]  epoch 62/100,  batch 21/135,  loss_val=2.98142,  acc_val=37.50%
8218.4s	2517	[ val ]  epoch 62/100,  batch 31/135,  loss_val=1.53958,  acc_val=64.06%
8220.2s	2518	[ val ]  epoch 62/100,  batch 41/135,  loss_val=2.02922,  acc_val=53.12%
8222.0s	2519	[ val ]  epoch 62/100,  batch 51/135,  loss_val=2.59006,  acc_val=45.31%
8223.8s	2520	[ val ]  epoch 62/100,  batch 61/135,  loss_val=2.43507,  acc_val=46.88%
8225.6s	2521	[ val ]  epoch 62/100,  batch 71/135,  loss_val=2.84138,  acc_val=29.69%
8227.3s	2522	[ val ]  epoch 62/100,  batch 81/135,  loss_val=3.50520,  acc_val=43.75%
8229.1s	2523	[ val ]  epoch 62/100,  batch 91/135,  loss_val=4.46100,  acc_val=14.06%
8230.9s	2524	[ val ]  epoch 62/100,  batch 101/135,  loss_val=1.63017,  acc_val=53.12%
8232.7s	2525	[ val ]  epoch 62/100,  batch 111/135,  loss_val=3.16283,  acc_val=21.88%
8234.7s	2526	[ val ]  epoch 62/100,  batch 121/135,  loss_val=1.25816,  acc_val=59.38%
8236.3s	2527	[ val ]  epoch 62/100,  batch 131/135,  loss_val=2.65465,  acc_val=40.62%
8236.9s	2528	===================================================================================================================
8236.9s	2529	Epoch 62/100 summary: loss_train=0.57377, acc_train=81.84%, loss_val=2.50, acc_val=44.13% (best: 46.24% @ epoch 56)
8236.9s	2530	===================================================================================================================
8236.9s	2531	Starting epoch 63/100, learning_rate=0.1
8238.1s	2532	[train]  epoch 63/100,  batch 1/188,  loss_train=0.47218,  acc_train=85.94%
8243.7s	2533	[train]  epoch 63/100,  batch 11/188,  loss_train=0.49595,  acc_train=84.38%
8249.4s	2534	[train]  epoch 63/100,  batch 21/188,  loss_train=0.62072,  acc_train=87.50%
8255.0s	2535	[train]  epoch 63/100,  batch 31/188,  loss_train=0.60614,  acc_train=75.00%
8260.6s	2536	[train]  epoch 63/100,  batch 41/188,  loss_train=0.53862,  acc_train=82.81%
8266.4s	2537	[train]  epoch 63/100,  batch 51/188,  loss_train=0.61335,  acc_train=82.81%
8271.9s	2538	[train]  epoch 63/100,  batch 61/188,  loss_train=0.57929,  acc_train=82.81%
8277.5s	2539	[train]  epoch 63/100,  batch 71/188,  loss_train=0.39707,  acc_train=89.06%
8283.1s	2540	[train]  epoch 63/100,  batch 81/188,  loss_train=0.76360,  acc_train=79.69%
8288.7s	2541	[train]  epoch 63/100,  batch 91/188,  loss_train=0.36371,  acc_train=92.19%
8294.3s	2542	[train]  epoch 63/100,  batch 101/188,  loss_train=0.51885,  acc_train=78.12%
8300.2s	2543	[train]  epoch 63/100,  batch 111/188,  loss_train=0.55476,  acc_train=79.69%
8305.6s	2544	[train]  epoch 63/100,  batch 121/188,  loss_train=0.65359,  acc_train=82.81%
8311.3s	2545	[train]  epoch 63/100,  batch 131/188,  loss_train=0.48907,  acc_train=84.38%
8316.9s	2546	[train]  epoch 63/100,  batch 141/188,  loss_train=0.69201,  acc_train=78.12%
8322.5s	2547	[train]  epoch 63/100,  batch 151/188,  loss_train=0.71429,  acc_train=79.69%
8328.2s	2548	[train]  epoch 63/100,  batch 161/188,  loss_train=0.67403,  acc_train=73.44%
8334.0s	2549	[train]  epoch 63/100,  batch 171/188,  loss_train=0.82368,  acc_train=75.00%
8339.4s	2550	[train]  epoch 63/100,  batch 181/188,  loss_train=0.67429,  acc_train=81.25%
8344.0s	2551	[ val ]  epoch 63/100,  batch 1/135,  loss_val=3.66350,  acc_val=28.12%
8345.8s	2552	[ val ]  epoch 63/100,  batch 11/135,  loss_val=2.18841,  acc_val=54.69%
8347.6s	2553	[ val ]  epoch 63/100,  batch 21/135,  loss_val=2.01581,  acc_val=43.75%
8349.4s	2554	[ val ]  epoch 63/100,  batch 31/135,  loss_val=2.32476,  acc_val=54.69%
8351.2s	2555	[ val ]  epoch 63/100,  batch 41/135,  loss_val=3.04517,  acc_val=34.38%
8353.0s	2556	[ val ]  epoch 63/100,  batch 51/135,  loss_val=1.05009,  acc_val=76.56%
8354.8s	2557	[ val ]  epoch 63/100,  batch 61/135,  loss_val=3.51793,  acc_val=26.56%
8356.6s	2558	[ val ]  epoch 63/100,  batch 71/135,  loss_val=2.14722,  acc_val=42.19%
8358.4s	2559	[ val ]  epoch 63/100,  batch 81/135,  loss_val=2.76921,  acc_val=45.31%
8360.2s	2560	[ val ]  epoch 63/100,  batch 91/135,  loss_val=4.81117,  acc_val=17.19%
8362.0s	2561	[ val ]  epoch 63/100,  batch 101/135,  loss_val=1.57824,  acc_val=54.69%
8363.8s	2562	[ val ]  epoch 63/100,  batch 111/135,  loss_val=3.42633,  acc_val=35.94%
8365.8s	2563	[ val ]  epoch 63/100,  batch 121/135,  loss_val=1.32155,  acc_val=64.06%
8367.3s	2564	[ val ]  epoch 63/100,  batch 131/135,  loss_val=3.31722,  acc_val=23.44%
8367.9s	2565	===================================================================================================================
8367.9s	2566	Epoch 63/100 summary: loss_train=0.57470, acc_train=82.07%, loss_val=2.66, acc_val=41.24% (best: 46.24% @ epoch 56)
8367.9s	2567	===================================================================================================================
8367.9s	2568	Starting epoch 64/100, learning_rate=0.1
8369.2s	2569	[train]  epoch 64/100,  batch 1/188,  loss_train=0.40799,  acc_train=84.38%
8374.8s	2570	[train]  epoch 64/100,  batch 11/188,  loss_train=0.55968,  acc_train=84.38%
8380.4s	2571	[train]  epoch 64/100,  batch 21/188,  loss_train=0.44560,  acc_train=85.94%
8386.0s	2572	[train]  epoch 64/100,  batch 31/188,  loss_train=0.57524,  acc_train=82.81%
8391.7s	2573	[train]  epoch 64/100,  batch 41/188,  loss_train=0.40740,  acc_train=89.06%
8397.5s	2574	[train]  epoch 64/100,  batch 51/188,  loss_train=0.46677,  acc_train=89.06%
8402.9s	2575	[train]  epoch 64/100,  batch 61/188,  loss_train=0.66283,  acc_train=78.12%
8408.6s	2576	[train]  epoch 64/100,  batch 71/188,  loss_train=0.41762,  acc_train=90.62%
8414.2s	2577	[train]  epoch 64/100,  batch 81/188,  loss_train=0.48361,  acc_train=87.50%
8419.8s	2578	[train]  epoch 64/100,  batch 91/188,  loss_train=0.43558,  acc_train=85.94%
8425.4s	2579	[train]  epoch 64/100,  batch 101/188,  loss_train=0.45728,  acc_train=82.81%
8431.3s	2580	[train]  epoch 64/100,  batch 111/188,  loss_train=0.71701,  acc_train=79.69%
8436.8s	2581	[train]  epoch 64/100,  batch 121/188,  loss_train=0.65859,  acc_train=81.25%
8442.4s	2582	[train]  epoch 64/100,  batch 131/188,  loss_train=0.81598,  acc_train=68.75%
8448.0s	2583	[train]  epoch 64/100,  batch 141/188,  loss_train=0.63292,  acc_train=75.00%
8453.7s	2584	[train]  epoch 64/100,  batch 151/188,  loss_train=0.61963,  acc_train=76.56%
8459.3s	2585	[train]  epoch 64/100,  batch 161/188,  loss_train=0.59575,  acc_train=78.12%
8465.1s	2586	[train]  epoch 64/100,  batch 171/188,  loss_train=0.36465,  acc_train=89.06%
8470.6s	2587	[train]  epoch 64/100,  batch 181/188,  loss_train=0.63951,  acc_train=81.25%
8475.2s	2588	[ val ]  epoch 64/100,  batch 1/135,  loss_val=2.67577,  acc_val=40.62%
8476.9s	2589	[ val ]  epoch 64/100,  batch 11/135,  loss_val=3.59716,  acc_val=25.00%
8478.7s	2590	[ val ]  epoch 64/100,  batch 21/135,  loss_val=2.42399,  acc_val=42.19%
8480.5s	2591	[ val ]  epoch 64/100,  batch 31/135,  loss_val=2.50006,  acc_val=45.31%
8482.3s	2592	[ val ]  epoch 64/100,  batch 41/135,  loss_val=2.04084,  acc_val=56.25%
8484.0s	2593	[ val ]  epoch 64/100,  batch 51/135,  loss_val=2.25846,  acc_val=50.00%
8485.8s	2594	[ val ]  epoch 64/100,  batch 61/135,  loss_val=2.36190,  acc_val=51.56%
8487.6s	2595	[ val ]  epoch 64/100,  batch 71/135,  loss_val=2.84762,  acc_val=31.25%
8489.3s	2596	[ val ]  epoch 64/100,  batch 81/135,  loss_val=2.51032,  acc_val=53.12%
8491.1s	2597	[ val ]  epoch 64/100,  batch 91/135,  loss_val=3.15907,  acc_val=25.00%
8492.9s	2598	[ val ]  epoch 64/100,  batch 101/135,  loss_val=1.16683,  acc_val=64.06%
8494.8s	2599	[ val ]  epoch 64/100,  batch 111/135,  loss_val=2.45917,  acc_val=43.75%
8496.7s	2600	[ val ]  epoch 64/100,  batch 121/135,  loss_val=2.10673,  acc_val=45.31%
8498.3s	2601	[ val ]  epoch 64/100,  batch 131/135,  loss_val=3.93556,  acc_val=26.56%
8498.9s	2602	===================================================================================================================
8498.9s	2603	Epoch 64/100 summary: loss_train=0.53054, acc_train=83.38%, loss_val=2.56, acc_val=43.39% (best: 46.24% @ epoch 56)
8498.9s	2604	===================================================================================================================
8498.9s	2605	Starting epoch 65/100, learning_rate=0.1
8500.2s	2606	[train]  epoch 65/100,  batch 1/188,  loss_train=0.47095,  acc_train=87.50%
8505.8s	2607	[train]  epoch 65/100,  batch 11/188,  loss_train=0.62425,  acc_train=82.81%
8511.4s	2608	[train]  epoch 65/100,  batch 21/188,  loss_train=0.77745,  acc_train=75.00%
8517.0s	2609	[train]  epoch 65/100,  batch 31/188,  loss_train=0.38188,  acc_train=90.62%
8522.6s	2610	[train]  epoch 65/100,  batch 41/188,  loss_train=0.52522,  acc_train=84.38%
8528.5s	2611	[train]  epoch 65/100,  batch 51/188,  loss_train=0.56839,  acc_train=89.06%
8533.9s	2612	[train]  epoch 65/100,  batch 61/188,  loss_train=0.42112,  acc_train=89.06%
8539.5s	2613	[train]  epoch 65/100,  batch 71/188,  loss_train=0.35001,  acc_train=92.19%
8545.1s	2614	[train]  epoch 65/100,  batch 81/188,  loss_train=0.62314,  acc_train=75.00%
8550.8s	2615	[train]  epoch 65/100,  batch 91/188,  loss_train=0.79154,  acc_train=73.44%
8556.4s	2616	[train]  epoch 65/100,  batch 101/188,  loss_train=0.51657,  acc_train=89.06%
8562.2s	2617	[train]  epoch 65/100,  batch 111/188,  loss_train=0.59382,  acc_train=81.25%
8567.7s	2618	[train]  epoch 65/100,  batch 121/188,  loss_train=0.58597,  acc_train=81.25%
8573.3s	2619	[train]  epoch 65/100,  batch 131/188,  loss_train=0.61571,  acc_train=79.69%
8578.9s	2620	[train]  epoch 65/100,  batch 141/188,  loss_train=0.55647,  acc_train=81.25%
8584.5s	2621	[train]  epoch 65/100,  batch 151/188,  loss_train=0.57936,  acc_train=84.38%
8590.2s	2622	[train]  epoch 65/100,  batch 161/188,  loss_train=0.51519,  acc_train=85.94%
8596.1s	2623	[train]  epoch 65/100,  batch 171/188,  loss_train=0.53996,  acc_train=81.25%
8601.4s	2624	[train]  epoch 65/100,  batch 181/188,  loss_train=0.69337,  acc_train=81.25%
8606.1s	2625	[ val ]  epoch 65/100,  batch 1/135,  loss_val=3.49951,  acc_val=26.56%
8607.9s	2626	[ val ]  epoch 65/100,  batch 11/135,  loss_val=2.77443,  acc_val=37.50%
8609.7s	2627	[ val ]  epoch 65/100,  batch 21/135,  loss_val=2.79183,  acc_val=40.62%
8611.5s	2628	[ val ]  epoch 65/100,  batch 31/135,  loss_val=2.19977,  acc_val=46.88%
8613.3s	2629	[ val ]  epoch 65/100,  batch 41/135,  loss_val=2.81867,  acc_val=45.31%
8615.1s	2630	[ val ]  epoch 65/100,  batch 51/135,  loss_val=1.94548,  acc_val=62.50%
8616.9s	2631	[ val ]  epoch 65/100,  batch 61/135,  loss_val=2.16589,  acc_val=68.75%
8618.6s	2632	[ val ]  epoch 65/100,  batch 71/135,  loss_val=2.72877,  acc_val=29.69%
8620.4s	2633	[ val ]  epoch 65/100,  batch 81/135,  loss_val=2.85442,  acc_val=50.00%
8622.5s	2634	[ val ]  epoch 65/100,  batch 91/135,  loss_val=3.97002,  acc_val=25.00%
8624.2s	2635	[ val ]  epoch 65/100,  batch 101/135,  loss_val=2.73950,  acc_val=32.81%
8626.0s	2636	[ val ]  epoch 65/100,  batch 111/135,  loss_val=4.68132,  acc_val=17.19%
8628.1s	2637	[ val ]  epoch 65/100,  batch 121/135,  loss_val=1.88796,  acc_val=51.56%
8629.6s	2638	[ val ]  epoch 65/100,  batch 131/135,  loss_val=4.05219,  acc_val=28.12%
8630.2s	2639	===================================================================================================================
8630.2s	2640	Epoch 65/100 summary: loss_train=0.53862, acc_train=83.19%, loss_val=2.81, acc_val=42.03% (best: 46.24% @ epoch 56)
8630.2s	2641	===================================================================================================================
8630.2s	2642	Starting epoch 66/100, learning_rate=0.1
8631.5s	2643	[train]  epoch 66/100,  batch 1/188,  loss_train=0.45801,  acc_train=78.12%
8637.1s	2644	[train]  epoch 66/100,  batch 11/188,  loss_train=0.50739,  acc_train=84.38%
8642.7s	2645	[train]  epoch 66/100,  batch 21/188,  loss_train=0.49073,  acc_train=84.38%
8648.4s	2646	[train]  epoch 66/100,  batch 31/188,  loss_train=0.62427,  acc_train=78.12%
8654.0s	2647	[train]  epoch 66/100,  batch 41/188,  loss_train=0.53638,  acc_train=81.25%
8659.9s	2648	[train]  epoch 66/100,  batch 51/188,  loss_train=0.37544,  acc_train=89.06%
8665.3s	2649	[train]  epoch 66/100,  batch 61/188,  loss_train=0.39245,  acc_train=87.50%
8670.9s	2650	[train]  epoch 66/100,  batch 71/188,  loss_train=0.61010,  acc_train=76.56%
8676.5s	2651	[train]  epoch 66/100,  batch 81/188,  loss_train=0.54586,  acc_train=82.81%
8682.2s	2652	[train]  epoch 66/100,  batch 91/188,  loss_train=0.66005,  acc_train=82.81%
8687.8s	2653	[train]  epoch 66/100,  batch 101/188,  loss_train=0.64495,  acc_train=75.00%
8693.7s	2654	[train]  epoch 66/100,  batch 111/188,  loss_train=0.37923,  acc_train=90.62%
8699.1s	2655	[train]  epoch 66/100,  batch 121/188,  loss_train=0.37234,  acc_train=89.06%
8704.7s	2656	[train]  epoch 66/100,  batch 131/188,  loss_train=0.47917,  acc_train=81.25%
8710.4s	2657	[train]  epoch 66/100,  batch 141/188,  loss_train=0.43004,  acc_train=87.50%
8716.0s	2658	[train]  epoch 66/100,  batch 151/188,  loss_train=0.70635,  acc_train=76.56%
8721.7s	2659	[train]  epoch 66/100,  batch 161/188,  loss_train=0.62070,  acc_train=81.25%
8727.5s	2660	[train]  epoch 66/100,  batch 171/188,  loss_train=0.73122,  acc_train=78.12%
8733.0s	2661	[train]  epoch 66/100,  batch 181/188,  loss_train=0.51055,  acc_train=89.06%
8737.6s	2662	[ val ]  epoch 66/100,  batch 1/135,  loss_val=5.10063,  acc_val=21.88%
8739.4s	2663	[ val ]  epoch 66/100,  batch 11/135,  loss_val=1.90598,  acc_val=57.81%
8741.2s	2664	[ val ]  epoch 66/100,  batch 21/135,  loss_val=1.85167,  acc_val=56.25%
8743.0s	2665	[ val ]  epoch 66/100,  batch 31/135,  loss_val=2.54167,  acc_val=43.75%
8744.8s	2666	[ val ]  epoch 66/100,  batch 41/135,  loss_val=1.87735,  acc_val=51.56%
8746.6s	2667	[ val ]  epoch 66/100,  batch 51/135,  loss_val=2.03364,  acc_val=50.00%
8748.4s	2668	[ val ]  epoch 66/100,  batch 61/135,  loss_val=2.96247,  acc_val=40.62%
8750.3s	2669	[ val ]  epoch 66/100,  batch 71/135,  loss_val=3.22859,  acc_val=31.25%
8752.1s	2670	[ val ]  epoch 66/100,  batch 81/135,  loss_val=3.62287,  acc_val=46.88%
8753.9s	2671	[ val ]  epoch 66/100,  batch 91/135,  loss_val=2.75659,  acc_val=37.50%
8755.7s	2672	[ val ]  epoch 66/100,  batch 101/135,  loss_val=2.33766,  acc_val=39.06%
8757.5s	2673	[ val ]  epoch 66/100,  batch 111/135,  loss_val=2.63480,  acc_val=35.94%
8759.6s	2674	[ val ]  epoch 66/100,  batch 121/135,  loss_val=1.29857,  acc_val=64.06%
8761.0s	2675	[ val ]  epoch 66/100,  batch 131/135,  loss_val=2.78911,  acc_val=40.62%
8761.7s	2676	===================================================================================================================
8761.7s	2677	Epoch 66/100 summary: loss_train=0.54198, acc_train=82.90%, loss_val=2.36, acc_val=46.54% (best: 46.54% @ epoch 66)
8761.7s	2678	===================================================================================================================
8761.7s	2679	Starting epoch 67/100, learning_rate=0.1
8762.9s	2680	[train]  epoch 67/100,  batch 1/188,  loss_train=0.26388,  acc_train=92.19%
8768.5s	2681	[train]  epoch 67/100,  batch 11/188,  loss_train=0.52519,  acc_train=84.38%
8774.2s	2682	[train]  epoch 67/100,  batch 21/188,  loss_train=0.66714,  acc_train=78.12%
8779.9s	2683	[train]  epoch 67/100,  batch 31/188,  loss_train=0.52086,  acc_train=85.94%
8785.5s	2684	[train]  epoch 67/100,  batch 41/188,  loss_train=0.63297,  acc_train=79.69%
8791.3s	2685	[train]  epoch 67/100,  batch 51/188,  loss_train=0.44176,  acc_train=85.94%
8796.8s	2686	[train]  epoch 67/100,  batch 61/188,  loss_train=0.46366,  acc_train=81.25%
8802.4s	2687	[train]  epoch 67/100,  batch 71/188,  loss_train=0.43885,  acc_train=84.38%
8808.0s	2688	[train]  epoch 67/100,  batch 81/188,  loss_train=0.44614,  acc_train=89.06%
8813.6s	2689	[train]  epoch 67/100,  batch 91/188,  loss_train=0.39281,  acc_train=87.50%
8819.3s	2690	[train]  epoch 67/100,  batch 101/188,  loss_train=0.46676,  acc_train=87.50%
8825.0s	2691	[train]  epoch 67/100,  batch 111/188,  loss_train=0.53031,  acc_train=81.25%
8830.5s	2692	[train]  epoch 67/100,  batch 121/188,  loss_train=0.77707,  acc_train=81.25%
8836.1s	2693	[train]  epoch 67/100,  batch 131/188,  loss_train=0.92596,  acc_train=73.44%
8841.8s	2694	[train]  epoch 67/100,  batch 141/188,  loss_train=0.37452,  acc_train=87.50%
8847.4s	2695	[train]  epoch 67/100,  batch 151/188,  loss_train=0.64025,  acc_train=78.12%
8853.1s	2696	[train]  epoch 67/100,  batch 161/188,  loss_train=0.50687,  acc_train=81.25%
8858.9s	2697	[train]  epoch 67/100,  batch 171/188,  loss_train=0.41285,  acc_train=85.94%
8864.4s	2698	[train]  epoch 67/100,  batch 181/188,  loss_train=0.64397,  acc_train=81.25%
8868.9s	2699	[ val ]  epoch 67/100,  batch 1/135,  loss_val=3.12238,  acc_val=39.06%
8870.7s	2700	[ val ]  epoch 67/100,  batch 11/135,  loss_val=5.62923,  acc_val=9.38%
8872.5s	2701	[ val ]  epoch 67/100,  batch 21/135,  loss_val=1.83443,  acc_val=57.81%
8874.3s	2702	[ val ]  epoch 67/100,  batch 31/135,  loss_val=1.80645,  acc_val=60.94%
8876.1s	2703	[ val ]  epoch 67/100,  batch 41/135,  loss_val=1.75010,  acc_val=54.69%
8878.0s	2704	[ val ]  epoch 67/100,  batch 51/135,  loss_val=2.56773,  acc_val=48.44%
8879.8s	2705	[ val ]  epoch 67/100,  batch 61/135,  loss_val=2.74462,  acc_val=46.88%
8881.6s	2706	[ val ]  epoch 67/100,  batch 71/135,  loss_val=3.83793,  acc_val=23.44%
8883.4s	2707	[ val ]  epoch 67/100,  batch 81/135,  loss_val=3.05700,  acc_val=46.88%
8885.2s	2708	[ val ]  epoch 67/100,  batch 91/135,  loss_val=3.30489,  acc_val=28.12%
8886.9s	2709	[ val ]  epoch 67/100,  batch 101/135,  loss_val=0.74863,  acc_val=79.69%
8888.7s	2710	[ val ]  epoch 67/100,  batch 111/135,  loss_val=3.50182,  acc_val=28.12%
8890.8s	2711	[ val ]  epoch 67/100,  batch 121/135,  loss_val=1.97565,  acc_val=56.25%
8892.3s	2712	[ val ]  epoch 67/100,  batch 131/135,  loss_val=2.25434,  acc_val=42.19%
8892.9s	2713	===================================================================================================================
8892.9s	2714	Epoch 67/100 summary: loss_train=0.51413, acc_train=83.99%, loss_val=2.37, acc_val=47.95% (best: 47.95% @ epoch 67)
8892.9s	2715	===================================================================================================================
8892.9s	2716	Starting epoch 68/100, learning_rate=0.1
8894.2s	2717	[train]  epoch 68/100,  batch 1/188,  loss_train=0.44792,  acc_train=84.38%
8899.9s	2718	[train]  epoch 68/100,  batch 11/188,  loss_train=0.56941,  acc_train=79.69%
8905.5s	2719	[train]  epoch 68/100,  batch 21/188,  loss_train=0.74288,  acc_train=70.31%
8911.1s	2720	[train]  epoch 68/100,  batch 31/188,  loss_train=0.46556,  acc_train=84.38%
8916.7s	2721	[train]  epoch 68/100,  batch 41/188,  loss_train=0.56640,  acc_train=76.56%
8922.6s	2722	[train]  epoch 68/100,  batch 51/188,  loss_train=0.31779,  acc_train=85.94%
8928.0s	2723	[train]  epoch 68/100,  batch 61/188,  loss_train=0.54842,  acc_train=84.38%
8933.6s	2724	[train]  epoch 68/100,  batch 71/188,  loss_train=0.56457,  acc_train=89.06%
8939.2s	2725	[train]  epoch 68/100,  batch 81/188,  loss_train=0.58185,  acc_train=84.38%
8944.9s	2726	[train]  epoch 68/100,  batch 91/188,  loss_train=0.62983,  acc_train=79.69%
8950.5s	2727	[train]  epoch 68/100,  batch 101/188,  loss_train=0.43063,  acc_train=82.81%
8956.3s	2728	[train]  epoch 68/100,  batch 111/188,  loss_train=0.51382,  acc_train=84.38%
8961.8s	2729	[train]  epoch 68/100,  batch 121/188,  loss_train=0.32820,  acc_train=90.62%
8967.4s	2730	[train]  epoch 68/100,  batch 131/188,  loss_train=0.34757,  acc_train=92.19%
8973.0s	2731	[train]  epoch 68/100,  batch 141/188,  loss_train=0.56829,  acc_train=78.12%
8978.7s	2732	[train]  epoch 68/100,  batch 151/188,  loss_train=0.50119,  acc_train=85.94%
8984.3s	2733	[train]  epoch 68/100,  batch 161/188,  loss_train=0.45063,  acc_train=78.12%
8990.1s	2734	[train]  epoch 68/100,  batch 171/188,  loss_train=0.53355,  acc_train=81.25%
8995.5s	2735	[train]  epoch 68/100,  batch 181/188,  loss_train=0.64954,  acc_train=76.56%
9000.2s	2736	[ val ]  epoch 68/100,  batch 1/135,  loss_val=2.94493,  acc_val=39.06%
9002.0s	2737	[ val ]  epoch 68/100,  batch 11/135,  loss_val=2.27690,  acc_val=39.06%
9003.8s	2738	[ val ]  epoch 68/100,  batch 21/135,  loss_val=2.43784,  acc_val=37.50%
9005.7s	2739	[ val ]  epoch 68/100,  batch 31/135,  loss_val=1.51650,  acc_val=65.62%
9007.6s	2740	[ val ]  epoch 68/100,  batch 41/135,  loss_val=1.85664,  acc_val=56.25%
9009.3s	2741	[ val ]  epoch 68/100,  batch 51/135,  loss_val=2.10443,  acc_val=53.12%
9011.1s	2742	[ val ]  epoch 68/100,  batch 61/135,  loss_val=2.82333,  acc_val=37.50%
9012.9s	2743	[ val ]  epoch 68/100,  batch 71/135,  loss_val=3.76052,  acc_val=31.25%
9014.7s	2744	[ val ]  epoch 68/100,  batch 81/135,  loss_val=2.13983,  acc_val=57.81%
9016.5s	2745	[ val ]  epoch 68/100,  batch 91/135,  loss_val=3.07058,  acc_val=39.06%
9018.3s	2746	[ val ]  epoch 68/100,  batch 101/135,  loss_val=1.20094,  acc_val=62.50%
9020.4s	2747	[ val ]  epoch 68/100,  batch 111/135,  loss_val=4.56030,  acc_val=20.31%
9021.9s	2748	[ val ]  epoch 68/100,  batch 121/135,  loss_val=2.40706,  acc_val=50.00%
9023.7s	2749	[ val ]  epoch 68/100,  batch 131/135,  loss_val=2.96243,  acc_val=40.62%
9024.3s	2750	===================================================================================================================
9024.3s	2751	Epoch 68/100 summary: loss_train=0.50613, acc_train=84.10%, loss_val=2.45, acc_val=46.79% (best: 47.95% @ epoch 67)
9024.3s	2752	===================================================================================================================
9024.3s	2753	Starting epoch 69/100, learning_rate=0.1
9025.6s	2754	[train]  epoch 69/100,  batch 1/188,  loss_train=0.35886,  acc_train=85.94%
9031.2s	2755	[train]  epoch 69/100,  batch 11/188,  loss_train=0.42192,  acc_train=87.50%
9036.8s	2756	[train]  epoch 69/100,  batch 21/188,  loss_train=0.49254,  acc_train=79.69%
9042.6s	2757	[train]  epoch 69/100,  batch 31/188,  loss_train=0.40910,  acc_train=87.50%
9048.2s	2758	[train]  epoch 69/100,  batch 41/188,  loss_train=0.33449,  acc_train=90.62%
9054.0s	2759	[train]  epoch 69/100,  batch 51/188,  loss_train=0.37283,  acc_train=89.06%
9059.5s	2760	[train]  epoch 69/100,  batch 61/188,  loss_train=0.32570,  acc_train=89.06%
9065.1s	2761	[train]  epoch 69/100,  batch 71/188,  loss_train=0.59006,  acc_train=84.38%
9070.8s	2762	[train]  epoch 69/100,  batch 81/188,  loss_train=0.32682,  acc_train=92.19%
9076.4s	2763	[train]  epoch 69/100,  batch 91/188,  loss_train=0.55988,  acc_train=82.81%
9082.0s	2764	[train]  epoch 69/100,  batch 101/188,  loss_train=0.45887,  acc_train=84.38%
9087.9s	2765	[train]  epoch 69/100,  batch 111/188,  loss_train=0.46922,  acc_train=85.94%
9093.2s	2766	[train]  epoch 69/100,  batch 121/188,  loss_train=0.69310,  acc_train=81.25%
9098.9s	2767	[train]  epoch 69/100,  batch 131/188,  loss_train=0.43227,  acc_train=90.62%
9104.5s	2768	[train]  epoch 69/100,  batch 141/188,  loss_train=0.66281,  acc_train=81.25%
9110.1s	2769	[train]  epoch 69/100,  batch 151/188,  loss_train=0.43556,  acc_train=89.06%
9115.8s	2770	[train]  epoch 69/100,  batch 161/188,  loss_train=0.79164,  acc_train=75.00%
9121.7s	2771	[train]  epoch 69/100,  batch 171/188,  loss_train=0.53733,  acc_train=79.69%
9127.1s	2772	[train]  epoch 69/100,  batch 181/188,  loss_train=0.43141,  acc_train=82.81%
9131.7s	2773	[ val ]  epoch 69/100,  batch 1/135,  loss_val=4.13985,  acc_val=32.81%
9133.7s	2774	[ val ]  epoch 69/100,  batch 11/135,  loss_val=2.55989,  acc_val=39.06%
9135.5s	2775	[ val ]  epoch 69/100,  batch 21/135,  loss_val=2.64812,  acc_val=48.44%
9137.3s	2776	[ val ]  epoch 69/100,  batch 31/135,  loss_val=0.46109,  acc_val=85.94%
9139.1s	2777	[ val ]  epoch 69/100,  batch 41/135,  loss_val=3.14161,  acc_val=37.50%
9140.9s	2778	[ val ]  epoch 69/100,  batch 51/135,  loss_val=2.04709,  acc_val=59.38%
9142.7s	2779	[ val ]  epoch 69/100,  batch 61/135,  loss_val=2.71123,  acc_val=45.31%
9144.5s	2780	[ val ]  epoch 69/100,  batch 71/135,  loss_val=2.52541,  acc_val=39.06%
9146.2s	2781	[ val ]  epoch 69/100,  batch 81/135,  loss_val=3.90431,  acc_val=39.06%
9148.0s	2782	[ val ]  epoch 69/100,  batch 91/135,  loss_val=3.80433,  acc_val=15.62%
9149.8s	2783	[ val ]  epoch 69/100,  batch 101/135,  loss_val=1.36290,  acc_val=62.50%
9151.5s	2784	[ val ]  epoch 69/100,  batch 111/135,  loss_val=4.96673,  acc_val=10.94%
9153.6s	2785	[ val ]  epoch 69/100,  batch 121/135,  loss_val=1.77261,  acc_val=59.38%
9155.1s	2786	[ val ]  epoch 69/100,  batch 131/135,  loss_val=1.52798,  acc_val=56.25%
9155.7s	2787	===================================================================================================================
9155.7s	2788	Epoch 69/100 summary: loss_train=0.50824, acc_train=83.74%, loss_val=2.50, acc_val=45.50% (best: 47.95% @ epoch 67)
9155.7s	2789	===================================================================================================================
9155.7s	2790	Starting epoch 70/100, learning_rate=0.1
9157.0s	2791	[train]  epoch 70/100,  batch 1/188,  loss_train=0.39064,  acc_train=90.62%
9162.6s	2792	[train]  epoch 70/100,  batch 11/188,  loss_train=0.56529,  acc_train=81.25%
9168.2s	2793	[train]  epoch 70/100,  batch 21/188,  loss_train=0.38055,  acc_train=85.94%
9173.9s	2794	[train]  epoch 70/100,  batch 31/188,  loss_train=0.50543,  acc_train=82.81%
9179.5s	2795	[train]  epoch 70/100,  batch 41/188,  loss_train=0.38303,  acc_train=90.62%
9185.4s	2796	[train]  epoch 70/100,  batch 51/188,  loss_train=0.36869,  acc_train=89.06%
9190.7s	2797	[train]  epoch 70/100,  batch 61/188,  loss_train=0.44378,  acc_train=87.50%
9196.3s	2798	[train]  epoch 70/100,  batch 71/188,  loss_train=0.41184,  acc_train=89.06%
9202.0s	2799	[train]  epoch 70/100,  batch 81/188,  loss_train=0.25327,  acc_train=90.62%
9207.6s	2800	[train]  epoch 70/100,  batch 91/188,  loss_train=0.35015,  acc_train=89.06%
9213.2s	2801	[train]  epoch 70/100,  batch 101/188,  loss_train=0.47502,  acc_train=85.94%
9219.1s	2802	[train]  epoch 70/100,  batch 111/188,  loss_train=0.46434,  acc_train=85.94%
9224.6s	2803	[train]  epoch 70/100,  batch 121/188,  loss_train=0.32060,  acc_train=93.75%
9230.2s	2804	[train]  epoch 70/100,  batch 131/188,  loss_train=0.70371,  acc_train=76.56%
9235.8s	2805	[train]  epoch 70/100,  batch 141/188,  loss_train=0.47137,  acc_train=87.50%
9241.5s	2806	[train]  epoch 70/100,  batch 151/188,  loss_train=0.68472,  acc_train=79.69%
9247.1s	2807	[train]  epoch 70/100,  batch 161/188,  loss_train=0.26586,  acc_train=93.75%
9253.0s	2808	[train]  epoch 70/100,  batch 171/188,  loss_train=0.54810,  acc_train=84.38%
9258.4s	2809	[train]  epoch 70/100,  batch 181/188,  loss_train=0.62520,  acc_train=81.25%
9263.0s	2810	[ val ]  epoch 70/100,  batch 1/135,  loss_val=2.57806,  acc_val=42.19%
9264.9s	2811	[ val ]  epoch 70/100,  batch 11/135,  loss_val=2.31587,  acc_val=43.75%
9266.6s	2812	[ val ]  epoch 70/100,  batch 21/135,  loss_val=2.42007,  acc_val=39.06%
9268.4s	2813	[ val ]  epoch 70/100,  batch 31/135,  loss_val=1.15540,  acc_val=75.00%
9270.2s	2814	[ val ]  epoch 70/100,  batch 41/135,  loss_val=1.72746,  acc_val=60.94%
9272.0s	2815	[ val ]  epoch 70/100,  batch 51/135,  loss_val=2.48363,  acc_val=54.69%
9273.8s	2816	[ val ]  epoch 70/100,  batch 61/135,  loss_val=2.26406,  acc_val=51.56%
9275.6s	2817	[ val ]  epoch 70/100,  batch 71/135,  loss_val=2.41166,  acc_val=35.94%
9277.4s	2818	[ val ]  epoch 70/100,  batch 81/135,  loss_val=3.42601,  acc_val=48.44%
9279.2s	2819	[ val ]  epoch 70/100,  batch 91/135,  loss_val=3.18584,  acc_val=21.88%
9281.0s	2820	[ val ]  epoch 70/100,  batch 101/135,  loss_val=2.27183,  acc_val=48.44%
9282.7s	2821	[ val ]  epoch 70/100,  batch 111/135,  loss_val=3.28455,  acc_val=29.69%
9284.8s	2822	[ val ]  epoch 70/100,  batch 121/135,  loss_val=0.46828,  acc_val=85.94%
9286.3s	2823	[ val ]  epoch 70/100,  batch 131/135,  loss_val=3.01840,  acc_val=35.94%
9286.9s	2824	===================================================================================================================
9286.9s	2825	Epoch 70/100 summary: loss_train=0.44502, acc_train=86.07%, loss_val=2.42, acc_val=45.62% (best: 47.95% @ epoch 67)
9286.9s	2826	===================================================================================================================
9286.9s	2827	Starting epoch 71/100, learning_rate=0.1
9288.2s	2828	[train]  epoch 71/100,  batch 1/188,  loss_train=0.39355,  acc_train=90.62%
9293.8s	2829	[train]  epoch 71/100,  batch 11/188,  loss_train=0.54138,  acc_train=82.81%
9299.5s	2830	[train]  epoch 71/100,  batch 21/188,  loss_train=0.53484,  acc_train=85.94%
9305.1s	2831	[train]  epoch 71/100,  batch 31/188,  loss_train=0.36831,  acc_train=90.62%
9310.7s	2832	[train]  epoch 71/100,  batch 41/188,  loss_train=0.41310,  acc_train=84.38%
9316.5s	2833	[train]  epoch 71/100,  batch 51/188,  loss_train=0.26226,  acc_train=95.31%
9321.9s	2834	[train]  epoch 71/100,  batch 61/188,  loss_train=0.33325,  acc_train=92.19%
9327.6s	2835	[train]  epoch 71/100,  batch 71/188,  loss_train=0.43199,  acc_train=84.38%
9333.3s	2836	[train]  epoch 71/100,  batch 81/188,  loss_train=0.56992,  acc_train=82.81%
9338.9s	2837	[train]  epoch 71/100,  batch 91/188,  loss_train=0.53741,  acc_train=81.25%
9344.5s	2838	[train]  epoch 71/100,  batch 101/188,  loss_train=0.57076,  acc_train=85.94%
9350.4s	2839	[train]  epoch 71/100,  batch 111/188,  loss_train=0.34267,  acc_train=89.06%
9355.8s	2840	[train]  epoch 71/100,  batch 121/188,  loss_train=0.41560,  acc_train=87.50%
9361.4s	2841	[train]  epoch 71/100,  batch 131/188,  loss_train=0.76229,  acc_train=76.56%
9367.0s	2842	[train]  epoch 71/100,  batch 141/188,  loss_train=0.33021,  acc_train=87.50%
9372.6s	2843	[train]  epoch 71/100,  batch 151/188,  loss_train=0.31393,  acc_train=92.19%
9378.3s	2844	[train]  epoch 71/100,  batch 161/188,  loss_train=0.48276,  acc_train=85.94%
9384.1s	2845	[train]  epoch 71/100,  batch 171/188,  loss_train=0.57008,  acc_train=82.81%
9389.5s	2846	[train]  epoch 71/100,  batch 181/188,  loss_train=0.48516,  acc_train=84.38%
9394.2s	2847	[ val ]  epoch 71/100,  batch 1/135,  loss_val=3.42855,  acc_val=29.69%
9396.0s	2848	[ val ]  epoch 71/100,  batch 11/135,  loss_val=1.11851,  acc_val=71.88%
9397.8s	2849	[ val ]  epoch 71/100,  batch 21/135,  loss_val=2.59789,  acc_val=37.50%
9399.6s	2850	[ val ]  epoch 71/100,  batch 31/135,  loss_val=2.05667,  acc_val=59.38%
9401.4s	2851	[ val ]  epoch 71/100,  batch 41/135,  loss_val=3.02266,  acc_val=39.06%
9403.2s	2852	[ val ]  epoch 71/100,  batch 51/135,  loss_val=2.76199,  acc_val=48.44%
9405.0s	2853	[ val ]  epoch 71/100,  batch 61/135,  loss_val=3.06478,  acc_val=37.50%
9406.7s	2854	[ val ]  epoch 71/100,  batch 71/135,  loss_val=2.89229,  acc_val=40.62%
9408.5s	2855	[ val ]  epoch 71/100,  batch 81/135,  loss_val=4.55387,  acc_val=20.31%
9410.3s	2856	[ val ]  epoch 71/100,  batch 91/135,  loss_val=4.17601,  acc_val=26.56%
9412.1s	2857	[ val ]  epoch 71/100,  batch 101/135,  loss_val=0.70157,  acc_val=84.38%
9413.9s	2858	[ val ]  epoch 71/100,  batch 111/135,  loss_val=3.86040,  acc_val=32.81%
9416.0s	2859	[ val ]  epoch 71/100,  batch 121/135,  loss_val=1.35240,  acc_val=65.62%
9417.5s	2860	[ val ]  epoch 71/100,  batch 131/135,  loss_val=4.02299,  acc_val=26.56%
9418.1s	2861	===================================================================================================================
9418.1s	2862	Epoch 71/100 summary: loss_train=0.45395, acc_train=85.70%, loss_val=2.91, acc_val=40.73% (best: 47.95% @ epoch 67)
9418.1s	2863	===================================================================================================================
9418.1s	2864	Starting epoch 72/100, learning_rate=0.1
9419.6s	2865	[train]  epoch 72/100,  batch 1/188,  loss_train=0.35863,  acc_train=92.19%
9425.3s	2866	[train]  epoch 72/100,  batch 11/188,  loss_train=0.36689,  acc_train=92.19%
9431.0s	2867	[train]  epoch 72/100,  batch 21/188,  loss_train=0.29618,  acc_train=89.06%
9436.7s	2868	[train]  epoch 72/100,  batch 31/188,  loss_train=0.35467,  acc_train=93.75%
9442.3s	2869	[train]  epoch 72/100,  batch 41/188,  loss_train=0.34579,  acc_train=87.50%
9448.2s	2870	[train]  epoch 72/100,  batch 51/188,  loss_train=0.28830,  acc_train=93.75%
9453.6s	2871	[train]  epoch 72/100,  batch 61/188,  loss_train=0.28726,  acc_train=92.19%
9459.2s	2872	[train]  epoch 72/100,  batch 71/188,  loss_train=0.48198,  acc_train=82.81%
9464.8s	2873	[train]  epoch 72/100,  batch 81/188,  loss_train=0.38118,  acc_train=89.06%
9470.4s	2874	[train]  epoch 72/100,  batch 91/188,  loss_train=0.30742,  acc_train=90.62%
9476.1s	2875	[train]  epoch 72/100,  batch 101/188,  loss_train=0.48264,  acc_train=87.50%
9481.9s	2876	[train]  epoch 72/100,  batch 111/188,  loss_train=0.37967,  acc_train=85.94%
9487.3s	2877	[train]  epoch 72/100,  batch 121/188,  loss_train=0.40789,  acc_train=84.38%
9493.0s	2878	[train]  epoch 72/100,  batch 131/188,  loss_train=0.35844,  acc_train=87.50%
9498.6s	2879	[train]  epoch 72/100,  batch 141/188,  loss_train=0.50532,  acc_train=85.94%
9504.2s	2880	[train]  epoch 72/100,  batch 151/188,  loss_train=0.42537,  acc_train=82.81%
9509.8s	2881	[train]  epoch 72/100,  batch 161/188,  loss_train=0.71591,  acc_train=81.25%
9515.7s	2882	[train]  epoch 72/100,  batch 171/188,  loss_train=0.50373,  acc_train=84.38%
9521.0s	2883	[train]  epoch 72/100,  batch 181/188,  loss_train=0.36972,  acc_train=89.06%
9525.6s	2884	[ val ]  epoch 72/100,  batch 1/135,  loss_val=3.61342,  acc_val=31.25%
9527.4s	2885	[ val ]  epoch 72/100,  batch 11/135,  loss_val=2.14449,  acc_val=56.25%
9529.2s	2886	[ val ]  epoch 72/100,  batch 21/135,  loss_val=2.63439,  acc_val=35.94%
9531.0s	2887	[ val ]  epoch 72/100,  batch 31/135,  loss_val=1.92985,  acc_val=57.81%
9532.8s	2888	[ val ]  epoch 72/100,  batch 41/135,  loss_val=2.06601,  acc_val=56.25%
9534.6s	2889	[ val ]  epoch 72/100,  batch 51/135,  loss_val=2.00018,  acc_val=56.25%
9536.3s	2890	[ val ]  epoch 72/100,  batch 61/135,  loss_val=1.80504,  acc_val=65.62%
9538.1s	2891	[ val ]  epoch 72/100,  batch 71/135,  loss_val=3.37678,  acc_val=31.25%
9539.9s	2892	[ val ]  epoch 72/100,  batch 81/135,  loss_val=1.74393,  acc_val=65.62%
9541.7s	2893	[ val ]  epoch 72/100,  batch 91/135,  loss_val=3.74915,  acc_val=15.62%
9543.5s	2894	[ val ]  epoch 72/100,  batch 101/135,  loss_val=1.31248,  acc_val=60.94%
9545.2s	2895	[ val ]  epoch 72/100,  batch 111/135,  loss_val=3.39293,  acc_val=31.25%
9547.5s	2896	[ val ]  epoch 72/100,  batch 121/135,  loss_val=0.81638,  acc_val=79.69%
9548.9s	2897	[ val ]  epoch 72/100,  batch 131/135,  loss_val=3.60425,  acc_val=29.69%
9549.5s	2898	===================================================================================================================
9549.5s	2899	Epoch 72/100 summary: loss_train=0.43902, acc_train=86.08%, loss_val=2.43, acc_val=45.86% (best: 47.95% @ epoch 67)
9549.5s	2900	===================================================================================================================
9549.5s	2901	Starting epoch 73/100, learning_rate=0.1
9550.8s	2902	[train]  epoch 73/100,  batch 1/188,  loss_train=0.30044,  acc_train=90.62%
9556.5s	2903	[train]  epoch 73/100,  batch 11/188,  loss_train=0.44483,  acc_train=92.19%
9562.1s	2904	[train]  epoch 73/100,  batch 21/188,  loss_train=0.55360,  acc_train=78.12%
9567.7s	2905	[train]  epoch 73/100,  batch 31/188,  loss_train=0.38164,  acc_train=85.94%
9573.3s	2906	[train]  epoch 73/100,  batch 41/188,  loss_train=0.28528,  acc_train=90.62%
9579.2s	2907	[train]  epoch 73/100,  batch 51/188,  loss_train=0.29894,  acc_train=92.19%
9584.6s	2908	[train]  epoch 73/100,  batch 61/188,  loss_train=0.30200,  acc_train=92.19%
9590.2s	2909	[train]  epoch 73/100,  batch 71/188,  loss_train=0.58062,  acc_train=85.94%
9595.8s	2910	[train]  epoch 73/100,  batch 81/188,  loss_train=0.56951,  acc_train=78.12%
9601.4s	2911	[train]  epoch 73/100,  batch 91/188,  loss_train=0.51095,  acc_train=87.50%
9607.0s	2912	[train]  epoch 73/100,  batch 101/188,  loss_train=0.48097,  acc_train=87.50%
9612.9s	2913	[train]  epoch 73/100,  batch 111/188,  loss_train=0.31732,  acc_train=89.06%
9618.3s	2914	[train]  epoch 73/100,  batch 121/188,  loss_train=0.56777,  acc_train=82.81%
9623.9s	2915	[train]  epoch 73/100,  batch 131/188,  loss_train=0.67638,  acc_train=76.56%
9629.6s	2916	[train]  epoch 73/100,  batch 141/188,  loss_train=0.41898,  acc_train=89.06%
9635.2s	2917	[train]  epoch 73/100,  batch 151/188,  loss_train=0.31089,  acc_train=89.06%
9640.8s	2918	[train]  epoch 73/100,  batch 161/188,  loss_train=0.76926,  acc_train=73.44%
9646.7s	2919	[train]  epoch 73/100,  batch 171/188,  loss_train=0.47315,  acc_train=85.94%
9652.1s	2920	[train]  epoch 73/100,  batch 181/188,  loss_train=0.53121,  acc_train=87.50%
9656.7s	2921	[ val ]  epoch 73/100,  batch 1/135,  loss_val=2.81721,  acc_val=39.06%
9658.5s	2922	[ val ]  epoch 73/100,  batch 11/135,  loss_val=2.25102,  acc_val=57.81%
9660.3s	2923	[ val ]  epoch 73/100,  batch 21/135,  loss_val=2.56749,  acc_val=40.62%
9662.0s	2924	[ val ]  epoch 73/100,  batch 31/135,  loss_val=1.23605,  acc_val=73.44%
9663.8s	2925	[ val ]  epoch 73/100,  batch 41/135,  loss_val=1.56147,  acc_val=64.06%
9665.6s	2926	[ val ]  epoch 73/100,  batch 51/135,  loss_val=1.86053,  acc_val=56.25%
9667.3s	2927	[ val ]  epoch 73/100,  batch 61/135,  loss_val=4.33796,  acc_val=21.88%
9669.1s	2928	[ val ]  epoch 73/100,  batch 71/135,  loss_val=2.43126,  acc_val=39.06%
9670.9s	2929	[ val ]  epoch 73/100,  batch 81/135,  loss_val=3.82275,  acc_val=45.31%
9672.7s	2930	[ val ]  epoch 73/100,  batch 91/135,  loss_val=2.86861,  acc_val=32.81%
9674.5s	2931	[ val ]  epoch 73/100,  batch 101/135,  loss_val=1.78668,  acc_val=51.56%
9676.4s	2932	[ val ]  epoch 73/100,  batch 111/135,  loss_val=2.21030,  acc_val=54.69%
9678.5s	2933	[ val ]  epoch 73/100,  batch 121/135,  loss_val=2.14890,  acc_val=54.69%
9680.0s	2934	[ val ]  epoch 73/100,  batch 131/135,  loss_val=2.58614,  acc_val=46.88%
9680.6s	2935	===================================================================================================================
9680.6s	2936	Epoch 73/100 summary: loss_train=0.45121, acc_train=85.65%, loss_val=2.69, acc_val=43.48% (best: 47.95% @ epoch 67)
9680.6s	2937	===================================================================================================================
9680.6s	2938	Starting epoch 74/100, learning_rate=0.1
9681.9s	2939	[train]  epoch 74/100,  batch 1/188,  loss_train=0.52351,  acc_train=84.38%
9687.5s	2940	[train]  epoch 74/100,  batch 11/188,  loss_train=0.42128,  acc_train=90.62%
9693.1s	2941	[train]  epoch 74/100,  batch 21/188,  loss_train=0.27083,  acc_train=90.62%
9698.7s	2942	[train]  epoch 74/100,  batch 31/188,  loss_train=0.37546,  acc_train=85.94%
9704.4s	2943	[train]  epoch 74/100,  batch 41/188,  loss_train=0.48750,  acc_train=82.81%
9710.4s	2944	[train]  epoch 74/100,  batch 51/188,  loss_train=0.33976,  acc_train=92.19%
9715.7s	2945	[train]  epoch 74/100,  batch 61/188,  loss_train=0.39478,  acc_train=87.50%
9721.3s	2946	[train]  epoch 74/100,  batch 71/188,  loss_train=0.41244,  acc_train=85.94%
9726.9s	2947	[train]  epoch 74/100,  batch 81/188,  loss_train=0.49239,  acc_train=84.38%
9732.6s	2948	[train]  epoch 74/100,  batch 91/188,  loss_train=0.45842,  acc_train=85.94%
9738.2s	2949	[train]  epoch 74/100,  batch 101/188,  loss_train=0.45349,  acc_train=82.81%
9744.1s	2950	[train]  epoch 74/100,  batch 111/188,  loss_train=0.50558,  acc_train=78.12%
9749.4s	2951	[train]  epoch 74/100,  batch 121/188,  loss_train=0.48550,  acc_train=89.06%
9755.1s	2952	[train]  epoch 74/100,  batch 131/188,  loss_train=0.60405,  acc_train=84.38%
9760.7s	2953	[train]  epoch 74/100,  batch 141/188,  loss_train=0.31305,  acc_train=95.31%
9766.3s	2954	[train]  epoch 74/100,  batch 151/188,  loss_train=0.56609,  acc_train=82.81%
9771.9s	2955	[train]  epoch 74/100,  batch 161/188,  loss_train=0.58247,  acc_train=78.12%
9777.6s	2956	[train]  epoch 74/100,  batch 171/188,  loss_train=0.40302,  acc_train=82.81%
9783.1s	2957	[train]  epoch 74/100,  batch 181/188,  loss_train=0.43208,  acc_train=82.81%
9787.7s	2958	[ val ]  epoch 74/100,  batch 1/135,  loss_val=3.33920,  acc_val=25.00%
9789.5s	2959	[ val ]  epoch 74/100,  batch 11/135,  loss_val=1.64221,  acc_val=56.25%
9791.3s	2960	[ val ]  epoch 74/100,  batch 21/135,  loss_val=2.25690,  acc_val=39.06%
9793.1s	2961	[ val ]  epoch 74/100,  batch 31/135,  loss_val=1.41649,  acc_val=67.19%
9794.9s	2962	[ val ]  epoch 74/100,  batch 41/135,  loss_val=1.20002,  acc_val=75.00%
9796.7s	2963	[ val ]  epoch 74/100,  batch 51/135,  loss_val=2.72539,  acc_val=37.50%
9798.5s	2964	[ val ]  epoch 74/100,  batch 61/135,  loss_val=3.25228,  acc_val=39.06%
9800.3s	2965	[ val ]  epoch 74/100,  batch 71/135,  loss_val=3.33930,  acc_val=26.56%
9802.1s	2966	[ val ]  epoch 74/100,  batch 81/135,  loss_val=3.11293,  acc_val=45.31%
9804.0s	2967	[ val ]  epoch 74/100,  batch 91/135,  loss_val=2.55441,  acc_val=34.38%
9805.8s	2968	[ val ]  epoch 74/100,  batch 101/135,  loss_val=0.88369,  acc_val=76.56%
9807.6s	2969	[ val ]  epoch 74/100,  batch 111/135,  loss_val=2.23549,  acc_val=50.00%
9809.6s	2970	[ val ]  epoch 74/100,  batch 121/135,  loss_val=1.95115,  acc_val=48.44%
9811.1s	2971	[ val ]  epoch 74/100,  batch 131/135,  loss_val=3.97226,  acc_val=29.69%
9811.8s	2972	===================================================================================================================
9811.8s	2973	Epoch 74/100 summary: loss_train=0.44994, acc_train=85.67%, loss_val=2.65, acc_val=43.44% (best: 47.95% @ epoch 67)
9811.8s	2974	===================================================================================================================
9811.8s	2975	Starting epoch 75/100, learning_rate=0.1
9813.0s	2976	[train]  epoch 75/100,  batch 1/188,  loss_train=0.47365,  acc_train=84.38%
9818.7s	2977	[train]  epoch 75/100,  batch 11/188,  loss_train=0.45343,  acc_train=89.06%
9824.3s	2978	[train]  epoch 75/100,  batch 21/188,  loss_train=0.52997,  acc_train=82.81%
9829.9s	2979	[train]  epoch 75/100,  batch 31/188,  loss_train=0.27075,  acc_train=93.75%
9835.6s	2980	[train]  epoch 75/100,  batch 41/188,  loss_train=0.47581,  acc_train=87.50%
9841.4s	2981	[train]  epoch 75/100,  batch 51/188,  loss_train=0.29057,  acc_train=90.62%
9846.8s	2982	[train]  epoch 75/100,  batch 61/188,  loss_train=0.33546,  acc_train=87.50%
9852.4s	2983	[train]  epoch 75/100,  batch 71/188,  loss_train=0.44492,  acc_train=85.94%
9858.0s	2984	[train]  epoch 75/100,  batch 81/188,  loss_train=0.36391,  acc_train=90.62%
9863.7s	2985	[train]  epoch 75/100,  batch 91/188,  loss_train=0.50397,  acc_train=82.81%
9869.3s	2986	[train]  epoch 75/100,  batch 101/188,  loss_train=0.45863,  acc_train=84.38%
9875.2s	2987	[train]  epoch 75/100,  batch 111/188,  loss_train=0.43469,  acc_train=85.94%
9880.6s	2988	[train]  epoch 75/100,  batch 121/188,  loss_train=0.54286,  acc_train=85.94%
9886.2s	2989	[train]  epoch 75/100,  batch 131/188,  loss_train=0.41712,  acc_train=87.50%
9891.8s	2990	[train]  epoch 75/100,  batch 141/188,  loss_train=0.47831,  acc_train=87.50%
9897.5s	2991	[train]  epoch 75/100,  batch 151/188,  loss_train=0.47667,  acc_train=85.94%
9903.2s	2992	[train]  epoch 75/100,  batch 161/188,  loss_train=0.35217,  acc_train=89.06%
9909.0s	2993	[train]  epoch 75/100,  batch 171/188,  loss_train=0.46682,  acc_train=85.94%
9914.4s	2994	[train]  epoch 75/100,  batch 181/188,  loss_train=0.63000,  acc_train=78.12%
9919.1s	2995	[ val ]  epoch 75/100,  batch 1/135,  loss_val=4.87129,  acc_val=18.75%
9920.9s	2996	[ val ]  epoch 75/100,  batch 11/135,  loss_val=3.03218,  acc_val=39.06%
9922.7s	2997	[ val ]  epoch 75/100,  batch 21/135,  loss_val=3.16213,  acc_val=31.25%
9924.5s	2998	[ val ]  epoch 75/100,  batch 31/135,  loss_val=2.01123,  acc_val=60.94%
9926.3s	2999	[ val ]  epoch 75/100,  batch 41/135,  loss_val=3.00814,  acc_val=32.81%
9928.0s	3000	[ val ]  epoch 75/100,  batch 51/135,  loss_val=3.14371,  acc_val=46.88%
9929.8s	3001	[ val ]  epoch 75/100,  batch 61/135,  loss_val=2.39650,  acc_val=48.44%
9931.8s	3002	[ val ]  epoch 75/100,  batch 71/135,  loss_val=2.79168,  acc_val=40.62%
9933.6s	3003	[ val ]  epoch 75/100,  batch 81/135,  loss_val=3.07931,  acc_val=53.12%
9935.4s	3004	[ val ]  epoch 75/100,  batch 91/135,  loss_val=3.81034,  acc_val=26.56%
9937.2s	3005	[ val ]  epoch 75/100,  batch 101/135,  loss_val=1.25675,  acc_val=68.75%
9939.0s	3006	[ val ]  epoch 75/100,  batch 111/135,  loss_val=3.08293,  acc_val=34.38%
9941.1s	3007	[ val ]  epoch 75/100,  batch 121/135,  loss_val=1.43487,  acc_val=54.69%
9942.5s	3008	[ val ]  epoch 75/100,  batch 131/135,  loss_val=3.37453,  acc_val=35.94%
9943.2s	3009	===================================================================================================================
9943.2s	3010	Epoch 75/100 summary: loss_train=0.44109, acc_train=86.23%, loss_val=2.42, acc_val=47.00% (best: 47.95% @ epoch 67)
9943.2s	3011	===================================================================================================================
9943.2s	3012	Starting epoch 76/100, learning_rate=0.1
9944.6s	3013	[train]  epoch 76/100,  batch 1/188,  loss_train=0.33859,  acc_train=89.06%
9950.2s	3014	[train]  epoch 76/100,  batch 11/188,  loss_train=0.30971,  acc_train=93.75%
9955.8s	3015	[train]  epoch 76/100,  batch 21/188,  loss_train=0.44113,  acc_train=85.94%
9961.5s	3016	[train]  epoch 76/100,  batch 31/188,  loss_train=0.29926,  acc_train=90.62%
9967.1s	3017	[train]  epoch 76/100,  batch 41/188,  loss_train=0.23591,  acc_train=95.31%
9973.0s	3018	[train]  epoch 76/100,  batch 51/188,  loss_train=0.44623,  acc_train=89.06%
9978.4s	3019	[train]  epoch 76/100,  batch 61/188,  loss_train=0.45281,  acc_train=87.50%
9984.0s	3020	[train]  epoch 76/100,  batch 71/188,  loss_train=0.41176,  acc_train=85.94%
9989.6s	3021	[train]  epoch 76/100,  batch 81/188,  loss_train=0.63498,  acc_train=81.25%
9995.3s	3022	[train]  epoch 76/100,  batch 91/188,  loss_train=0.36774,  acc_train=92.19%
10000.9s	3023	[train]  epoch 76/100,  batch 101/188,  loss_train=0.36062,  acc_train=89.06%
10006.7s	3024	[train]  epoch 76/100,  batch 111/188,  loss_train=0.48311,  acc_train=81.25%
10012.1s	3025	[train]  epoch 76/100,  batch 121/188,  loss_train=0.47174,  acc_train=84.38%
10017.8s	3026	[train]  epoch 76/100,  batch 131/188,  loss_train=0.26532,  acc_train=90.62%
10023.4s	3027	[train]  epoch 76/100,  batch 141/188,  loss_train=0.64057,  acc_train=81.25%
10029.1s	3028	[train]  epoch 76/100,  batch 151/188,  loss_train=0.45833,  acc_train=92.19%
10034.7s	3029	[train]  epoch 76/100,  batch 161/188,  loss_train=0.51698,  acc_train=84.38%
10040.6s	3030	[train]  epoch 76/100,  batch 171/188,  loss_train=0.33791,  acc_train=87.50%
10046.0s	3031	[train]  epoch 76/100,  batch 181/188,  loss_train=0.57909,  acc_train=81.25%
10050.6s	3032	[ val ]  epoch 76/100,  batch 1/135,  loss_val=3.32937,  acc_val=39.06%
10052.4s	3033	[ val ]  epoch 76/100,  batch 11/135,  loss_val=2.26660,  acc_val=42.19%
10054.2s	3034	[ val ]  epoch 76/100,  batch 21/135,  loss_val=1.69964,  acc_val=59.38%
10056.0s	3035	[ val ]  epoch 76/100,  batch 31/135,  loss_val=2.30920,  acc_val=56.25%
10057.8s	3036	[ val ]  epoch 76/100,  batch 41/135,  loss_val=1.74408,  acc_val=59.38%
10059.6s	3037	[ val ]  epoch 76/100,  batch 51/135,  loss_val=2.30164,  acc_val=50.00%
10061.4s	3038	[ val ]  epoch 76/100,  batch 61/135,  loss_val=2.49224,  acc_val=51.56%
10063.2s	3039	[ val ]  epoch 76/100,  batch 71/135,  loss_val=2.47988,  acc_val=37.50%
10065.0s	3040	[ val ]  epoch 76/100,  batch 81/135,  loss_val=3.51423,  acc_val=45.31%
10066.8s	3041	[ val ]  epoch 76/100,  batch 91/135,  loss_val=2.91623,  acc_val=35.94%
10068.6s	3042	[ val ]  epoch 76/100,  batch 101/135,  loss_val=0.58278,  acc_val=85.94%
10070.4s	3043	[ val ]  epoch 76/100,  batch 111/135,  loss_val=2.32998,  acc_val=48.44%
10072.4s	3044	[ val ]  epoch 76/100,  batch 121/135,  loss_val=1.25367,  acc_val=60.94%
10073.9s	3045	[ val ]  epoch 76/100,  batch 131/135,  loss_val=2.64558,  acc_val=45.31%
10074.5s	3046	===================================================================================================================
10074.5s	3047	Epoch 76/100 summary: loss_train=0.42018, acc_train=86.79%, loss_val=2.42, acc_val=46.38% (best: 47.95% @ epoch 67)
10074.5s	3048	===================================================================================================================
10074.5s	3049	Starting epoch 77/100, learning_rate=0.1
10075.8s	3050	[train]  epoch 77/100,  batch 1/188,  loss_train=0.54756,  acc_train=85.94%
10081.4s	3051	[train]  epoch 77/100,  batch 11/188,  loss_train=0.31537,  acc_train=89.06%
10087.1s	3052	[train]  epoch 77/100,  batch 21/188,  loss_train=0.39594,  acc_train=84.38%
10092.7s	3053	[train]  epoch 77/100,  batch 31/188,  loss_train=0.48137,  acc_train=79.69%
10098.3s	3054	[train]  epoch 77/100,  batch 41/188,  loss_train=0.27608,  acc_train=93.75%
10104.1s	3055	[train]  epoch 77/100,  batch 51/188,  loss_train=0.27507,  acc_train=89.06%
10109.6s	3056	[train]  epoch 77/100,  batch 61/188,  loss_train=0.22618,  acc_train=95.31%
10115.2s	3057	[train]  epoch 77/100,  batch 71/188,  loss_train=0.31888,  acc_train=87.50%
10120.9s	3058	[train]  epoch 77/100,  batch 81/188,  loss_train=0.52208,  acc_train=90.62%
10126.5s	3059	[train]  epoch 77/100,  batch 91/188,  loss_train=0.30447,  acc_train=90.62%
10132.1s	3060	[train]  epoch 77/100,  batch 101/188,  loss_train=0.31436,  acc_train=92.19%
10138.0s	3061	[train]  epoch 77/100,  batch 111/188,  loss_train=0.23566,  acc_train=93.75%
10143.4s	3062	[train]  epoch 77/100,  batch 121/188,  loss_train=0.50237,  acc_train=87.50%
10149.1s	3063	[train]  epoch 77/100,  batch 131/188,  loss_train=0.45138,  acc_train=87.50%
10154.7s	3064	[train]  epoch 77/100,  batch 141/188,  loss_train=0.49145,  acc_train=85.94%
10160.4s	3065	[train]  epoch 77/100,  batch 151/188,  loss_train=0.29975,  acc_train=89.06%
10166.0s	3066	[train]  epoch 77/100,  batch 161/188,  loss_train=0.43883,  acc_train=85.94%
10171.9s	3067	[train]  epoch 77/100,  batch 171/188,  loss_train=0.36331,  acc_train=89.06%
10177.2s	3068	[train]  epoch 77/100,  batch 181/188,  loss_train=0.35848,  acc_train=85.94%
10181.8s	3069	[ val ]  epoch 77/100,  batch 1/135,  loss_val=3.85319,  acc_val=28.12%
10183.6s	3070	[ val ]  epoch 77/100,  batch 11/135,  loss_val=0.86440,  acc_val=75.00%
10185.5s	3071	[ val ]  epoch 77/100,  batch 21/135,  loss_val=1.83459,  acc_val=54.69%
10187.3s	3072	[ val ]  epoch 77/100,  batch 31/135,  loss_val=3.20358,  acc_val=34.38%
10189.1s	3073	[ val ]  epoch 77/100,  batch 41/135,  loss_val=1.57208,  acc_val=64.06%
10190.9s	3074	[ val ]  epoch 77/100,  batch 51/135,  loss_val=2.38116,  acc_val=53.12%
10192.6s	3075	[ val ]  epoch 77/100,  batch 61/135,  loss_val=3.97669,  acc_val=29.69%
10194.4s	3076	[ val ]  epoch 77/100,  batch 71/135,  loss_val=3.28688,  acc_val=29.69%
10196.2s	3077	[ val ]  epoch 77/100,  batch 81/135,  loss_val=3.53584,  acc_val=35.94%
10197.9s	3078	[ val ]  epoch 77/100,  batch 91/135,  loss_val=3.15418,  acc_val=26.56%
10199.7s	3079	[ val ]  epoch 77/100,  batch 101/135,  loss_val=1.40870,  acc_val=56.25%
10201.5s	3080	[ val ]  epoch 77/100,  batch 111/135,  loss_val=2.78286,  acc_val=35.94%
10203.5s	3081	[ val ]  epoch 77/100,  batch 121/135,  loss_val=1.53666,  acc_val=53.12%
10205.0s	3082	[ val ]  epoch 77/100,  batch 131/135,  loss_val=2.23883,  acc_val=45.31%
10205.6s	3083	===================================================================================================================
10205.6s	3084	Epoch 77/100 summary: loss_train=0.38743, acc_train=88.08%, loss_val=2.59, acc_val=44.44% (best: 47.95% @ epoch 67)
10205.6s	3085	===================================================================================================================
10205.6s	3086	Starting epoch 78/100, learning_rate=0.1
10206.8s	3087	[train]  epoch 78/100,  batch 1/188,  loss_train=0.34988,  acc_train=87.50%
10212.5s	3088	[train]  epoch 78/100,  batch 11/188,  loss_train=0.38234,  acc_train=90.62%
10218.1s	3089	[train]  epoch 78/100,  batch 21/188,  loss_train=0.54189,  acc_train=82.81%
10223.7s	3090	[train]  epoch 78/100,  batch 31/188,  loss_train=0.27024,  acc_train=92.19%
10229.3s	3091	[train]  epoch 78/100,  batch 41/188,  loss_train=0.47337,  acc_train=87.50%
10235.2s	3092	[train]  epoch 78/100,  batch 51/188,  loss_train=0.24386,  acc_train=95.31%
10240.6s	3093	[train]  epoch 78/100,  batch 61/188,  loss_train=0.38396,  acc_train=89.06%
10246.2s	3094	[train]  epoch 78/100,  batch 71/188,  loss_train=0.29846,  acc_train=90.62%
10251.8s	3095	[train]  epoch 78/100,  batch 81/188,  loss_train=0.31910,  acc_train=92.19%
10257.5s	3096	[train]  epoch 78/100,  batch 91/188,  loss_train=0.33437,  acc_train=85.94%
10263.1s	3097	[train]  epoch 78/100,  batch 101/188,  loss_train=0.29940,  acc_train=87.50%
10269.0s	3098	[train]  epoch 78/100,  batch 111/188,  loss_train=0.50924,  acc_train=78.12%
10274.3s	3099	[train]  epoch 78/100,  batch 121/188,  loss_train=0.35696,  acc_train=87.50%
10280.0s	3100	[train]  epoch 78/100,  batch 131/188,  loss_train=0.35652,  acc_train=84.38%
10285.6s	3101	[train]  epoch 78/100,  batch 141/188,  loss_train=0.34666,  acc_train=92.19%
10291.2s	3102	[train]  epoch 78/100,  batch 151/188,  loss_train=0.75294,  acc_train=71.88%
10296.9s	3103	[train]  epoch 78/100,  batch 161/188,  loss_train=0.48634,  acc_train=85.94%
10302.7s	3104	[train]  epoch 78/100,  batch 171/188,  loss_train=0.56943,  acc_train=81.25%
10308.1s	3105	[train]  epoch 78/100,  batch 181/188,  loss_train=0.58509,  acc_train=81.25%
10312.9s	3106	[ val ]  epoch 78/100,  batch 1/135,  loss_val=4.27607,  acc_val=29.69%
10314.8s	3107	[ val ]  epoch 78/100,  batch 11/135,  loss_val=2.75137,  acc_val=42.19%
10316.6s	3108	[ val ]  epoch 78/100,  batch 21/135,  loss_val=2.24918,  acc_val=34.38%
10318.4s	3109	[ val ]  epoch 78/100,  batch 31/135,  loss_val=1.32624,  acc_val=68.75%
10320.2s	3110	[ val ]  epoch 78/100,  batch 41/135,  loss_val=2.57625,  acc_val=51.56%
10321.9s	3111	[ val ]  epoch 78/100,  batch 51/135,  loss_val=2.27126,  acc_val=48.44%
10323.7s	3112	[ val ]  epoch 78/100,  batch 61/135,  loss_val=2.20720,  acc_val=56.25%
10325.5s	3113	[ val ]  epoch 78/100,  batch 71/135,  loss_val=2.43678,  acc_val=45.31%
10327.2s	3114	[ val ]  epoch 78/100,  batch 81/135,  loss_val=2.82893,  acc_val=50.00%
10329.0s	3115	[ val ]  epoch 78/100,  batch 91/135,  loss_val=2.67112,  acc_val=42.19%
10330.9s	3116	[ val ]  epoch 78/100,  batch 101/135,  loss_val=0.96464,  acc_val=75.00%
10332.6s	3117	[ val ]  epoch 78/100,  batch 111/135,  loss_val=3.53431,  acc_val=26.56%
10334.7s	3118	[ val ]  epoch 78/100,  batch 121/135,  loss_val=3.97427,  acc_val=28.12%
10336.2s	3119	[ val ]  epoch 78/100,  batch 131/135,  loss_val=3.45487,  acc_val=42.19%
10336.8s	3120	===================================================================================================================
10336.8s	3121	Epoch 78/100 summary: loss_train=0.37998, acc_train=88.26%, loss_val=2.45, acc_val=46.40% (best: 47.95% @ epoch 67)
10336.8s	3122	===================================================================================================================
10336.8s	3123	Starting epoch 79/100, learning_rate=0.1
10338.0s	3124	[train]  epoch 79/100,  batch 1/188,  loss_train=0.25615,  acc_train=92.19%
10343.7s	3125	[train]  epoch 79/100,  batch 11/188,  loss_train=0.41609,  acc_train=85.94%
10349.4s	3126	[train]  epoch 79/100,  batch 21/188,  loss_train=0.32258,  acc_train=87.50%
10355.0s	3127	[train]  epoch 79/100,  batch 31/188,  loss_train=0.28793,  acc_train=92.19%
10360.6s	3128	[train]  epoch 79/100,  batch 41/188,  loss_train=0.29685,  acc_train=92.19%
10366.5s	3129	[train]  epoch 79/100,  batch 51/188,  loss_train=0.21644,  acc_train=96.88%
10371.9s	3130	[train]  epoch 79/100,  batch 61/188,  loss_train=0.33668,  acc_train=90.62%
10377.6s	3131	[train]  epoch 79/100,  batch 71/188,  loss_train=0.41000,  acc_train=89.06%
10383.2s	3132	[train]  epoch 79/100,  batch 81/188,  loss_train=0.39231,  acc_train=89.06%
10388.8s	3133	[train]  epoch 79/100,  batch 91/188,  loss_train=0.38997,  acc_train=87.50%
10394.5s	3134	[train]  epoch 79/100,  batch 101/188,  loss_train=0.39654,  acc_train=92.19%
10400.4s	3135	[train]  epoch 79/100,  batch 111/188,  loss_train=0.60190,  acc_train=78.12%
10405.7s	3136	[train]  epoch 79/100,  batch 121/188,  loss_train=0.45067,  acc_train=81.25%
10411.4s	3137	[train]  epoch 79/100,  batch 131/188,  loss_train=0.37594,  acc_train=95.31%
10417.0s	3138	[train]  epoch 79/100,  batch 141/188,  loss_train=0.48154,  acc_train=81.25%
10422.6s	3139	[train]  epoch 79/100,  batch 151/188,  loss_train=0.48328,  acc_train=84.38%
10428.2s	3140	[train]  epoch 79/100,  batch 161/188,  loss_train=0.34854,  acc_train=92.19%
10434.1s	3141	[train]  epoch 79/100,  batch 171/188,  loss_train=0.56110,  acc_train=81.25%
10439.5s	3142	[train]  epoch 79/100,  batch 181/188,  loss_train=0.43827,  acc_train=89.06%
10444.1s	3143	[ val ]  epoch 79/100,  batch 1/135,  loss_val=2.97802,  acc_val=40.62%
10445.9s	3144	[ val ]  epoch 79/100,  batch 11/135,  loss_val=3.93069,  acc_val=23.44%
10447.7s	3145	[ val ]  epoch 79/100,  batch 21/135,  loss_val=2.45416,  acc_val=50.00%
10449.5s	3146	[ val ]  epoch 79/100,  batch 31/135,  loss_val=2.82054,  acc_val=45.31%
10451.3s	3147	[ val ]  epoch 79/100,  batch 41/135,  loss_val=1.16605,  acc_val=68.75%
10453.1s	3148	[ val ]  epoch 79/100,  batch 51/135,  loss_val=3.19829,  acc_val=45.31%
10454.9s	3149	[ val ]  epoch 79/100,  batch 61/135,  loss_val=2.70086,  acc_val=37.50%
10456.7s	3150	[ val ]  epoch 79/100,  batch 71/135,  loss_val=2.68703,  acc_val=45.31%
10458.5s	3151	[ val ]  epoch 79/100,  batch 81/135,  loss_val=3.73209,  acc_val=43.75%
10460.2s	3152	[ val ]  epoch 79/100,  batch 91/135,  loss_val=4.20716,  acc_val=23.44%
10462.0s	3153	[ val ]  epoch 79/100,  batch 101/135,  loss_val=1.77802,  acc_val=50.00%
10463.8s	3154	[ val ]  epoch 79/100,  batch 111/135,  loss_val=3.75695,  acc_val=20.31%
10465.9s	3155	[ val ]  epoch 79/100,  batch 121/135,  loss_val=1.96935,  acc_val=40.62%
10467.4s	3156	[ val ]  epoch 79/100,  batch 131/135,  loss_val=2.39442,  acc_val=48.44%
10468.0s	3157	===================================================================================================================
10468.0s	3158	Epoch 79/100 summary: loss_train=0.41079, acc_train=87.22%, loss_val=2.62, acc_val=44.49% (best: 47.95% @ epoch 67)
10468.0s	3159	===================================================================================================================
10468.0s	3160	Starting epoch 80/100, learning_rate=0.1
10469.2s	3161	[train]  epoch 80/100,  batch 1/188,  loss_train=0.37130,  acc_train=90.62%
10474.9s	3162	[train]  epoch 80/100,  batch 11/188,  loss_train=0.34457,  acc_train=92.19%
10480.5s	3163	[train]  epoch 80/100,  batch 21/188,  loss_train=0.31184,  acc_train=90.62%
10486.2s	3164	[train]  epoch 80/100,  batch 31/188,  loss_train=0.45644,  acc_train=81.25%
10491.8s	3165	[train]  epoch 80/100,  batch 41/188,  loss_train=0.31900,  acc_train=90.62%
10497.7s	3166	[train]  epoch 80/100,  batch 51/188,  loss_train=0.35409,  acc_train=85.94%
10503.1s	3167	[train]  epoch 80/100,  batch 61/188,  loss_train=0.25599,  acc_train=95.31%
10508.7s	3168	[train]  epoch 80/100,  batch 71/188,  loss_train=0.62805,  acc_train=82.81%
10514.4s	3169	[train]  epoch 80/100,  batch 81/188,  loss_train=0.26350,  acc_train=93.75%
10520.0s	3170	[train]  epoch 80/100,  batch 91/188,  loss_train=0.30317,  acc_train=92.19%
10525.7s	3171	[train]  epoch 80/100,  batch 101/188,  loss_train=0.28331,  acc_train=92.19%
10531.7s	3172	[train]  epoch 80/100,  batch 111/188,  loss_train=0.22031,  acc_train=96.88%
10537.1s	3173	[train]  epoch 80/100,  batch 121/188,  loss_train=0.49044,  acc_train=85.94%
10542.7s	3174	[train]  epoch 80/100,  batch 131/188,  loss_train=0.49917,  acc_train=79.69%
10548.4s	3175	[train]  epoch 80/100,  batch 141/188,  loss_train=0.42814,  acc_train=87.50%
10554.0s	3176	[train]  epoch 80/100,  batch 151/188,  loss_train=0.48924,  acc_train=85.94%
10559.6s	3177	[train]  epoch 80/100,  batch 161/188,  loss_train=0.49588,  acc_train=87.50%
10565.5s	3178	[train]  epoch 80/100,  batch 171/188,  loss_train=0.37567,  acc_train=87.50%
10570.9s	3179	[train]  epoch 80/100,  batch 181/188,  loss_train=0.35522,  acc_train=87.50%
10575.5s	3180	[ val ]  epoch 80/100,  batch 1/135,  loss_val=2.11752,  acc_val=57.81%
10577.3s	3181	[ val ]  epoch 80/100,  batch 11/135,  loss_val=2.19009,  acc_val=48.44%
10579.1s	3182	[ val ]  epoch 80/100,  batch 21/135,  loss_val=3.25241,  acc_val=32.81%
10580.9s	3183	[ val ]  epoch 80/100,  batch 31/135,  loss_val=1.12994,  acc_val=67.19%
10582.7s	3184	[ val ]  epoch 80/100,  batch 41/135,  loss_val=2.01196,  acc_val=51.56%
10584.5s	3185	[ val ]  epoch 80/100,  batch 51/135,  loss_val=3.84742,  acc_val=29.69%
10586.3s	3186	[ val ]  epoch 80/100,  batch 61/135,  loss_val=2.43436,  acc_val=53.12%
10588.1s	3187	[ val ]  epoch 80/100,  batch 71/135,  loss_val=2.05336,  acc_val=43.75%
10589.9s	3188	[ val ]  epoch 80/100,  batch 81/135,  loss_val=2.87233,  acc_val=45.31%
10591.7s	3189	[ val ]  epoch 80/100,  batch 91/135,  loss_val=3.29180,  acc_val=32.81%
10593.5s	3190	[ val ]  epoch 80/100,  batch 101/135,  loss_val=1.01828,  acc_val=70.31%
10595.3s	3191	[ val ]  epoch 80/100,  batch 111/135,  loss_val=3.11840,  acc_val=35.94%
10597.4s	3192	[ val ]  epoch 80/100,  batch 121/135,  loss_val=1.29665,  acc_val=53.12%
10598.8s	3193	[ val ]  epoch 80/100,  batch 131/135,  loss_val=3.42321,  acc_val=43.75%
10599.4s	3194	===================================================================================================================
10599.4s	3195	Epoch 80/100 summary: loss_train=0.40085, acc_train=87.67%, loss_val=2.66, acc_val=43.66% (best: 47.95% @ epoch 67)
10599.4s	3196	===================================================================================================================
10599.4s	3197	Starting epoch 81/100, learning_rate=0.1
10600.7s	3198	[train]  epoch 81/100,  batch 1/188,  loss_train=0.41484,  acc_train=87.50%
10606.4s	3199	[train]  epoch 81/100,  batch 11/188,  loss_train=0.39125,  acc_train=90.62%
10612.1s	3200	[train]  epoch 81/100,  batch 21/188,  loss_train=0.34118,  acc_train=87.50%
10617.7s	3201	[train]  epoch 81/100,  batch 31/188,  loss_train=0.34106,  acc_train=90.62%
10623.3s	3202	[train]  epoch 81/100,  batch 41/188,  loss_train=0.39765,  acc_train=85.94%
10629.2s	3203	[train]  epoch 81/100,  batch 51/188,  loss_train=0.35436,  acc_train=92.19%
10634.6s	3204	[train]  epoch 81/100,  batch 61/188,  loss_train=0.24238,  acc_train=93.75%
10640.2s	3205	[train]  epoch 81/100,  batch 71/188,  loss_train=0.35562,  acc_train=85.94%
10645.8s	3206	[train]  epoch 81/100,  batch 81/188,  loss_train=0.26465,  acc_train=92.19%
10651.4s	3207	[train]  epoch 81/100,  batch 91/188,  loss_train=0.42714,  acc_train=89.06%
10657.0s	3208	[train]  epoch 81/100,  batch 101/188,  loss_train=0.46646,  acc_train=82.81%
10663.0s	3209	[train]  epoch 81/100,  batch 111/188,  loss_train=0.32208,  acc_train=85.94%
10668.3s	3210	[train]  epoch 81/100,  batch 121/188,  loss_train=0.24462,  acc_train=93.75%
10673.9s	3211	[train]  epoch 81/100,  batch 131/188,  loss_train=0.44160,  acc_train=84.38%
10679.6s	3212	[train]  epoch 81/100,  batch 141/188,  loss_train=0.33794,  acc_train=85.94%
10685.2s	3213	[train]  epoch 81/100,  batch 151/188,  loss_train=0.24359,  acc_train=92.19%
10690.8s	3214	[train]  epoch 81/100,  batch 161/188,  loss_train=0.32548,  acc_train=87.50%
10696.7s	3215	[train]  epoch 81/100,  batch 171/188,  loss_train=0.28241,  acc_train=89.06%
10702.1s	3216	[train]  epoch 81/100,  batch 181/188,  loss_train=0.41336,  acc_train=82.81%
10706.8s	3217	[ val ]  epoch 81/100,  batch 1/135,  loss_val=4.96904,  acc_val=25.00%
10708.6s	3218	[ val ]  epoch 81/100,  batch 11/135,  loss_val=3.18950,  acc_val=37.50%
10710.4s	3219	[ val ]  epoch 81/100,  batch 21/135,  loss_val=3.00586,  acc_val=34.38%
10712.2s	3220	[ val ]  epoch 81/100,  batch 31/135,  loss_val=0.99496,  acc_val=78.12%
10713.9s	3221	[ val ]  epoch 81/100,  batch 41/135,  loss_val=2.77807,  acc_val=42.19%
10715.7s	3222	[ val ]  epoch 81/100,  batch 51/135,  loss_val=3.28059,  acc_val=35.94%
10717.5s	3223	[ val ]  epoch 81/100,  batch 61/135,  loss_val=4.58369,  acc_val=21.88%
10719.3s	3224	[ val ]  epoch 81/100,  batch 71/135,  loss_val=2.27582,  acc_val=45.31%
10721.1s	3225	[ val ]  epoch 81/100,  batch 81/135,  loss_val=4.32048,  acc_val=45.31%
10722.9s	3226	[ val ]  epoch 81/100,  batch 91/135,  loss_val=3.89463,  acc_val=37.50%
10724.7s	3227	[ val ]  epoch 81/100,  batch 101/135,  loss_val=2.07886,  acc_val=45.31%
10726.5s	3228	[ val ]  epoch 81/100,  batch 111/135,  loss_val=2.75965,  acc_val=32.81%
10728.7s	3229	[ val ]  epoch 81/100,  batch 121/135,  loss_val=1.61974,  acc_val=57.81%
10730.2s	3230	[ val ]  epoch 81/100,  batch 131/135,  loss_val=4.08523,  acc_val=40.62%
10730.8s	3231	===================================================================================================================
10730.8s	3232	Epoch 81/100 summary: loss_train=0.37170, acc_train=88.55%, loss_val=2.59, acc_val=46.13% (best: 47.95% @ epoch 67)
10730.8s	3233	===================================================================================================================
10730.8s	3234	Starting epoch 82/100, learning_rate=0.1
10732.0s	3235	[train]  epoch 82/100,  batch 1/188,  loss_train=0.31770,  acc_train=89.06%
10737.7s	3236	[train]  epoch 82/100,  batch 11/188,  loss_train=0.53003,  acc_train=85.94%
10743.3s	3237	[train]  epoch 82/100,  batch 21/188,  loss_train=0.33391,  acc_train=90.62%
10748.9s	3238	[train]  epoch 82/100,  batch 31/188,  loss_train=0.72470,  acc_train=79.69%
10754.5s	3239	[train]  epoch 82/100,  batch 41/188,  loss_train=0.24278,  acc_train=92.19%
10760.6s	3240	[train]  epoch 82/100,  batch 51/188,  loss_train=0.25160,  acc_train=95.31%
10765.8s	3241	[train]  epoch 82/100,  batch 61/188,  loss_train=0.34249,  acc_train=92.19%
10771.4s	3242	[train]  epoch 82/100,  batch 71/188,  loss_train=0.50799,  acc_train=81.25%
10777.1s	3243	[train]  epoch 82/100,  batch 81/188,  loss_train=0.39758,  acc_train=89.06%
10782.8s	3244	[train]  epoch 82/100,  batch 91/188,  loss_train=0.37222,  acc_train=87.50%
10788.4s	3245	[train]  epoch 82/100,  batch 101/188,  loss_train=0.37594,  acc_train=85.94%
10794.2s	3246	[train]  epoch 82/100,  batch 111/188,  loss_train=0.32223,  acc_train=89.06%
10799.7s	3247	[train]  epoch 82/100,  batch 121/188,  loss_train=0.53141,  acc_train=84.38%
10805.3s	3248	[train]  epoch 82/100,  batch 131/188,  loss_train=0.44281,  acc_train=84.38%
10810.9s	3249	[train]  epoch 82/100,  batch 141/188,  loss_train=0.51730,  acc_train=82.81%
10816.6s	3250	[train]  epoch 82/100,  batch 151/188,  loss_train=0.43135,  acc_train=82.81%
10822.3s	3251	[train]  epoch 82/100,  batch 161/188,  loss_train=0.25071,  acc_train=93.75%
10828.1s	3252	[train]  epoch 82/100,  batch 171/188,  loss_train=0.47635,  acc_train=84.38%
10833.6s	3253	[train]  epoch 82/100,  batch 181/188,  loss_train=0.59457,  acc_train=79.69%
10838.1s	3254	[ val ]  epoch 82/100,  batch 1/135,  loss_val=2.90383,  acc_val=39.06%
10840.0s	3255	[ val ]  epoch 82/100,  batch 11/135,  loss_val=2.34430,  acc_val=51.56%
10841.8s	3256	[ val ]  epoch 82/100,  batch 21/135,  loss_val=3.73625,  acc_val=26.56%
10843.5s	3257	[ val ]  epoch 82/100,  batch 31/135,  loss_val=1.72113,  acc_val=65.62%
10845.3s	3258	[ val ]  epoch 82/100,  batch 41/135,  loss_val=2.08736,  acc_val=54.69%
10847.1s	3259	[ val ]  epoch 82/100,  batch 51/135,  loss_val=1.89157,  acc_val=54.69%
10848.9s	3260	[ val ]  epoch 82/100,  batch 61/135,  loss_val=4.01230,  acc_val=26.56%
10850.6s	3261	[ val ]  epoch 82/100,  batch 71/135,  loss_val=2.22612,  acc_val=43.75%
10852.4s	3262	[ val ]  epoch 82/100,  batch 81/135,  loss_val=2.66828,  acc_val=48.44%
10854.3s	3263	[ val ]  epoch 82/100,  batch 91/135,  loss_val=3.47838,  acc_val=26.56%
10856.2s	3264	[ val ]  epoch 82/100,  batch 101/135,  loss_val=1.15216,  acc_val=73.44%
10858.0s	3265	[ val ]  epoch 82/100,  batch 111/135,  loss_val=2.42604,  acc_val=48.44%
10860.1s	3266	[ val ]  epoch 82/100,  batch 121/135,  loss_val=0.49678,  acc_val=87.50%
10861.6s	3267	[ val ]  epoch 82/100,  batch 131/135,  loss_val=3.26787,  acc_val=35.94%
10862.1s	3268	===================================================================================================================
10862.1s	3269	Epoch 82/100 summary: loss_train=0.39850, acc_train=87.37%, loss_val=2.49, acc_val=45.97% (best: 47.95% @ epoch 67)
10862.1s	3270	===================================================================================================================
10862.1s	3271	Starting epoch 83/100, learning_rate=0.1
10863.4s	3272	[train]  epoch 83/100,  batch 1/188,  loss_train=0.23582,  acc_train=90.62%
10869.1s	3273	[train]  epoch 83/100,  batch 11/188,  loss_train=0.34912,  acc_train=85.94%
10874.7s	3274	[train]  epoch 83/100,  batch 21/188,  loss_train=0.54028,  acc_train=85.94%
10880.4s	3275	[train]  epoch 83/100,  batch 31/188,  loss_train=0.55699,  acc_train=79.69%
10886.0s	3276	[train]  epoch 83/100,  batch 41/188,  loss_train=0.37801,  acc_train=84.38%
10892.0s	3277	[train]  epoch 83/100,  batch 51/188,  loss_train=0.36088,  acc_train=87.50%
10897.3s	3278	[train]  epoch 83/100,  batch 61/188,  loss_train=0.31539,  acc_train=93.75%
10902.9s	3279	[train]  epoch 83/100,  batch 71/188,  loss_train=0.27944,  acc_train=87.50%
10908.6s	3280	[train]  epoch 83/100,  batch 81/188,  loss_train=0.32439,  acc_train=92.19%
10914.2s	3281	[train]  epoch 83/100,  batch 91/188,  loss_train=0.42159,  acc_train=82.81%
10919.9s	3282	[train]  epoch 83/100,  batch 101/188,  loss_train=0.32224,  acc_train=92.19%
10925.7s	3283	[train]  epoch 83/100,  batch 111/188,  loss_train=0.36687,  acc_train=90.62%
10931.1s	3284	[train]  epoch 83/100,  batch 121/188,  loss_train=0.40353,  acc_train=87.50%
10936.7s	3285	[train]  epoch 83/100,  batch 131/188,  loss_train=0.45857,  acc_train=81.25%
10942.3s	3286	[train]  epoch 83/100,  batch 141/188,  loss_train=0.39236,  acc_train=87.50%
10947.9s	3287	[train]  epoch 83/100,  batch 151/188,  loss_train=0.27943,  acc_train=90.62%
10953.6s	3288	[train]  epoch 83/100,  batch 161/188,  loss_train=0.39083,  acc_train=89.06%
10959.3s	3289	[train]  epoch 83/100,  batch 171/188,  loss_train=0.37425,  acc_train=85.94%
10964.8s	3290	[train]  epoch 83/100,  batch 181/188,  loss_train=0.36315,  acc_train=87.50%
10969.5s	3291	[ val ]  epoch 83/100,  batch 1/135,  loss_val=3.37741,  acc_val=28.12%
10971.3s	3292	[ val ]  epoch 83/100,  batch 11/135,  loss_val=2.79969,  acc_val=50.00%
10973.1s	3293	[ val ]  epoch 83/100,  batch 21/135,  loss_val=2.46842,  acc_val=46.88%
10974.9s	3294	[ val ]  epoch 83/100,  batch 31/135,  loss_val=2.19633,  acc_val=54.69%
10976.7s	3295	[ val ]  epoch 83/100,  batch 41/135,  loss_val=1.55891,  acc_val=71.88%
10978.5s	3296	[ val ]  epoch 83/100,  batch 51/135,  loss_val=2.65903,  acc_val=48.44%
10980.3s	3297	[ val ]  epoch 83/100,  batch 61/135,  loss_val=3.21557,  acc_val=35.94%
10982.2s	3298	[ val ]  epoch 83/100,  batch 71/135,  loss_val=2.41403,  acc_val=48.44%
10984.1s	3299	[ val ]  epoch 83/100,  batch 81/135,  loss_val=2.10926,  acc_val=65.62%
10985.9s	3300	[ val ]  epoch 83/100,  batch 91/135,  loss_val=2.87364,  acc_val=45.31%
10987.7s	3301	[ val ]  epoch 83/100,  batch 101/135,  loss_val=0.93875,  acc_val=79.69%
10989.8s	3302	[ val ]  epoch 83/100,  batch 111/135,  loss_val=3.41771,  acc_val=39.06%
10991.3s	3303	[ val ]  epoch 83/100,  batch 121/135,  loss_val=1.12718,  acc_val=65.62%
10993.0s	3304	[ val ]  epoch 83/100,  batch 131/135,  loss_val=3.50107,  acc_val=35.94%
10993.6s	3305	===================================================================================================================
10993.6s	3306	Epoch 83/100 summary: loss_train=0.37100, acc_train=88.56%, loss_val=2.36, acc_val=48.65% (best: 48.65% @ epoch 83)
10993.6s	3307	===================================================================================================================
10993.6s	3308	Starting epoch 84/100, learning_rate=0.1
10994.9s	3309	[train]  epoch 84/100,  batch 1/188,  loss_train=0.26936,  acc_train=90.62%
11000.5s	3310	[train]  epoch 84/100,  batch 11/188,  loss_train=0.40360,  acc_train=87.50%
11006.2s	3311	[train]  epoch 84/100,  batch 21/188,  loss_train=0.39069,  acc_train=85.94%
11011.8s	3312	[train]  epoch 84/100,  batch 31/188,  loss_train=0.33448,  acc_train=92.19%
11017.5s	3313	[train]  epoch 84/100,  batch 41/188,  loss_train=0.35772,  acc_train=90.62%
11023.2s	3314	[train]  epoch 84/100,  batch 51/188,  loss_train=0.34363,  acc_train=90.62%
11028.7s	3315	[train]  epoch 84/100,  batch 61/188,  loss_train=0.31182,  acc_train=89.06%
11034.3s	3316	[train]  epoch 84/100,  batch 71/188,  loss_train=0.40346,  acc_train=89.06%
11040.0s	3317	[train]  epoch 84/100,  batch 81/188,  loss_train=0.28324,  acc_train=90.62%
11045.6s	3318	[train]  epoch 84/100,  batch 91/188,  loss_train=0.49501,  acc_train=85.94%
11051.3s	3319	[train]  epoch 84/100,  batch 101/188,  loss_train=0.37980,  acc_train=85.94%
11057.1s	3320	[train]  epoch 84/100,  batch 111/188,  loss_train=0.43348,  acc_train=85.94%
11062.6s	3321	[train]  epoch 84/100,  batch 121/188,  loss_train=0.20108,  acc_train=96.88%
11068.2s	3322	[train]  epoch 84/100,  batch 131/188,  loss_train=0.41752,  acc_train=87.50%
11073.8s	3323	[train]  epoch 84/100,  batch 141/188,  loss_train=0.31804,  acc_train=89.06%
11079.5s	3324	[train]  epoch 84/100,  batch 151/188,  loss_train=0.51467,  acc_train=85.94%
11085.1s	3325	[train]  epoch 84/100,  batch 161/188,  loss_train=0.72937,  acc_train=78.12%
11091.0s	3326	[train]  epoch 84/100,  batch 171/188,  loss_train=0.46749,  acc_train=85.94%
11096.3s	3327	[train]  epoch 84/100,  batch 181/188,  loss_train=0.52340,  acc_train=85.94%
11101.0s	3328	[ val ]  epoch 84/100,  batch 1/135,  loss_val=2.99649,  acc_val=42.19%
11102.8s	3329	[ val ]  epoch 84/100,  batch 11/135,  loss_val=1.94894,  acc_val=54.69%
11104.6s	3330	[ val ]  epoch 84/100,  batch 21/135,  loss_val=1.93025,  acc_val=50.00%
11106.4s	3331	[ val ]  epoch 84/100,  batch 31/135,  loss_val=1.82847,  acc_val=57.81%
11108.2s	3332	[ val ]  epoch 84/100,  batch 41/135,  loss_val=2.06705,  acc_val=50.00%
11110.0s	3333	[ val ]  epoch 84/100,  batch 51/135,  loss_val=2.15429,  acc_val=53.12%
11111.9s	3334	[ val ]  epoch 84/100,  batch 61/135,  loss_val=2.58477,  acc_val=53.12%
11113.7s	3335	[ val ]  epoch 84/100,  batch 71/135,  loss_val=4.06710,  acc_val=17.19%
11115.5s	3336	[ val ]  epoch 84/100,  batch 81/135,  loss_val=2.48510,  acc_val=53.12%
11117.3s	3337	[ val ]  epoch 84/100,  batch 91/135,  loss_val=4.15754,  acc_val=21.88%
11119.1s	3338	[ val ]  epoch 84/100,  batch 101/135,  loss_val=2.05011,  acc_val=48.44%
11120.9s	3339	[ val ]  epoch 84/100,  batch 111/135,  loss_val=3.15135,  acc_val=28.12%
11123.0s	3340	[ val ]  epoch 84/100,  batch 121/135,  loss_val=0.93536,  acc_val=70.31%
11124.4s	3341	[ val ]  epoch 84/100,  batch 131/135,  loss_val=2.67911,  acc_val=43.75%
11125.0s	3342	===================================================================================================================
11125.0s	3343	Epoch 84/100 summary: loss_train=0.36106, acc_train=89.06%, loss_val=2.79, acc_val=44.07% (best: 48.65% @ epoch 83)
11125.0s	3344	===================================================================================================================
11125.0s	3345	Starting epoch 85/100, learning_rate=0.1
11126.3s	3346	[train]  epoch 85/100,  batch 1/188,  loss_train=0.27013,  acc_train=93.75%
11131.9s	3347	[train]  epoch 85/100,  batch 11/188,  loss_train=0.36097,  acc_train=89.06%
11137.5s	3348	[train]  epoch 85/100,  batch 21/188,  loss_train=0.24728,  acc_train=93.75%
11143.2s	3349	[train]  epoch 85/100,  batch 31/188,  loss_train=0.37329,  acc_train=85.94%
11148.8s	3350	[train]  epoch 85/100,  batch 41/188,  loss_train=0.31989,  acc_train=92.19%
11154.8s	3351	[train]  epoch 85/100,  batch 51/188,  loss_train=0.45501,  acc_train=87.50%
11160.1s	3352	[train]  epoch 85/100,  batch 61/188,  loss_train=0.38202,  acc_train=92.19%
11165.8s	3353	[train]  epoch 85/100,  batch 71/188,  loss_train=0.32304,  acc_train=90.62%
11171.4s	3354	[train]  epoch 85/100,  batch 81/188,  loss_train=0.29928,  acc_train=95.31%
11177.1s	3355	[train]  epoch 85/100,  batch 91/188,  loss_train=0.29200,  acc_train=92.19%
11182.7s	3356	[train]  epoch 85/100,  batch 101/188,  loss_train=0.39580,  acc_train=89.06%
11188.6s	3357	[train]  epoch 85/100,  batch 111/188,  loss_train=0.37238,  acc_train=87.50%
11193.9s	3358	[train]  epoch 85/100,  batch 121/188,  loss_train=0.28816,  acc_train=95.31%
11199.5s	3359	[train]  epoch 85/100,  batch 131/188,  loss_train=0.34267,  acc_train=89.06%
11205.2s	3360	[train]  epoch 85/100,  batch 141/188,  loss_train=0.37364,  acc_train=87.50%
11210.9s	3361	[train]  epoch 85/100,  batch 151/188,  loss_train=0.36038,  acc_train=89.06%
11216.5s	3362	[train]  epoch 85/100,  batch 161/188,  loss_train=0.35424,  acc_train=90.62%
11222.5s	3363	[train]  epoch 85/100,  batch 171/188,  loss_train=0.47377,  acc_train=87.50%
11227.8s	3364	[train]  epoch 85/100,  batch 181/188,  loss_train=0.32721,  acc_train=92.19%
11232.4s	3365	[ val ]  epoch 85/100,  batch 1/135,  loss_val=3.34484,  acc_val=42.19%
11234.2s	3366	[ val ]  epoch 85/100,  batch 11/135,  loss_val=0.98818,  acc_val=73.44%
11236.0s	3367	[ val ]  epoch 85/100,  batch 21/135,  loss_val=1.70376,  acc_val=53.12%
11237.8s	3368	[ val ]  epoch 85/100,  batch 31/135,  loss_val=1.72937,  acc_val=65.62%
11239.8s	3369	[ val ]  epoch 85/100,  batch 41/135,  loss_val=1.57361,  acc_val=67.19%
11241.6s	3370	[ val ]  epoch 85/100,  batch 51/135,  loss_val=2.25585,  acc_val=53.12%
11243.4s	3371	[ val ]  epoch 85/100,  batch 61/135,  loss_val=2.33752,  acc_val=50.00%
11245.1s	3372	[ val ]  epoch 85/100,  batch 71/135,  loss_val=3.26158,  acc_val=34.38%
11246.9s	3373	[ val ]  epoch 85/100,  batch 81/135,  loss_val=2.70012,  acc_val=54.69%
11248.7s	3374	[ val ]  epoch 85/100,  batch 91/135,  loss_val=3.10081,  acc_val=37.50%
11250.5s	3375	[ val ]  epoch 85/100,  batch 101/135,  loss_val=1.96328,  acc_val=39.06%
11252.3s	3376	[ val ]  epoch 85/100,  batch 111/135,  loss_val=2.12702,  acc_val=50.00%
11254.3s	3377	[ val ]  epoch 85/100,  batch 121/135,  loss_val=1.44367,  acc_val=64.06%
11255.9s	3378	[ val ]  epoch 85/100,  batch 131/135,  loss_val=3.39138,  acc_val=31.25%
11256.5s	3379	===================================================================================================================
11256.5s	3380	Epoch 85/100 summary: loss_train=0.35793, acc_train=89.04%, loss_val=2.48, acc_val=46.61% (best: 48.65% @ epoch 83)
11256.5s	3381	===================================================================================================================
11256.5s	3382	Starting epoch 86/100, learning_rate=0.1
11257.7s	3383	[train]  epoch 86/100,  batch 1/188,  loss_train=0.34178,  acc_train=90.62%
11263.3s	3384	[train]  epoch 86/100,  batch 11/188,  loss_train=0.22591,  acc_train=93.75%
11269.0s	3385	[train]  epoch 86/100,  batch 21/188,  loss_train=0.29565,  acc_train=90.62%
11274.6s	3386	[train]  epoch 86/100,  batch 31/188,  loss_train=0.24876,  acc_train=93.75%
11280.2s	3387	[train]  epoch 86/100,  batch 41/188,  loss_train=0.37244,  acc_train=89.06%
11286.1s	3388	[train]  epoch 86/100,  batch 51/188,  loss_train=0.27016,  acc_train=92.19%
11291.5s	3389	[train]  epoch 86/100,  batch 61/188,  loss_train=0.29406,  acc_train=90.62%
11297.2s	3390	[train]  epoch 86/100,  batch 71/188,  loss_train=0.46444,  acc_train=85.94%
11302.8s	3391	[train]  epoch 86/100,  batch 81/188,  loss_train=0.28935,  acc_train=95.31%
11308.5s	3392	[train]  epoch 86/100,  batch 91/188,  loss_train=0.27467,  acc_train=90.62%
11314.1s	3393	[train]  epoch 86/100,  batch 101/188,  loss_train=0.29364,  acc_train=93.75%
11320.0s	3394	[train]  epoch 86/100,  batch 111/188,  loss_train=0.34352,  acc_train=90.62%
11325.3s	3395	[train]  epoch 86/100,  batch 121/188,  loss_train=0.27743,  acc_train=92.19%
11331.0s	3396	[train]  epoch 86/100,  batch 131/188,  loss_train=0.32832,  acc_train=90.62%
11336.6s	3397	[train]  epoch 86/100,  batch 141/188,  loss_train=0.49934,  acc_train=85.94%
11342.2s	3398	[train]  epoch 86/100,  batch 151/188,  loss_train=0.31877,  acc_train=89.06%
11347.9s	3399	[train]  epoch 86/100,  batch 161/188,  loss_train=0.43798,  acc_train=85.94%
11353.8s	3400	[train]  epoch 86/100,  batch 171/188,  loss_train=0.24155,  acc_train=95.31%
11359.2s	3401	[train]  epoch 86/100,  batch 181/188,  loss_train=0.41477,  acc_train=87.50%
11363.8s	3402	[ val ]  epoch 86/100,  batch 1/135,  loss_val=2.76244,  acc_val=37.50%
11365.7s	3403	[ val ]  epoch 86/100,  batch 11/135,  loss_val=2.29586,  acc_val=50.00%
11367.7s	3404	[ val ]  epoch 86/100,  batch 21/135,  loss_val=2.65328,  acc_val=40.62%
11369.5s	3405	[ val ]  epoch 86/100,  batch 31/135,  loss_val=2.07961,  acc_val=57.81%
11371.3s	3406	[ val ]  epoch 86/100,  batch 41/135,  loss_val=2.52083,  acc_val=46.88%
11373.0s	3407	[ val ]  epoch 86/100,  batch 51/135,  loss_val=2.46086,  acc_val=51.56%
11374.8s	3408	[ val ]  epoch 86/100,  batch 61/135,  loss_val=2.55802,  acc_val=46.88%
11376.6s	3409	[ val ]  epoch 86/100,  batch 71/135,  loss_val=1.65856,  acc_val=51.56%
11378.4s	3410	[ val ]  epoch 86/100,  batch 81/135,  loss_val=3.60038,  acc_val=39.06%
11380.2s	3411	[ val ]  epoch 86/100,  batch 91/135,  loss_val=3.75639,  acc_val=29.69%
11382.0s	3412	[ val ]  epoch 86/100,  batch 101/135,  loss_val=1.87628,  acc_val=51.56%
11383.8s	3413	[ val ]  epoch 86/100,  batch 111/135,  loss_val=2.49279,  acc_val=51.56%
11385.9s	3414	[ val ]  epoch 86/100,  batch 121/135,  loss_val=1.62476,  acc_val=53.12%
11387.4s	3415	[ val ]  epoch 86/100,  batch 131/135,  loss_val=2.48693,  acc_val=39.06%
11388.0s	3416	===================================================================================================================
11388.0s	3417	Epoch 86/100 summary: loss_train=0.35449, acc_train=89.20%, loss_val=2.37, acc_val=47.81% (best: 48.65% @ epoch 83)
11388.0s	3418	===================================================================================================================
11388.0s	3419	Starting epoch 87/100, learning_rate=0.1
11389.2s	3420	[train]  epoch 87/100,  batch 1/188,  loss_train=0.39695,  acc_train=84.38%
11394.8s	3421	[train]  epoch 87/100,  batch 11/188,  loss_train=0.28770,  acc_train=90.62%
11400.5s	3422	[train]  epoch 87/100,  batch 21/188,  loss_train=0.22295,  acc_train=92.19%
11406.2s	3423	[train]  epoch 87/100,  batch 31/188,  loss_train=0.29815,  acc_train=87.50%
11411.8s	3424	[train]  epoch 87/100,  batch 41/188,  loss_train=0.44940,  acc_train=85.94%
11417.7s	3425	[train]  epoch 87/100,  batch 51/188,  loss_train=0.17116,  acc_train=96.88%
11423.1s	3426	[train]  epoch 87/100,  batch 61/188,  loss_train=0.31060,  acc_train=90.62%
11428.7s	3427	[train]  epoch 87/100,  batch 71/188,  loss_train=0.38834,  acc_train=92.19%
11434.3s	3428	[train]  epoch 87/100,  batch 81/188,  loss_train=0.40411,  acc_train=89.06%
11439.9s	3429	[train]  epoch 87/100,  batch 91/188,  loss_train=0.25840,  acc_train=92.19%
11445.5s	3430	[train]  epoch 87/100,  batch 101/188,  loss_train=0.42871,  acc_train=85.94%
11451.4s	3431	[train]  epoch 87/100,  batch 111/188,  loss_train=0.29854,  acc_train=90.62%
11456.8s	3432	[train]  epoch 87/100,  batch 121/188,  loss_train=0.21958,  acc_train=96.88%
11462.5s	3433	[train]  epoch 87/100,  batch 131/188,  loss_train=0.39281,  acc_train=84.38%
11468.1s	3434	[train]  epoch 87/100,  batch 141/188,  loss_train=0.38332,  acc_train=90.62%
11473.7s	3435	[train]  epoch 87/100,  batch 151/188,  loss_train=0.29780,  acc_train=92.19%
11479.3s	3436	[train]  epoch 87/100,  batch 161/188,  loss_train=0.36750,  acc_train=90.62%
11485.2s	3437	[train]  epoch 87/100,  batch 171/188,  loss_train=0.25483,  acc_train=89.06%
11490.5s	3438	[train]  epoch 87/100,  batch 181/188,  loss_train=0.50147,  acc_train=85.94%
11495.1s	3439	[ val ]  epoch 87/100,  batch 1/135,  loss_val=3.07122,  acc_val=35.94%
11496.9s	3440	[ val ]  epoch 87/100,  batch 11/135,  loss_val=2.60628,  acc_val=50.00%
11498.7s	3441	[ val ]  epoch 87/100,  batch 21/135,  loss_val=2.07374,  acc_val=46.88%
11500.5s	3442	[ val ]  epoch 87/100,  batch 31/135,  loss_val=1.67528,  acc_val=60.94%
11502.3s	3443	[ val ]  epoch 87/100,  batch 41/135,  loss_val=1.82197,  acc_val=62.50%
11504.0s	3444	[ val ]  epoch 87/100,  batch 51/135,  loss_val=2.45235,  acc_val=46.88%
11505.8s	3445	[ val ]  epoch 87/100,  batch 61/135,  loss_val=3.07014,  acc_val=39.06%
11507.6s	3446	[ val ]  epoch 87/100,  batch 71/135,  loss_val=4.11460,  acc_val=14.06%
11509.4s	3447	[ val ]  epoch 87/100,  batch 81/135,  loss_val=3.32239,  acc_val=46.88%
11511.2s	3448	[ val ]  epoch 87/100,  batch 91/135,  loss_val=3.99635,  acc_val=21.88%
11513.0s	3449	[ val ]  epoch 87/100,  batch 101/135,  loss_val=2.09741,  acc_val=50.00%
11514.7s	3450	[ val ]  epoch 87/100,  batch 111/135,  loss_val=2.67632,  acc_val=45.31%
11516.8s	3451	[ val ]  epoch 87/100,  batch 121/135,  loss_val=1.31913,  acc_val=71.88%
11518.3s	3452	[ val ]  epoch 87/100,  batch 131/135,  loss_val=3.32062,  acc_val=34.38%
11518.9s	3453	===================================================================================================================
11518.9s	3454	Epoch 87/100 summary: loss_train=0.33458, acc_train=89.79%, loss_val=2.53, acc_val=46.02% (best: 48.65% @ epoch 83)
11518.9s	3455	===================================================================================================================
11518.9s	3456	Starting epoch 88/100, learning_rate=0.1
11520.1s	3457	[train]  epoch 88/100,  batch 1/188,  loss_train=0.18089,  acc_train=98.44%
11525.8s	3458	[train]  epoch 88/100,  batch 11/188,  loss_train=0.21291,  acc_train=93.75%
11531.4s	3459	[train]  epoch 88/100,  batch 21/188,  loss_train=0.31226,  acc_train=92.19%
11537.1s	3460	[train]  epoch 88/100,  batch 31/188,  loss_train=0.29661,  acc_train=90.62%
11542.7s	3461	[train]  epoch 88/100,  batch 41/188,  loss_train=0.26659,  acc_train=93.75%
11548.6s	3462	[train]  epoch 88/100,  batch 51/188,  loss_train=0.49063,  acc_train=85.94%
11553.9s	3463	[train]  epoch 88/100,  batch 61/188,  loss_train=0.21603,  acc_train=93.75%
11559.6s	3464	[train]  epoch 88/100,  batch 71/188,  loss_train=0.28782,  acc_train=92.19%
11565.2s	3465	[train]  epoch 88/100,  batch 81/188,  loss_train=0.26855,  acc_train=89.06%
11570.8s	3466	[train]  epoch 88/100,  batch 91/188,  loss_train=0.20797,  acc_train=93.75%
11576.4s	3467	[train]  epoch 88/100,  batch 101/188,  loss_train=0.24135,  acc_train=93.75%
11582.4s	3468	[train]  epoch 88/100,  batch 111/188,  loss_train=0.26048,  acc_train=90.62%
11587.8s	3469	[train]  epoch 88/100,  batch 121/188,  loss_train=0.27308,  acc_train=87.50%
11593.4s	3470	[train]  epoch 88/100,  batch 131/188,  loss_train=0.26528,  acc_train=93.75%
11599.0s	3471	[train]  epoch 88/100,  batch 141/188,  loss_train=0.21555,  acc_train=92.19%
11604.7s	3472	[train]  epoch 88/100,  batch 151/188,  loss_train=0.29230,  acc_train=87.50%
11610.3s	3473	[train]  epoch 88/100,  batch 161/188,  loss_train=0.33641,  acc_train=90.62%
11616.2s	3474	[train]  epoch 88/100,  batch 171/188,  loss_train=0.60655,  acc_train=79.69%
11621.5s	3475	[train]  epoch 88/100,  batch 181/188,  loss_train=0.46098,  acc_train=85.94%
11626.2s	3476	[ val ]  epoch 88/100,  batch 1/135,  loss_val=3.55167,  acc_val=21.88%
11628.0s	3477	[ val ]  epoch 88/100,  batch 11/135,  loss_val=3.20236,  acc_val=43.75%
11629.8s	3478	[ val ]  epoch 88/100,  batch 21/135,  loss_val=2.36929,  acc_val=43.75%
11631.6s	3479	[ val ]  epoch 88/100,  batch 31/135,  loss_val=1.47324,  acc_val=68.75%
11633.4s	3480	[ val ]  epoch 88/100,  batch 41/135,  loss_val=1.58656,  acc_val=68.75%
11635.2s	3481	[ val ]  epoch 88/100,  batch 51/135,  loss_val=2.53951,  acc_val=56.25%
11637.0s	3482	[ val ]  epoch 88/100,  batch 61/135,  loss_val=3.15204,  acc_val=40.62%
11638.8s	3483	[ val ]  epoch 88/100,  batch 71/135,  loss_val=3.05308,  acc_val=42.19%
11640.6s	3484	[ val ]  epoch 88/100,  batch 81/135,  loss_val=3.36738,  acc_val=50.00%
11642.4s	3485	[ val ]  epoch 88/100,  batch 91/135,  loss_val=4.26343,  acc_val=25.00%
11644.2s	3486	[ val ]  epoch 88/100,  batch 101/135,  loss_val=0.87886,  acc_val=65.62%
11646.0s	3487	[ val ]  epoch 88/100,  batch 111/135,  loss_val=1.40481,  acc_val=65.62%
11648.1s	3488	[ val ]  epoch 88/100,  batch 121/135,  loss_val=2.47245,  acc_val=29.69%
11649.5s	3489	[ val ]  epoch 88/100,  batch 131/135,  loss_val=2.34136,  acc_val=46.88%
11650.1s	3490	===================================================================================================================
11650.1s	3491	Epoch 88/100 summary: loss_train=0.31409, acc_train=90.36%, loss_val=2.53, acc_val=46.35% (best: 48.65% @ epoch 83)
11650.1s	3492	===================================================================================================================
11650.1s	3493	Starting epoch 89/100, learning_rate=0.1
11651.4s	3494	[train]  epoch 89/100,  batch 1/188,  loss_train=0.34203,  acc_train=90.62%
11657.1s	3495	[train]  epoch 89/100,  batch 11/188,  loss_train=0.16929,  acc_train=95.31%
11662.7s	3496	[train]  epoch 89/100,  batch 21/188,  loss_train=0.44372,  acc_train=89.06%
11668.4s	3497	[train]  epoch 89/100,  batch 31/188,  loss_train=0.45392,  acc_train=85.94%
11674.0s	3498	[train]  epoch 89/100,  batch 41/188,  loss_train=0.29793,  acc_train=90.62%
11679.8s	3499	[train]  epoch 89/100,  batch 51/188,  loss_train=0.26211,  acc_train=93.75%
11685.3s	3500	[train]  epoch 89/100,  batch 61/188,  loss_train=0.39753,  acc_train=89.06%
11690.9s	3501	[train]  epoch 89/100,  batch 71/188,  loss_train=0.35190,  acc_train=87.50%
11696.6s	3502	[train]  epoch 89/100,  batch 81/188,  loss_train=0.13642,  acc_train=98.44%
11702.2s	3503	[train]  epoch 89/100,  batch 91/188,  loss_train=0.28078,  acc_train=87.50%
11707.8s	3504	[train]  epoch 89/100,  batch 101/188,  loss_train=0.31607,  acc_train=90.62%
11713.7s	3505	[train]  epoch 89/100,  batch 111/188,  loss_train=0.22653,  acc_train=93.75%
11719.2s	3506	[train]  epoch 89/100,  batch 121/188,  loss_train=0.30549,  acc_train=93.75%
11724.8s	3507	[train]  epoch 89/100,  batch 131/188,  loss_train=0.39310,  acc_train=90.62%
11730.4s	3508	[train]  epoch 89/100,  batch 141/188,  loss_train=0.35713,  acc_train=85.94%
11736.0s	3509	[train]  epoch 89/100,  batch 151/188,  loss_train=0.36952,  acc_train=87.50%
11741.7s	3510	[train]  epoch 89/100,  batch 161/188,  loss_train=0.29468,  acc_train=93.75%
11747.6s	3511	[train]  epoch 89/100,  batch 171/188,  loss_train=0.25096,  acc_train=92.19%
11752.9s	3512	[train]  epoch 89/100,  batch 181/188,  loss_train=0.26479,  acc_train=93.75%
11757.6s	3513	[ val ]  epoch 89/100,  batch 1/135,  loss_val=4.62591,  acc_val=26.56%
11759.4s	3514	[ val ]  epoch 89/100,  batch 11/135,  loss_val=4.20368,  acc_val=29.69%
11761.2s	3515	[ val ]  epoch 89/100,  batch 21/135,  loss_val=3.59012,  acc_val=26.56%
11763.0s	3516	[ val ]  epoch 89/100,  batch 31/135,  loss_val=2.50682,  acc_val=46.88%
11764.8s	3517	[ val ]  epoch 89/100,  batch 41/135,  loss_val=3.08643,  acc_val=37.50%
11766.6s	3518	[ val ]  epoch 89/100,  batch 51/135,  loss_val=2.16503,  acc_val=57.81%
11768.4s	3519	[ val ]  epoch 89/100,  batch 61/135,  loss_val=2.51679,  acc_val=53.12%
11770.2s	3520	[ val ]  epoch 89/100,  batch 71/135,  loss_val=3.18257,  acc_val=29.69%
11772.0s	3521	[ val ]  epoch 89/100,  batch 81/135,  loss_val=2.50265,  acc_val=56.25%
11773.7s	3522	[ val ]  epoch 89/100,  batch 91/135,  loss_val=3.40240,  acc_val=31.25%
11775.5s	3523	[ val ]  epoch 89/100,  batch 101/135,  loss_val=1.56153,  acc_val=54.69%
11777.3s	3524	[ val ]  epoch 89/100,  batch 111/135,  loss_val=3.69591,  acc_val=26.56%
11779.6s	3525	[ val ]  epoch 89/100,  batch 121/135,  loss_val=2.29612,  acc_val=46.88%
11780.9s	3526	[ val ]  epoch 89/100,  batch 131/135,  loss_val=4.10151,  acc_val=29.69%
11781.5s	3527	===================================================================================================================
11781.5s	3528	Epoch 89/100 summary: loss_train=0.31129, acc_train=90.72%, loss_val=2.76, acc_val=43.92% (best: 48.65% @ epoch 83)
11781.5s	3529	===================================================================================================================
11781.5s	3530	Starting epoch 90/100, learning_rate=0.1
11782.7s	3531	[train]  epoch 90/100,  batch 1/188,  loss_train=0.15068,  acc_train=96.88%
11788.4s	3532	[train]  epoch 90/100,  batch 11/188,  loss_train=0.33354,  acc_train=90.62%
11794.0s	3533	[train]  epoch 90/100,  batch 21/188,  loss_train=0.20102,  acc_train=95.31%
11799.6s	3534	[train]  epoch 90/100,  batch 31/188,  loss_train=0.24037,  acc_train=93.75%
11805.2s	3535	[train]  epoch 90/100,  batch 41/188,  loss_train=0.35576,  acc_train=89.06%
11811.1s	3536	[train]  epoch 90/100,  batch 51/188,  loss_train=0.32914,  acc_train=85.94%
11816.5s	3537	[train]  epoch 90/100,  batch 61/188,  loss_train=0.43719,  acc_train=84.38%
11822.1s	3538	[train]  epoch 90/100,  batch 71/188,  loss_train=0.57194,  acc_train=82.81%
11827.7s	3539	[train]  epoch 90/100,  batch 81/188,  loss_train=0.29940,  acc_train=90.62%
11833.3s	3540	[train]  epoch 90/100,  batch 91/188,  loss_train=0.33064,  acc_train=93.75%
11838.9s	3541	[train]  epoch 90/100,  batch 101/188,  loss_train=0.52858,  acc_train=84.38%
11844.8s	3542	[train]  epoch 90/100,  batch 111/188,  loss_train=0.56068,  acc_train=78.12%
11850.2s	3543	[train]  epoch 90/100,  batch 121/188,  loss_train=0.33414,  acc_train=90.62%
11855.9s	3544	[train]  epoch 90/100,  batch 131/188,  loss_train=0.43414,  acc_train=84.38%
11861.5s	3545	[train]  epoch 90/100,  batch 141/188,  loss_train=0.31432,  acc_train=89.06%
11867.1s	3546	[train]  epoch 90/100,  batch 151/188,  loss_train=0.35604,  acc_train=90.62%
11872.8s	3547	[train]  epoch 90/100,  batch 161/188,  loss_train=0.24509,  acc_train=90.62%
11878.7s	3548	[train]  epoch 90/100,  batch 171/188,  loss_train=0.30534,  acc_train=90.62%
11884.1s	3549	[train]  epoch 90/100,  batch 181/188,  loss_train=0.52109,  acc_train=78.12%
11888.6s	3550	[ val ]  epoch 90/100,  batch 1/135,  loss_val=2.02507,  acc_val=57.81%
11890.4s	3551	[ val ]  epoch 90/100,  batch 11/135,  loss_val=2.85845,  acc_val=37.50%
11892.2s	3552	[ val ]  epoch 90/100,  batch 21/135,  loss_val=3.50722,  acc_val=31.25%
11893.9s	3553	[ val ]  epoch 90/100,  batch 31/135,  loss_val=1.37466,  acc_val=65.62%
11895.7s	3554	[ val ]  epoch 90/100,  batch 41/135,  loss_val=2.04051,  acc_val=62.50%
11897.5s	3555	[ val ]  epoch 90/100,  batch 51/135,  loss_val=2.54585,  acc_val=43.75%
11899.3s	3556	[ val ]  epoch 90/100,  batch 61/135,  loss_val=3.89449,  acc_val=34.38%
11901.1s	3557	[ val ]  epoch 90/100,  batch 71/135,  loss_val=4.68931,  acc_val=15.62%
11902.8s	3558	[ val ]  epoch 90/100,  batch 81/135,  loss_val=3.17179,  acc_val=45.31%
11904.6s	3559	[ val ]  epoch 90/100,  batch 91/135,  loss_val=3.14752,  acc_val=37.50%
11906.4s	3560	[ val ]  epoch 90/100,  batch 101/135,  loss_val=1.34352,  acc_val=65.62%
11908.3s	3561	[ val ]  epoch 90/100,  batch 111/135,  loss_val=2.38154,  acc_val=42.19%
11910.4s	3562	[ val ]  epoch 90/100,  batch 121/135,  loss_val=3.46717,  acc_val=26.56%
11911.8s	3563	[ val ]  epoch 90/100,  batch 131/135,  loss_val=2.76418,  acc_val=45.31%
11912.5s	3564	===================================================================================================================
11912.5s	3565	Epoch 90/100 summary: loss_train=0.37252, acc_train=88.03%, loss_val=2.64, acc_val=44.68% (best: 48.65% @ epoch 83)
11912.5s	3566	===================================================================================================================
11912.5s	3567	Starting epoch 91/100, learning_rate=0.1
11913.7s	3568	[train]  epoch 91/100,  batch 1/188,  loss_train=0.39838,  acc_train=81.25%
11919.4s	3569	[train]  epoch 91/100,  batch 11/188,  loss_train=0.31142,  acc_train=90.62%
11925.0s	3570	[train]  epoch 91/100,  batch 21/188,  loss_train=0.35835,  acc_train=92.19%
11930.6s	3571	[train]  epoch 91/100,  batch 31/188,  loss_train=0.31401,  acc_train=90.62%
11936.2s	3572	[train]  epoch 91/100,  batch 41/188,  loss_train=0.29763,  acc_train=92.19%
11942.3s	3573	[train]  epoch 91/100,  batch 51/188,  loss_train=0.29547,  acc_train=90.62%
11947.5s	3574	[train]  epoch 91/100,  batch 61/188,  loss_train=0.27616,  acc_train=90.62%
11953.1s	3575	[train]  epoch 91/100,  batch 71/188,  loss_train=0.40953,  acc_train=85.94%
11958.8s	3576	[train]  epoch 91/100,  batch 81/188,  loss_train=0.45938,  acc_train=85.94%
11964.4s	3577	[train]  epoch 91/100,  batch 91/188,  loss_train=0.44134,  acc_train=89.06%
11970.0s	3578	[train]  epoch 91/100,  batch 101/188,  loss_train=0.27167,  acc_train=90.62%
11976.0s	3579	[train]  epoch 91/100,  batch 111/188,  loss_train=0.18216,  acc_train=98.44%
11981.3s	3580	[train]  epoch 91/100,  batch 121/188,  loss_train=0.26433,  acc_train=90.62%
11987.0s	3581	[train]  epoch 91/100,  batch 131/188,  loss_train=0.32497,  acc_train=89.06%
11992.6s	3582	[train]  epoch 91/100,  batch 141/188,  loss_train=0.23641,  acc_train=90.62%
11998.2s	3583	[train]  epoch 91/100,  batch 151/188,  loss_train=0.30370,  acc_train=90.62%
12003.9s	3584	[train]  epoch 91/100,  batch 161/188,  loss_train=0.27989,  acc_train=92.19%
12009.8s	3585	[train]  epoch 91/100,  batch 171/188,  loss_train=0.47389,  acc_train=84.38%
12015.1s	3586	[train]  epoch 91/100,  batch 181/188,  loss_train=0.23362,  acc_train=95.31%
12019.8s	3587	[ val ]  epoch 91/100,  batch 1/135,  loss_val=3.68044,  acc_val=35.94%
12021.6s	3588	[ val ]  epoch 91/100,  batch 11/135,  loss_val=4.13907,  acc_val=28.12%
12023.4s	3589	[ val ]  epoch 91/100,  batch 21/135,  loss_val=1.47926,  acc_val=64.06%
12025.2s	3590	[ val ]  epoch 91/100,  batch 31/135,  loss_val=1.11850,  acc_val=78.12%
12027.0s	3591	[ val ]  epoch 91/100,  batch 41/135,  loss_val=2.40843,  acc_val=50.00%
12028.8s	3592	[ val ]  epoch 91/100,  batch 51/135,  loss_val=3.55706,  acc_val=39.06%
12030.5s	3593	[ val ]  epoch 91/100,  batch 61/135,  loss_val=2.79737,  acc_val=46.88%
12032.3s	3594	[ val ]  epoch 91/100,  batch 71/135,  loss_val=2.00792,  acc_val=46.88%
12034.1s	3595	[ val ]  epoch 91/100,  batch 81/135,  loss_val=2.95200,  acc_val=53.12%
12036.1s	3596	[ val ]  epoch 91/100,  batch 91/135,  loss_val=4.50418,  acc_val=20.31%
12037.9s	3597	[ val ]  epoch 91/100,  batch 101/135,  loss_val=1.29720,  acc_val=67.19%
12039.7s	3598	[ val ]  epoch 91/100,  batch 111/135,  loss_val=3.37635,  acc_val=32.81%
12041.9s	3599	[ val ]  epoch 91/100,  batch 121/135,  loss_val=1.91234,  acc_val=53.12%
12043.3s	3600	[ val ]  epoch 91/100,  batch 131/135,  loss_val=3.06377,  acc_val=35.94%
12043.9s	3601	===================================================================================================================
12043.9s	3602	Epoch 91/100 summary: loss_train=0.32687, acc_train=90.26%, loss_val=2.53, acc_val=47.37% (best: 48.65% @ epoch 83)
12043.9s	3603	===================================================================================================================
12043.9s	3604	Starting epoch 92/100, learning_rate=0.1
12045.2s	3605	[train]  epoch 92/100,  batch 1/188,  loss_train=0.26713,  acc_train=93.75%
12050.8s	3606	[train]  epoch 92/100,  batch 11/188,  loss_train=0.28790,  acc_train=92.19%
12056.4s	3607	[train]  epoch 92/100,  batch 21/188,  loss_train=0.29907,  acc_train=93.75%
12062.1s	3608	[train]  epoch 92/100,  batch 31/188,  loss_train=0.45309,  acc_train=84.38%
12067.7s	3609	[train]  epoch 92/100,  batch 41/188,  loss_train=0.31482,  acc_train=89.06%
12073.6s	3610	[train]  epoch 92/100,  batch 51/188,  loss_train=0.36077,  acc_train=89.06%
12079.0s	3611	[train]  epoch 92/100,  batch 61/188,  loss_train=0.20669,  acc_train=96.88%
12084.6s	3612	[train]  epoch 92/100,  batch 71/188,  loss_train=0.25737,  acc_train=90.62%
12090.2s	3613	[train]  epoch 92/100,  batch 81/188,  loss_train=0.28323,  acc_train=89.06%
12095.9s	3614	[train]  epoch 92/100,  batch 91/188,  loss_train=0.44959,  acc_train=85.94%
12101.5s	3615	[train]  epoch 92/100,  batch 101/188,  loss_train=0.33615,  acc_train=90.62%
12107.4s	3616	[train]  epoch 92/100,  batch 111/188,  loss_train=0.31800,  acc_train=90.62%
12112.8s	3617	[train]  epoch 92/100,  batch 121/188,  loss_train=0.35525,  acc_train=87.50%
12118.4s	3618	[train]  epoch 92/100,  batch 131/188,  loss_train=0.24134,  acc_train=92.19%
12124.0s	3619	[train]  epoch 92/100,  batch 141/188,  loss_train=0.37498,  acc_train=82.81%
12129.6s	3620	[train]  epoch 92/100,  batch 151/188,  loss_train=0.27788,  acc_train=90.62%
12135.3s	3621	[train]  epoch 92/100,  batch 161/188,  loss_train=0.54987,  acc_train=79.69%
12141.3s	3622	[train]  epoch 92/100,  batch 171/188,  loss_train=0.53600,  acc_train=82.81%
12146.5s	3623	[train]  epoch 92/100,  batch 181/188,  loss_train=0.34286,  acc_train=90.62%
12151.2s	3624	[ val ]  epoch 92/100,  batch 1/135,  loss_val=3.74492,  acc_val=34.38%
12153.0s	3625	[ val ]  epoch 92/100,  batch 11/135,  loss_val=1.72207,  acc_val=60.94%
12154.8s	3626	[ val ]  epoch 92/100,  batch 21/135,  loss_val=2.55613,  acc_val=35.94%
12156.6s	3627	[ val ]  epoch 92/100,  batch 31/135,  loss_val=1.26688,  acc_val=71.88%
12158.4s	3628	[ val ]  epoch 92/100,  batch 41/135,  loss_val=2.23588,  acc_val=50.00%
12160.2s	3629	[ val ]  epoch 92/100,  batch 51/135,  loss_val=2.49957,  acc_val=48.44%
12162.0s	3630	[ val ]  epoch 92/100,  batch 61/135,  loss_val=2.75075,  acc_val=50.00%
12163.9s	3631	[ val ]  epoch 92/100,  batch 71/135,  loss_val=2.42127,  acc_val=46.88%
12165.7s	3632	[ val ]  epoch 92/100,  batch 81/135,  loss_val=2.32308,  acc_val=56.25%
12167.5s	3633	[ val ]  epoch 92/100,  batch 91/135,  loss_val=3.28329,  acc_val=32.81%
12169.3s	3634	[ val ]  epoch 92/100,  batch 101/135,  loss_val=0.78474,  acc_val=81.25%
12171.1s	3635	[ val ]  epoch 92/100,  batch 111/135,  loss_val=3.59593,  acc_val=25.00%
12173.2s	3636	[ val ]  epoch 92/100,  batch 121/135,  loss_val=2.12548,  acc_val=45.31%
12174.6s	3637	[ val ]  epoch 92/100,  batch 131/135,  loss_val=3.00365,  acc_val=39.06%
12175.2s	3638	===================================================================================================================
12175.2s	3639	Epoch 92/100 summary: loss_train=0.30831, acc_train=90.42%, loss_val=2.48, acc_val=46.78% (best: 48.65% @ epoch 83)
12175.2s	3640	===================================================================================================================
12175.2s	3641	Starting epoch 93/100, learning_rate=0.1
12176.5s	3642	[train]  epoch 93/100,  batch 1/188,  loss_train=0.17089,  acc_train=96.88%
12182.1s	3643	[train]  epoch 93/100,  batch 11/188,  loss_train=0.22389,  acc_train=96.88%
12187.8s	3644	[train]  epoch 93/100,  batch 21/188,  loss_train=0.20847,  acc_train=93.75%
12193.4s	3645	[train]  epoch 93/100,  batch 31/188,  loss_train=0.38494,  acc_train=87.50%
12199.1s	3646	[train]  epoch 93/100,  batch 41/188,  loss_train=0.27112,  acc_train=93.75%
12205.0s	3647	[train]  epoch 93/100,  batch 51/188,  loss_train=0.34216,  acc_train=87.50%
12210.3s	3648	[train]  epoch 93/100,  batch 61/188,  loss_train=0.39049,  acc_train=85.94%
12216.0s	3649	[train]  epoch 93/100,  batch 71/188,  loss_train=0.52131,  acc_train=84.38%
12221.6s	3650	[train]  epoch 93/100,  batch 81/188,  loss_train=0.28128,  acc_train=90.62%
12227.2s	3651	[train]  epoch 93/100,  batch 91/188,  loss_train=0.19510,  acc_train=93.75%
12232.9s	3652	[train]  epoch 93/100,  batch 101/188,  loss_train=0.23446,  acc_train=93.75%
12238.8s	3653	[train]  epoch 93/100,  batch 111/188,  loss_train=0.34858,  acc_train=87.50%
12244.2s	3654	[train]  epoch 93/100,  batch 121/188,  loss_train=0.30955,  acc_train=93.75%
12249.8s	3655	[train]  epoch 93/100,  batch 131/188,  loss_train=0.47972,  acc_train=81.25%
12255.4s	3656	[train]  epoch 93/100,  batch 141/188,  loss_train=0.36957,  acc_train=87.50%
12261.1s	3657	[train]  epoch 93/100,  batch 151/188,  loss_train=0.22886,  acc_train=95.31%
12266.7s	3658	[train]  epoch 93/100,  batch 161/188,  loss_train=0.36850,  acc_train=85.94%
12272.7s	3659	[train]  epoch 93/100,  batch 171/188,  loss_train=0.44839,  acc_train=87.50%
12277.9s	3660	[train]  epoch 93/100,  batch 181/188,  loss_train=0.38727,  acc_train=87.50%
12282.5s	3661	[ val ]  epoch 93/100,  batch 1/135,  loss_val=2.13290,  acc_val=48.44%
12284.3s	3662	[ val ]  epoch 93/100,  batch 11/135,  loss_val=1.78582,  acc_val=64.06%
12286.1s	3663	[ val ]  epoch 93/100,  batch 21/135,  loss_val=2.44712,  acc_val=35.94%
12287.9s	3664	[ val ]  epoch 93/100,  batch 31/135,  loss_val=0.97502,  acc_val=76.56%
12289.7s	3665	[ val ]  epoch 93/100,  batch 41/135,  loss_val=2.62863,  acc_val=45.31%
12291.6s	3666	[ val ]  epoch 93/100,  batch 51/135,  loss_val=1.71899,  acc_val=62.50%
12293.4s	3667	[ val ]  epoch 93/100,  batch 61/135,  loss_val=2.68000,  acc_val=48.44%
12295.2s	3668	[ val ]  epoch 93/100,  batch 71/135,  loss_val=3.10385,  acc_val=37.50%
12297.0s	3669	[ val ]  epoch 93/100,  batch 81/135,  loss_val=2.62000,  acc_val=53.12%
12298.8s	3670	[ val ]  epoch 93/100,  batch 91/135,  loss_val=3.73262,  acc_val=35.94%
12300.6s	3671	[ val ]  epoch 93/100,  batch 101/135,  loss_val=0.72953,  acc_val=82.81%
12302.4s	3672	[ val ]  epoch 93/100,  batch 111/135,  loss_val=5.04485,  acc_val=10.94%
12304.5s	3673	[ val ]  epoch 93/100,  batch 121/135,  loss_val=1.63709,  acc_val=59.38%
12305.9s	3674	[ val ]  epoch 93/100,  batch 131/135,  loss_val=1.69261,  acc_val=56.25%
12306.6s	3675	===================================================================================================================
12306.6s	3676	Epoch 93/100 summary: loss_train=0.36399, acc_train=88.42%, loss_val=2.62, acc_val=44.13% (best: 48.65% @ epoch 83)
12306.6s	3677	===================================================================================================================
12306.6s	3678	Starting epoch 94/100, learning_rate=0.1
12307.8s	3679	[train]  epoch 94/100,  batch 1/188,  loss_train=0.33093,  acc_train=90.62%
12313.5s	3680	[train]  epoch 94/100,  batch 11/188,  loss_train=0.18985,  acc_train=95.31%
12319.2s	3681	[train]  epoch 94/100,  batch 21/188,  loss_train=0.25934,  acc_train=93.75%
12324.8s	3682	[train]  epoch 94/100,  batch 31/188,  loss_train=0.29942,  acc_train=90.62%
12330.4s	3683	[train]  epoch 94/100,  batch 41/188,  loss_train=0.23136,  acc_train=95.31%
12336.4s	3684	[train]  epoch 94/100,  batch 51/188,  loss_train=0.22811,  acc_train=92.19%
12341.7s	3685	[train]  epoch 94/100,  batch 61/188,  loss_train=0.27343,  acc_train=90.62%
12347.3s	3686	[train]  epoch 94/100,  batch 71/188,  loss_train=0.27254,  acc_train=93.75%
12352.9s	3687	[train]  epoch 94/100,  batch 81/188,  loss_train=0.26262,  acc_train=96.88%
12358.6s	3688	[train]  epoch 94/100,  batch 91/188,  loss_train=0.38446,  acc_train=89.06%
12364.2s	3689	[train]  epoch 94/100,  batch 101/188,  loss_train=0.33012,  acc_train=89.06%
12370.1s	3690	[train]  epoch 94/100,  batch 111/188,  loss_train=0.32798,  acc_train=89.06%
12375.5s	3691	[train]  epoch 94/100,  batch 121/188,  loss_train=0.27638,  acc_train=92.19%
12381.2s	3692	[train]  epoch 94/100,  batch 131/188,  loss_train=0.22398,  acc_train=90.62%
12386.9s	3693	[train]  epoch 94/100,  batch 141/188,  loss_train=0.45268,  acc_train=85.94%
12392.5s	3694	[train]  epoch 94/100,  batch 151/188,  loss_train=0.35674,  acc_train=87.50%
12398.2s	3695	[train]  epoch 94/100,  batch 161/188,  loss_train=0.44021,  acc_train=85.94%
12404.2s	3696	[train]  epoch 94/100,  batch 171/188,  loss_train=0.52765,  acc_train=79.69%
12409.4s	3697	[train]  epoch 94/100,  batch 181/188,  loss_train=0.45366,  acc_train=85.94%
12414.1s	3698	[ val ]  epoch 94/100,  batch 1/135,  loss_val=3.91633,  acc_val=32.81%
12415.9s	3699	[ val ]  epoch 94/100,  batch 11/135,  loss_val=1.50300,  acc_val=62.50%
12417.7s	3700	[ val ]  epoch 94/100,  batch 21/135,  loss_val=2.94140,  acc_val=34.38%
12419.5s	3701	[ val ]  epoch 94/100,  batch 31/135,  loss_val=0.77509,  acc_val=81.25%
12421.4s	3702	[ val ]  epoch 94/100,  batch 41/135,  loss_val=1.99781,  acc_val=56.25%
12423.2s	3703	[ val ]  epoch 94/100,  batch 51/135,  loss_val=2.96182,  acc_val=42.19%
12425.0s	3704	[ val ]  epoch 94/100,  batch 61/135,  loss_val=3.77353,  acc_val=25.00%
12426.8s	3705	[ val ]  epoch 94/100,  batch 71/135,  loss_val=3.05784,  acc_val=31.25%
12428.6s	3706	[ val ]  epoch 94/100,  batch 81/135,  loss_val=3.71053,  acc_val=46.88%
12430.4s	3707	[ val ]  epoch 94/100,  batch 91/135,  loss_val=4.46674,  acc_val=23.44%
12432.1s	3708	[ val ]  epoch 94/100,  batch 101/135,  loss_val=1.04983,  acc_val=71.88%
12433.9s	3709	[ val ]  epoch 94/100,  batch 111/135,  loss_val=3.03300,  acc_val=32.81%
12436.1s	3710	[ val ]  epoch 94/100,  batch 121/135,  loss_val=0.96701,  acc_val=76.56%
12437.5s	3711	[ val ]  epoch 94/100,  batch 131/135,  loss_val=4.04571,  acc_val=26.56%
12438.1s	3712	===================================================================================================================
12438.1s	3713	Epoch 94/100 summary: loss_train=0.31292, acc_train=90.34%, loss_val=2.64, acc_val=46.55% (best: 48.65% @ epoch 83)
12438.1s	3714	===================================================================================================================
12438.1s	3715	Starting epoch 95/100, learning_rate=0.1
12439.3s	3716	[train]  epoch 95/100,  batch 1/188,  loss_train=0.30120,  acc_train=90.62%
12445.0s	3717	[train]  epoch 95/100,  batch 11/188,  loss_train=0.52904,  acc_train=89.06%
12450.6s	3718	[train]  epoch 95/100,  batch 21/188,  loss_train=0.33891,  acc_train=92.19%
12456.3s	3719	[train]  epoch 95/100,  batch 31/188,  loss_train=0.49738,  acc_train=84.38%
12461.9s	3720	[train]  epoch 95/100,  batch 41/188,  loss_train=0.34899,  acc_train=87.50%
12467.9s	3721	[train]  epoch 95/100,  batch 51/188,  loss_train=0.45563,  acc_train=84.38%
12473.2s	3722	[train]  epoch 95/100,  batch 61/188,  loss_train=0.26394,  acc_train=92.19%
12478.8s	3723	[train]  epoch 95/100,  batch 71/188,  loss_train=0.22688,  acc_train=93.75%
12484.5s	3724	[train]  epoch 95/100,  batch 81/188,  loss_train=0.27846,  acc_train=90.62%
12490.1s	3725	[train]  epoch 95/100,  batch 91/188,  loss_train=0.54381,  acc_train=78.12%
12495.8s	3726	[train]  epoch 95/100,  batch 101/188,  loss_train=0.23956,  acc_train=93.75%
12501.6s	3727	[train]  epoch 95/100,  batch 111/188,  loss_train=0.23543,  acc_train=93.75%
12507.0s	3728	[train]  epoch 95/100,  batch 121/188,  loss_train=0.34127,  acc_train=90.62%
12512.7s	3729	[train]  epoch 95/100,  batch 131/188,  loss_train=0.34971,  acc_train=87.50%
12518.3s	3730	[train]  epoch 95/100,  batch 141/188,  loss_train=0.39633,  acc_train=89.06%
12523.9s	3731	[train]  epoch 95/100,  batch 151/188,  loss_train=0.31848,  acc_train=92.19%
12529.5s	3732	[train]  epoch 95/100,  batch 161/188,  loss_train=0.34750,  acc_train=85.94%
12535.5s	3733	[train]  epoch 95/100,  batch 171/188,  loss_train=0.26429,  acc_train=90.62%
12540.8s	3734	[train]  epoch 95/100,  batch 181/188,  loss_train=0.35515,  acc_train=89.06%
12545.4s	3735	[ val ]  epoch 95/100,  batch 1/135,  loss_val=3.56041,  acc_val=31.25%
12547.2s	3736	[ val ]  epoch 95/100,  batch 11/135,  loss_val=2.63944,  acc_val=45.31%
12549.1s	3737	[ val ]  epoch 95/100,  batch 21/135,  loss_val=3.33077,  acc_val=25.00%
12550.9s	3738	[ val ]  epoch 95/100,  batch 31/135,  loss_val=1.43431,  acc_val=70.31%
12552.7s	3739	[ val ]  epoch 95/100,  batch 41/135,  loss_val=1.96417,  acc_val=62.50%
12554.5s	3740	[ val ]  epoch 95/100,  batch 51/135,  loss_val=1.28336,  acc_val=68.75%
12556.3s	3741	[ val ]  epoch 95/100,  batch 61/135,  loss_val=2.58543,  acc_val=50.00%
12558.0s	3742	[ val ]  epoch 95/100,  batch 71/135,  loss_val=1.40216,  acc_val=71.88%
12559.8s	3743	[ val ]  epoch 95/100,  batch 81/135,  loss_val=4.21490,  acc_val=40.62%
12561.6s	3744	[ val ]  epoch 95/100,  batch 91/135,  loss_val=4.87322,  acc_val=20.31%
12563.4s	3745	[ val ]  epoch 95/100,  batch 101/135,  loss_val=2.63024,  acc_val=34.38%
12565.2s	3746	[ val ]  epoch 95/100,  batch 111/135,  loss_val=3.22502,  acc_val=37.50%
12567.3s	3747	[ val ]  epoch 95/100,  batch 121/135,  loss_val=2.50857,  acc_val=46.88%
12568.7s	3748	[ val ]  epoch 95/100,  batch 131/135,  loss_val=2.25143,  acc_val=53.12%
12569.3s	3749	===================================================================================================================
12569.3s	3750	Epoch 95/100 summary: loss_train=0.32845, acc_train=90.04%, loss_val=2.69, acc_val=44.92% (best: 48.65% @ epoch 83)
12569.3s	3751	===================================================================================================================
12569.3s	3752	Starting epoch 96/100, learning_rate=0.1
12570.6s	3753	[train]  epoch 96/100,  batch 1/188,  loss_train=0.30601,  acc_train=90.62%
12576.2s	3754	[train]  epoch 96/100,  batch 11/188,  loss_train=0.28251,  acc_train=95.31%
12581.8s	3755	[train]  epoch 96/100,  batch 21/188,  loss_train=0.28094,  acc_train=90.62%
12587.5s	3756	[train]  epoch 96/100,  batch 31/188,  loss_train=0.44634,  acc_train=84.38%
12593.2s	3757	[train]  epoch 96/100,  batch 41/188,  loss_train=0.15342,  acc_train=98.44%
12599.1s	3758	[train]  epoch 96/100,  batch 51/188,  loss_train=0.41141,  acc_train=87.50%
12604.4s	3759	[train]  epoch 96/100,  batch 61/188,  loss_train=0.16584,  acc_train=93.75%
12610.0s	3760	[train]  epoch 96/100,  batch 71/188,  loss_train=0.24763,  acc_train=90.62%
12615.7s	3761	[train]  epoch 96/100,  batch 81/188,  loss_train=0.35853,  acc_train=90.62%
12621.3s	3762	[train]  epoch 96/100,  batch 91/188,  loss_train=0.17018,  acc_train=95.31%
12626.9s	3763	[train]  epoch 96/100,  batch 101/188,  loss_train=0.25442,  acc_train=92.19%
12632.9s	3764	[train]  epoch 96/100,  batch 111/188,  loss_train=0.33697,  acc_train=89.06%
12638.2s	3765	[train]  epoch 96/100,  batch 121/188,  loss_train=0.22212,  acc_train=90.62%
12643.8s	3766	[train]  epoch 96/100,  batch 131/188,  loss_train=0.43314,  acc_train=90.62%
12649.5s	3767	[train]  epoch 96/100,  batch 141/188,  loss_train=0.44017,  acc_train=78.12%
12655.1s	3768	[train]  epoch 96/100,  batch 151/188,  loss_train=0.47529,  acc_train=81.25%
12660.7s	3769	[train]  epoch 96/100,  batch 161/188,  loss_train=0.31898,  acc_train=90.62%
12666.7s	3770	[train]  epoch 96/100,  batch 171/188,  loss_train=0.36901,  acc_train=85.94%
12672.0s	3771	[train]  epoch 96/100,  batch 181/188,  loss_train=0.31067,  acc_train=89.06%
12676.7s	3772	[ val ]  epoch 96/100,  batch 1/135,  loss_val=3.92549,  acc_val=28.12%
12678.6s	3773	[ val ]  epoch 96/100,  batch 11/135,  loss_val=2.47428,  acc_val=50.00%
12680.4s	3774	[ val ]  epoch 96/100,  batch 21/135,  loss_val=5.15071,  acc_val=21.88%
12682.2s	3775	[ val ]  epoch 96/100,  batch 31/135,  loss_val=2.23476,  acc_val=57.81%
12684.0s	3776	[ val ]  epoch 96/100,  batch 41/135,  loss_val=1.76948,  acc_val=59.38%
12685.8s	3777	[ val ]  epoch 96/100,  batch 51/135,  loss_val=1.16440,  acc_val=70.31%
12687.6s	3778	[ val ]  epoch 96/100,  batch 61/135,  loss_val=3.26352,  acc_val=39.06%
12689.4s	3779	[ val ]  epoch 96/100,  batch 71/135,  loss_val=2.52075,  acc_val=50.00%
12691.2s	3780	[ val ]  epoch 96/100,  batch 81/135,  loss_val=3.60752,  acc_val=42.19%
12693.0s	3781	[ val ]  epoch 96/100,  batch 91/135,  loss_val=4.23023,  acc_val=26.56%
12694.7s	3782	[ val ]  epoch 96/100,  batch 101/135,  loss_val=1.37084,  acc_val=59.38%
12696.5s	3783	[ val ]  epoch 96/100,  batch 111/135,  loss_val=2.91232,  acc_val=42.19%
12698.7s	3784	[ val ]  epoch 96/100,  batch 121/135,  loss_val=2.15551,  acc_val=45.31%
12700.1s	3785	[ val ]  epoch 96/100,  batch 131/135,  loss_val=3.79277,  acc_val=35.94%
12700.7s	3786	===================================================================================================================
12700.7s	3787	Epoch 96/100 summary: loss_train=0.30709, acc_train=90.70%, loss_val=2.75, acc_val=42.66% (best: 48.65% @ epoch 83)
12700.7s	3788	===================================================================================================================
12700.7s	3789	Starting epoch 97/100, learning_rate=0.1
12702.0s	3790	[train]  epoch 97/100,  batch 1/188,  loss_train=0.23334,  acc_train=96.88%
12707.7s	3791	[train]  epoch 97/100,  batch 11/188,  loss_train=0.20018,  acc_train=93.75%
12713.3s	3792	[train]  epoch 97/100,  batch 21/188,  loss_train=0.30313,  acc_train=93.75%
12718.9s	3793	[train]  epoch 97/100,  batch 31/188,  loss_train=0.24958,  acc_train=93.75%
12724.6s	3794	[train]  epoch 97/100,  batch 41/188,  loss_train=0.30107,  acc_train=93.75%
12730.5s	3795	[train]  epoch 97/100,  batch 51/188,  loss_train=0.25180,  acc_train=90.62%
12735.9s	3796	[train]  epoch 97/100,  batch 61/188,  loss_train=0.36115,  acc_train=89.06%
12741.5s	3797	[train]  epoch 97/100,  batch 71/188,  loss_train=0.42222,  acc_train=87.50%
12747.2s	3798	[train]  epoch 97/100,  batch 81/188,  loss_train=0.21765,  acc_train=93.75%
12752.8s	3799	[train]  epoch 97/100,  batch 91/188,  loss_train=0.30270,  acc_train=90.62%
12758.4s	3800	[train]  epoch 97/100,  batch 101/188,  loss_train=0.22118,  acc_train=95.31%
12764.3s	3801	[train]  epoch 97/100,  batch 111/188,  loss_train=0.45350,  acc_train=89.06%
12769.7s	3802	[train]  epoch 97/100,  batch 121/188,  loss_train=0.17558,  acc_train=95.31%
12775.4s	3803	[train]  epoch 97/100,  batch 131/188,  loss_train=0.29644,  acc_train=90.62%
12781.0s	3804	[train]  epoch 97/100,  batch 141/188,  loss_train=0.34288,  acc_train=90.62%
12786.6s	3805	[train]  epoch 97/100,  batch 151/188,  loss_train=0.43030,  acc_train=85.94%
12792.2s	3806	[train]  epoch 97/100,  batch 161/188,  loss_train=0.24708,  acc_train=92.19%
12798.2s	3807	[train]  epoch 97/100,  batch 171/188,  loss_train=0.34002,  acc_train=92.19%
12803.5s	3808	[train]  epoch 97/100,  batch 181/188,  loss_train=0.37192,  acc_train=87.50%
12808.2s	3809	[ val ]  epoch 97/100,  batch 1/135,  loss_val=3.03290,  acc_val=39.06%
12810.0s	3810	[ val ]  epoch 97/100,  batch 11/135,  loss_val=1.78265,  acc_val=53.12%
12811.8s	3811	[ val ]  epoch 97/100,  batch 21/135,  loss_val=2.47429,  acc_val=42.19%
12813.6s	3812	[ val ]  epoch 97/100,  batch 31/135,  loss_val=1.04297,  acc_val=75.00%
12815.4s	3813	[ val ]  epoch 97/100,  batch 41/135,  loss_val=2.02461,  acc_val=62.50%
12817.2s	3814	[ val ]  epoch 97/100,  batch 51/135,  loss_val=2.62572,  acc_val=53.12%
12819.0s	3815	[ val ]  epoch 97/100,  batch 61/135,  loss_val=2.28640,  acc_val=51.56%
12820.8s	3816	[ val ]  epoch 97/100,  batch 71/135,  loss_val=4.01790,  acc_val=23.44%
12822.5s	3817	[ val ]  epoch 97/100,  batch 81/135,  loss_val=3.89990,  acc_val=39.06%
12824.3s	3818	[ val ]  epoch 97/100,  batch 91/135,  loss_val=2.38884,  acc_val=42.19%
12826.1s	3819	[ val ]  epoch 97/100,  batch 101/135,  loss_val=1.32170,  acc_val=59.38%
12827.9s	3820	[ val ]  epoch 97/100,  batch 111/135,  loss_val=2.88797,  acc_val=42.19%
12830.0s	3821	[ val ]  epoch 97/100,  batch 121/135,  loss_val=1.92048,  acc_val=57.81%
12831.5s	3822	[ val ]  epoch 97/100,  batch 131/135,  loss_val=2.28819,  acc_val=48.44%
12832.1s	3823	===================================================================================================================
12832.1s	3824	Epoch 97/100 summary: loss_train=0.30023, acc_train=90.91%, loss_val=2.65, acc_val=44.62% (best: 48.65% @ epoch 83)
12832.1s	3825	===================================================================================================================
12832.1s	3826	Starting epoch 98/100, learning_rate=0.1
12833.4s	3827	[train]  epoch 98/100,  batch 1/188,  loss_train=0.35052,  acc_train=89.06%
12839.0s	3828	[train]  epoch 98/100,  batch 11/188,  loss_train=0.35523,  acc_train=89.06%
12844.7s	3829	[train]  epoch 98/100,  batch 21/188,  loss_train=0.25831,  acc_train=93.75%
12850.3s	3830	[train]  epoch 98/100,  batch 31/188,  loss_train=0.17187,  acc_train=98.44%
12855.9s	3831	[train]  epoch 98/100,  batch 41/188,  loss_train=0.29635,  acc_train=95.31%
12861.9s	3832	[train]  epoch 98/100,  batch 51/188,  loss_train=0.32428,  acc_train=92.19%
12867.1s	3833	[train]  epoch 98/100,  batch 61/188,  loss_train=0.40462,  acc_train=89.06%
12872.8s	3834	[train]  epoch 98/100,  batch 71/188,  loss_train=0.29892,  acc_train=87.50%
12878.5s	3835	[train]  epoch 98/100,  batch 81/188,  loss_train=0.47859,  acc_train=85.94%
12884.1s	3836	[train]  epoch 98/100,  batch 91/188,  loss_train=0.34318,  acc_train=92.19%
12889.7s	3837	[train]  epoch 98/100,  batch 101/188,  loss_train=0.27231,  acc_train=89.06%
12895.6s	3838	[train]  epoch 98/100,  batch 111/188,  loss_train=0.29499,  acc_train=90.62%
12901.0s	3839	[train]  epoch 98/100,  batch 121/188,  loss_train=0.29169,  acc_train=90.62%
12906.6s	3840	[train]  epoch 98/100,  batch 131/188,  loss_train=0.35030,  acc_train=87.50%
12912.2s	3841	[train]  epoch 98/100,  batch 141/188,  loss_train=0.30595,  acc_train=92.19%
12917.9s	3842	[train]  epoch 98/100,  batch 151/188,  loss_train=0.33082,  acc_train=87.50%
12923.5s	3843	[train]  epoch 98/100,  batch 161/188,  loss_train=0.54841,  acc_train=82.81%
12929.3s	3844	[train]  epoch 98/100,  batch 171/188,  loss_train=0.33054,  acc_train=87.50%
12934.8s	3845	[train]  epoch 98/100,  batch 181/188,  loss_train=0.24656,  acc_train=92.19%
12939.4s	3846	[ val ]  epoch 98/100,  batch 1/135,  loss_val=2.91072,  acc_val=42.19%
12941.2s	3847	[ val ]  epoch 98/100,  batch 11/135,  loss_val=3.39290,  acc_val=28.12%
12943.0s	3848	[ val ]  epoch 98/100,  batch 21/135,  loss_val=3.66757,  acc_val=26.56%
12944.7s	3849	[ val ]  epoch 98/100,  batch 31/135,  loss_val=1.14251,  acc_val=67.19%
12946.5s	3850	[ val ]  epoch 98/100,  batch 41/135,  loss_val=1.69476,  acc_val=62.50%
12948.2s	3851	[ val ]  epoch 98/100,  batch 51/135,  loss_val=3.01627,  acc_val=43.75%
12950.0s	3852	[ val ]  epoch 98/100,  batch 61/135,  loss_val=2.85740,  acc_val=39.06%
12951.8s	3853	[ val ]  epoch 98/100,  batch 71/135,  loss_val=1.91782,  acc_val=51.56%
12953.6s	3854	[ val ]  epoch 98/100,  batch 81/135,  loss_val=2.94435,  acc_val=48.44%
12955.4s	3855	[ val ]  epoch 98/100,  batch 91/135,  loss_val=3.89690,  acc_val=25.00%
12957.1s	3856	[ val ]  epoch 98/100,  batch 101/135,  loss_val=0.74882,  acc_val=78.12%
12958.9s	3857	[ val ]  epoch 98/100,  batch 111/135,  loss_val=1.71211,  acc_val=56.25%
12961.0s	3858	[ val ]  epoch 98/100,  batch 121/135,  loss_val=1.71654,  acc_val=54.69%
12962.5s	3859	[ val ]  epoch 98/100,  batch 131/135,  loss_val=3.04827,  acc_val=40.62%
12963.0s	3860	===================================================================================================================
12963.0s	3861	Epoch 98/100 summary: loss_train=0.32160, acc_train=90.42%, loss_val=2.54, acc_val=46.55% (best: 48.65% @ epoch 83)
12963.0s	3862	===================================================================================================================
12963.0s	3863	Starting epoch 99/100, learning_rate=0.1
12964.3s	3864	[train]  epoch 99/100,  batch 1/188,  loss_train=0.40276,  acc_train=89.06%
12970.0s	3865	[train]  epoch 99/100,  batch 11/188,  loss_train=0.39473,  acc_train=84.38%
12975.6s	3866	[train]  epoch 99/100,  batch 21/188,  loss_train=0.22318,  acc_train=92.19%
12981.3s	3867	[train]  epoch 99/100,  batch 31/188,  loss_train=0.23490,  acc_train=93.75%
12986.9s	3868	[train]  epoch 99/100,  batch 41/188,  loss_train=0.28164,  acc_train=90.62%
12992.8s	3869	[train]  epoch 99/100,  batch 51/188,  loss_train=0.32405,  acc_train=90.62%
12998.1s	3870	[train]  epoch 99/100,  batch 61/188,  loss_train=0.38322,  acc_train=89.06%
13003.8s	3871	[train]  epoch 99/100,  batch 71/188,  loss_train=0.43455,  acc_train=85.94%
13009.4s	3872	[train]  epoch 99/100,  batch 81/188,  loss_train=0.28590,  acc_train=90.62%
13015.0s	3873	[train]  epoch 99/100,  batch 91/188,  loss_train=0.53690,  acc_train=76.56%
13020.7s	3874	[train]  epoch 99/100,  batch 101/188,  loss_train=0.14049,  acc_train=96.88%
13026.6s	3875	[train]  epoch 99/100,  batch 111/188,  loss_train=0.21722,  acc_train=93.75%
13032.0s	3876	[train]  epoch 99/100,  batch 121/188,  loss_train=0.27075,  acc_train=93.75%
13037.6s	3877	[train]  epoch 99/100,  batch 131/188,  loss_train=0.23193,  acc_train=92.19%
13043.2s	3878	[train]  epoch 99/100,  batch 141/188,  loss_train=0.26456,  acc_train=90.62%
13048.9s	3879	[train]  epoch 99/100,  batch 151/188,  loss_train=0.32809,  acc_train=89.06%
13054.5s	3880	[train]  epoch 99/100,  batch 161/188,  loss_train=0.33859,  acc_train=87.50%
13060.4s	3881	[train]  epoch 99/100,  batch 171/188,  loss_train=0.29900,  acc_train=90.62%
13065.7s	3882	[train]  epoch 99/100,  batch 181/188,  loss_train=0.25851,  acc_train=92.19%
13070.4s	3883	[ val ]  epoch 99/100,  batch 1/135,  loss_val=3.53748,  acc_val=37.50%
13072.2s	3884	[ val ]  epoch 99/100,  batch 11/135,  loss_val=2.70324,  acc_val=56.25%
13074.0s	3885	[ val ]  epoch 99/100,  batch 21/135,  loss_val=2.17023,  acc_val=53.12%
13075.8s	3886	[ val ]  epoch 99/100,  batch 31/135,  loss_val=0.94061,  acc_val=76.56%
13077.6s	3887	[ val ]  epoch 99/100,  batch 41/135,  loss_val=1.93237,  acc_val=59.38%
13079.4s	3888	[ val ]  epoch 99/100,  batch 51/135,  loss_val=2.30210,  acc_val=51.56%
13081.1s	3889	[ val ]  epoch 99/100,  batch 61/135,  loss_val=3.10510,  acc_val=29.69%
13082.9s	3890	[ val ]  epoch 99/100,  batch 71/135,  loss_val=2.92010,  acc_val=40.62%
13084.7s	3891	[ val ]  epoch 99/100,  batch 81/135,  loss_val=3.49190,  acc_val=40.62%
13086.5s	3892	[ val ]  epoch 99/100,  batch 91/135,  loss_val=3.44217,  acc_val=26.56%
13088.3s	3893	[ val ]  epoch 99/100,  batch 101/135,  loss_val=0.70186,  acc_val=81.25%
13090.2s	3894	[ val ]  epoch 99/100,  batch 111/135,  loss_val=4.72751,  acc_val=14.06%
13092.3s	3895	[ val ]  epoch 99/100,  batch 121/135,  loss_val=1.63501,  acc_val=60.94%
13093.7s	3896	[ val ]  epoch 99/100,  batch 131/135,  loss_val=3.52606,  acc_val=35.94%
13094.4s	3897	===================================================================================================================
13094.4s	3898	Epoch 99/100 summary: loss_train=0.29759, acc_train=91.07%, loss_val=2.55, acc_val=46.54% (best: 48.65% @ epoch 83)
13094.4s	3899	===================================================================================================================
13094.4s	3900	Starting epoch 100/100, learning_rate=0.1
13095.6s	3901	[train]  epoch 100/100,  batch 1/188,  loss_train=0.20559,  acc_train=96.88%
13101.2s	3902	[train]  epoch 100/100,  batch 11/188,  loss_train=0.14725,  acc_train=98.44%
13106.8s	3903	[train]  epoch 100/100,  batch 21/188,  loss_train=0.20223,  acc_train=93.75%
13112.4s	3904	[train]  epoch 100/100,  batch 31/188,  loss_train=0.23641,  acc_train=92.19%
13118.1s	3905	[train]  epoch 100/100,  batch 41/188,  loss_train=0.22859,  acc_train=92.19%
13124.1s	3906	[train]  epoch 100/100,  batch 51/188,  loss_train=0.24785,  acc_train=96.88%
13129.4s	3907	[train]  epoch 100/100,  batch 61/188,  loss_train=0.19159,  acc_train=93.75%
13135.0s	3908	[train]  epoch 100/100,  batch 71/188,  loss_train=0.15861,  acc_train=98.44%
13140.6s	3909	[train]  epoch 100/100,  batch 81/188,  loss_train=0.17993,  acc_train=96.88%
13146.3s	3910	[train]  epoch 100/100,  batch 91/188,  loss_train=0.23393,  acc_train=93.75%
13151.9s	3911	[train]  epoch 100/100,  batch 101/188,  loss_train=0.13134,  acc_train=95.31%
13157.9s	3912	[train]  epoch 100/100,  batch 111/188,  loss_train=0.25587,  acc_train=92.19%
13163.2s	3913	[train]  epoch 100/100,  batch 121/188,  loss_train=0.21927,  acc_train=93.75%
13168.8s	3914	[train]  epoch 100/100,  batch 131/188,  loss_train=0.30185,  acc_train=92.19%
13174.4s	3915	[train]  epoch 100/100,  batch 141/188,  loss_train=0.45791,  acc_train=82.81%
13180.1s	3916	[train]  epoch 100/100,  batch 151/188,  loss_train=0.17967,  acc_train=96.88%
13185.7s	3917	[train]  epoch 100/100,  batch 161/188,  loss_train=0.41275,  acc_train=89.06%
13191.7s	3918	[train]  epoch 100/100,  batch 171/188,  loss_train=0.24844,  acc_train=89.06%
13196.9s	3919	[train]  epoch 100/100,  batch 181/188,  loss_train=0.33257,  acc_train=87.50%
13201.6s	3920	[ val ]  epoch 100/100,  batch 1/135,  loss_val=2.75068,  acc_val=43.75%
13203.4s	3921	[ val ]  epoch 100/100,  batch 11/135,  loss_val=3.56708,  acc_val=28.12%
13205.2s	3922	[ val ]  epoch 100/100,  batch 21/135,  loss_val=2.73055,  acc_val=35.94%
13207.0s	3923	[ val ]  epoch 100/100,  batch 31/135,  loss_val=1.43246,  acc_val=62.50%
13208.8s	3924	[ val ]  epoch 100/100,  batch 41/135,  loss_val=2.05846,  acc_val=54.69%
13210.5s	3925	[ val ]  epoch 100/100,  batch 51/135,  loss_val=2.76767,  acc_val=50.00%
13212.3s	3926	[ val ]  epoch 100/100,  batch 61/135,  loss_val=2.16835,  acc_val=60.94%
13214.1s	3927	[ val ]  epoch 100/100,  batch 71/135,  loss_val=2.76278,  acc_val=46.88%
13215.9s	3928	[ val ]  epoch 100/100,  batch 81/135,  loss_val=2.54222,  acc_val=57.81%
13217.9s	3929	[ val ]  epoch 100/100,  batch 91/135,  loss_val=4.37233,  acc_val=18.75%
13219.7s	3930	[ val ]  epoch 100/100,  batch 101/135,  loss_val=0.91547,  acc_val=78.12%
13221.5s	3931	[ val ]  epoch 100/100,  batch 111/135,  loss_val=2.82258,  acc_val=42.19%
13223.6s	3932	[ val ]  epoch 100/100,  batch 121/135,  loss_val=2.84480,  acc_val=39.06%
13225.0s	3933	[ val ]  epoch 100/100,  batch 131/135,  loss_val=3.93895,  acc_val=32.81%
13225.6s	3934	====================================================================================================================
13225.6s	3935	Epoch 100/100 summary: loss_train=0.26739, acc_train=92.05%, loss_val=2.63, acc_val=45.69% (best: 48.65% @ epoch 83)
13225.6s	3936	====================================================================================================================
